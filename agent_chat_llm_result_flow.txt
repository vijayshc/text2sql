Agent Chat - LLM Result JSON Viewer Flow
============================================

┌─────────────────────────────────────────────────────────────────────┐
│                          USER INTERACTION                            │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 1. Sends query via Agent Chat UI
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    Frontend (agent-chat.js)                          │
│  - sendMessage() called                                              │
│  - POST to /api/agent/autogen/chat                                   │
│  - Includes: query, team_id/workflow_id, conversation_history        │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 2. SSE Stream
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│               Backend (autogen_routes.py)                            │
│  - autogen_chat_stream() function                                   │
│  - Creates AutoGenOrchestrator                                       │
│  - Runs team/workflow with RunMonitor                                │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 3. Executes
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│          AutoGen Orchestrator (autogen_orchestrator.py)              │
│  - Runs team agents/workflow                                        │
│  - Logs events via monitor.log_event()                              │
│  - Logs 'llm_result' event with detail: {reply, elapsed_sec, ...}   │
│  - Returns {success, reply, run_id}                                  │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 4. Returns result
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│            Backend (autogen_routes.py continued)                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ if res.get('success'):                                       │   │
│  │   run_id = res.get('run_id')                                 │   │
│  │   # Fetch llm_result from run events                         │   │
│  │   events = RunMonitor.get_events(run_id)                     │   │
│  │   for event in reversed(events):                             │   │
│  │     if event.get('event_type') == 'llm_result':              │   │
│  │       llm_result_data = event.get('detail', {})              │   │
│  │       break                                                   │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                       │
│  - Yields SSE update with:                                           │
│    {                                                                  │
│      type: 'llm_response',                                           │
│      content: reply,                                                 │
│      is_final: true,                                                 │
│      run_id: run_id,                                                 │
│      llm_result: llm_result_data  ← NEW!                             │
│    }                                                                  │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 5. Stream response
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│              Frontend (agent-chat.js continued)                      │
│  - handleUpdate() receives the SSE update                            │
│  - Case 'llm_response':                                              │
│    ┌───────────────────────────────────────────────────────────┐   │
│    │ if (update.is_final) {                                     │   │
│    │   addMessage(                                              │   │
│    │     update.content,                                        │   │
│    │     'agent',                                               │   │
│    │     true,                                                  │   │
│    │     update.llm_result || null  ← Pass llm_result data     │   │
│    │   );                                                       │   │
│    │ }                                                          │   │
│    └───────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 6. Render message
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│            addMessage() Function (agent-chat.js)                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ - Creates message element with markdown content             │   │
│  │ - If type === 'agent' && isFinal && llmResultData:          │   │
│  │   * Creates icon button: <i class="fas fa-code"></i>        │   │
│  │   * Appends button to avatar container (not content)        │   │
│  │   * Positioned next to robot icon at the top                │   │
│  │   * Stores llm_result in data attribute                     │   │
│  │   * Adds click handler → showLlmResultModal()               │   │
│  └─────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 7. Display in UI
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│                          CHAT UI                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  🤖 [</>]  ← Icon next to robot avatar                      │   │
│  │  ┌────────────────────────────────────────────────────┐     │   │
│  │  │ Here is the answer to your query...                │     │   │
│  │  │                                                     │     │   │
│  │  │ [Formatted markdown content]                       │     │   │
│  │  └────────────────────────────────────────────────────┘     │   │
│  └─────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 8. User clicks icon
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│         showLlmResultModal() Function (agent-chat.js)                │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ - Creates/shows Bootstrap modal                             │   │
│  │ - Displays pretty-printed JSON                              │   │
│  │ - Provides Copy button                                      │   │
│  └─────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ 9. View JSON
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    LLM Result JSON Modal                             │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  LLM Result JSON                                    [X]      │   │
│  │  ┌────────────────────────────────────────────────────┐     │   │
│  │  │ {                                                  │     │   │
│  │  │   "reply": "messages=[TextMessage(...), ...]",     │     │   │
│  │  │   "elapsed_sec": 2.345,                            │     │   │
│  │  │   "stop_reason": "stop"                            │     │   │
│  │  │ }                                                  │     │   │
│  │  └────────────────────────────────────────────────────┘     │   │
│  │                                                              │   │
│  │              [📋 Copy]  [Close]                              │   │
│  └─────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘


KEY COMPONENTS:
================

1. RunMonitor (run_monitor.py)
   - Stores all agent run events in SQLite database
   - Event type 'llm_result' contains the complete LLM response

2. AutoGenOrchestrator (autogen_orchestrator.py)
   - Logs llm_result event during team/workflow execution
   - Detail includes: reply, elapsed_sec, stop_reason

3. autogen_routes.py
   - Fetches llm_result event from database after run completes
   - Includes it in the SSE stream response

4. agent-chat.js
   - Receives llm_result in the stream
   - Adds icon button to final messages
   - Shows modal with JSON on click

DATA FLOW:
===========

RunMonitor DB → Backend fetches → SSE stream → Frontend stores → 
User clicks icon → Modal displays → User views/copies JSON
