2025-08-09 12:03:24,113 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:24,113 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:24,114 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:24,114 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:24,120 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:03:27,277 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-09 12:03:27,291 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:03:27,292 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:03:27,320 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:03:27,320 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:27,320 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:27,320 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:27,321 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:27,321 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:03:27,321 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:03:27,347 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:03:27,347 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:27,347 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:27,347 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:27,347 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:27,347 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:03:27,348 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:03:27,375 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:03:27,375 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:27,375 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:27,375 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:27,375 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:27,376 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-09 12:03:27,376 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:03:27,376 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:03:27,402 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:03:27,402 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-09 12:03:27,402 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:03:27,402 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:27,403 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:27,403 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:27,403 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:27,403 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:03:27,408 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-09 12:03:27,423 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-09 12:03:27,425 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-09 12:03:27,426 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-09 12:03:27,458 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:03:27,458 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:03:27,486 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:03:27,486 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:27,486 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:27,486 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:27,486 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:27,486 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:03:27,486 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:03:27,513 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:03:27,513 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:27,513 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:27,513 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:27,513 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:27,513 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:03:27,513 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:03:27,539 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:03:27,539 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:27,540 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:27,540 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:27,540 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:27,540 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-09 12:03:27,540 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:03:27,540 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:03:27,566 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:03:27,567 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-09 12:03:27,567 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:03:27,567 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:03:27,567 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:03:27,567 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:03:27,567 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:03:27,567 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:03:27,582 - INFO - [app.py:727] - Initializing application-wide components
2025-08-09 12:03:27,584 - INFO - [app.py:61] - Successfully started MCP server: Data Mapping Analyst
2025-08-09 12:03:27,584 - INFO - [app.py:61] - Successfully started MCP server: dataengineer
2025-08-09 12:03:27,584 - INFO - [app.py:729] - Application-wide components initialization complete
2025-08-09 12:03:27,586 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-09 12:03:27,586 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-09 12:03:49,454 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:49] "[32mGET /admin/vector-db HTTP/1.1[0m" 302 -
2025-08-09 12:03:49,470 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:49] "GET /login?next=http://127.0.0.1:5000/admin/vector-db HTTP/1.1" 200 -
2025-08-09 12:03:49,515 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:49] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-09 12:03:49,523 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:49] "GET /static/css/glassmorphism.css HTTP/1.1" 200 -
2025-08-09 12:03:49,526 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:49] "GET /static/css/auth.css HTTP/1.1" 200 -
2025-08-09 12:03:54,109 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-09 12:03:54,363 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "[32mPOST /login HTTP/1.1[0m" 302 -
2025-08-09 12:03:54,374 - DEBUG - [app.py:163] - Main page requested
2025-08-09 12:03:54,386 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET / HTTP/1.1" 200 -
2025-08-09 12:03:54,427 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-09 12:03:54,440 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-09 12:03:54,441 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-09 12:03:54,443 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-09 12:03:54,445 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-09 12:03:54,449 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-09 12:03:54,453 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-09 12:03:54,454 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-09 12:03:54,479 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-09 12:03:54,482 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-09 12:03:54,562 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-09 12:03:54,573 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:54] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-09 12:03:56,509 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-09 12:03:56,520 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:03:56] "GET /api/tables/suggestions?workspace=dfd&query= HTTP/1.1" 200 -
2025-08-09 12:04:01,771 - INFO - [app.py:185] - User explicitly specified tables: customers
2025-08-09 12:04:01,771 - INFO - [sql_generator.py:37] - Processing query: 'table customers  count'
2025-08-09 12:04:01,772 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:01] "POST /api/query HTTP/1.1" 200 -
2025-08-09 12:04:01,773 - INFO - [sql_generator.py:40] - User explicitly selected tables: customers
2025-08-09 12:04:01,773 - INFO - [intent_agent.py:27] - Intent detection started for query: 'table customers  count'
2025-08-09 12:04:01,773 - INFO - [intent_agent.py:38] - Using default intent 'data_retrieval' without calling LLM
2025-08-09 12:04:01,774 - INFO - [intent_agent.py:41] - Intent detection completed in 0.00s
2025-08-09 12:04:01,774 - INFO - [sql_generator.py:45] - Detected intent: data_retrieval
2025-08-09 12:04:01,774 - INFO - [sql_generator.py:141] - Starting SQL generation process
2025-08-09 12:04:01,774 - INFO - [database.py:80] - Attempting database connection
2025-08-09 12:04:01,775 - INFO - [database.py:84] - Database connection established in 0.00s
2025-08-09 12:04:01,776 - INFO - [column_agent.py:29] - Column pruning started for query: 'table customers  count'
2025-08-09 12:04:01,776 - INFO - [column_agent.py:30] - Processing tables: customers
2025-08-09 12:04:01,776 - INFO - [column_agent.py:38] - Only one table involved (customers). Skipping LLM call and including all columns.
2025-08-09 12:04:01,776 - INFO - [feedback_manager.py:250] - Stage 1: Vector search for 'table customers  count...'
2025-08-09 12:04:01,776 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:01,776 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:01,809 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:01,809 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-09 12:04:02,291 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:02] "GET /api/query/progress/9559bde9-9ae0-45b2-9c00-f4ee1aa44a92 HTTP/1.1" 200 -
2025-08-09 12:04:02,790 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:02] "GET /api/query/progress/9559bde9-9ae0-45b2-9c00-f4ee1aa44a92 HTTP/1.1" 200 -
2025-08-09 12:04:03,297 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:03] "GET /api/query/progress/9559bde9-9ae0-45b2-9c00-f4ee1aa44a92 HTTP/1.1" 200 -
2025-08-09 12:04:03,791 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:03] "GET /api/query/progress/9559bde9-9ae0-45b2-9c00-f4ee1aa44a92 HTTP/1.1" 200 -
2025-08-09 12:04:04,299 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:04] "GET /api/query/progress/9559bde9-9ae0-45b2-9c00-f4ee1aa44a92 HTTP/1.1" 200 -
2025-08-09 12:04:04,371 - INFO - [llm_engine.py:59] - Embedding model loaded in 2.56s
2025-08-09 12:04:04,410 - INFO - [llm_engine.py:85] - Generated embedding in 0.04s with shape (384,)
2025-08-09 12:04:04,412 - ERROR - [vector_store_client.py:269] - Error searching similar vectors in collection query_embeddings: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/query_embeddings/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b0213c2c350>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1289, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1048, in _send_output
    self.send(msg)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 986, in send
    self.connect()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7b0213c2c350>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/query_embeddings/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b0213c2c350>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/vector_store_client.py", line 238, in search_similar
    response = self.session.post(
               ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/query_embeddings/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b0213c2c350>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-09 12:04:04,415 - INFO - [feedback_manager.py:275] - No candidates found from vector search, falling back to text-based search
2025-08-09 12:04:04,415 - INFO - [feedback_manager.py:49] - Attempting database connection
2025-08-09 12:04:04,416 - INFO - [feedback_manager.py:53] - Database connection established in 0.00s
2025-08-09 12:04:04,416 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-09 12:04:04,417 - ERROR - [vector_store_client.py:50] - ChromaDB service connection error: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b02138bd310>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1289, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1048, in _send_output
    self.send(msg)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 986, in send
    self.connect()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7b02138bd310>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b02138bd310>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/vector_store_client.py", line 39, in connect
    response = self.session.get(f"{self.service_url}/health", timeout=10)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b02138bd310>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-09 12:04:04,418 - INFO - [feedback_manager.py:58] - Failed to connect to vector store, vector similarity search will be unavailable
2025-08-09 12:04:04,419 - INFO - [feedback_manager.py:415] - Found 1 similar queries using text-based search for 'table customers  count...'
2025-08-09 12:04:04,419 - INFO - [sql_generator.py:280] - Found 1 similar queries with reranking
2025-08-09 12:04:04,419 - INFO - [sql_generator.py:302] - Added similar query #1 from feedback (score: 0.0000): get me count of customers by their state...
2025-08-09 12:04:04,420 - INFO - [azure_client.py:35] - SQL generation started for query: 'table customers  count'
2025-08-09 12:04:04,420 - INFO - [azure_client.py:69] - Including schema information (587 chars)
2025-08-09 12:04:04,420 - INFO - [azure_client.py:97] - Including 1 SQL examples from feedback similarity search
2025-08-09 12:04:04,420 - INFO - [azure_client.py:114] - PROMPT: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: get me count of customers by their state\nSQL: SELECT \n    state,\n    COUNT(customer_id) AS customer_count\nFROM customers\nGROUP BY state\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers  count'}]
2025-08-09 12:04:04,420 - INFO - [llm_engine.py:128] - [SQL_GEN] Completion generation started (format: openai)
2025-08-09 12:04:04,421 - INFO - [llm_engine.py:193] - [SQL_GEN] Prompt: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief ... (truncated)
2025-08-09 12:04:04,421 - INFO - [llm_engine.py:197] - [SQL_GEN] Sending request to gemma-3-27b-it with max_tokens=2000, temperature=0.7, stream=False
2025-08-09 12:04:04,421 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: get me count of customers by their state\nSQL: SELECT \n    state,\n    COUNT(customer_id) AS customer_count\nFROM customers\nGROUP BY state\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers  count'}]
2025-08-09 12:04:04,789 - ERROR - [llm_engine.py:263] - [SQL_GEN] Completion generation error after 0.37s: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/llm_engine.py", line 237, in generate_completion
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 668, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1260, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 937, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
2025-08-09 12:04:04,801 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:04] "GET /api/query/progress/9559bde9-9ae0-45b2-9c00-f4ee1aa44a92 HTTP/1.1" 200 -
2025-08-09 12:04:04,805 - ERROR - [azure_client.py:138] - SQL generation error after 0.39s: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/azure_client.py", line 117, in generate_sql
    raw_response = self.llm_engine.generate_completion(messages, log_prefix="SQL_GEN")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/text2sql/src/utils/llm_engine.py", line 237, in generate_completion
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 668, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1260, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 937, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
2025-08-09 12:04:04,808 - INFO - [sql_generator.py:444] - SQL generation completed in 3.03s
2025-08-09 12:04:04,808 - INFO - [sql_generator.py:125] - Query processing completed in 3.04s
2025-08-09 12:04:05,298 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:05] "GET /api/query/progress/9559bde9-9ae0-45b2-9c00-f4ee1aa44a92 HTTP/1.1" 200 -
2025-08-09 12:04:31,833 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-09 12:04:31,833 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-09 12:04:31,833 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:04:31,833 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-09 12:04:31,834 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:04:31,834 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-09 12:04:31,834 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:04:31,834 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-09 12:04:31,834 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:04:31,834 - INFO - [database.py:294] - Closing database connection
2025-08-09 12:04:31,835 - INFO - [database.py:297] - Database engine disposed
2025-08-09 12:04:31,835 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-09 12:04:31,835 - DEBUG - [feedback_manager.py:788] - SQLite database engine disposed
2025-08-09 12:04:31,835 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-09 12:04:31,836 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-09 12:04:31,836 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-09 12:04:31,836 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:04:31,836 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-09 12:04:31,836 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:04:31,836 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-09 12:04:31,836 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:04:31,837 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-09 12:04:31,837 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:04:31,837 - INFO - [database.py:294] - Closing database connection
2025-08-09 12:04:31,837 - INFO - [database.py:297] - Database engine disposed
2025-08-09 12:04:31,837 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-09 12:04:31,837 - DEBUG - [feedback_manager.py:788] - SQLite database engine disposed
2025-08-09 12:04:31,837 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-09 12:04:35,186 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:35,186 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:35,187 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:35,187 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:35,188 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:04:38,249 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-09 12:04:38,252 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:38,252 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:38,279 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:38,280 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:38,280 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:38,280 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:38,280 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:38,280 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:38,280 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:38,306 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:38,306 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:38,307 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:38,307 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:38,307 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:38,307 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:38,307 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:38,333 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:38,333 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:38,334 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:38,334 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:38,334 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:38,334 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-09 12:04:38,334 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:38,334 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:38,360 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:38,360 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-09 12:04:38,360 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:04:38,360 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:38,360 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:38,360 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:38,360 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:38,361 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:04:38,365 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-09 12:04:38,380 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-09 12:04:38,382 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-09 12:04:38,383 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-09 12:04:38,409 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:38,409 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:38,435 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:38,435 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:38,436 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:38,436 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:38,436 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:38,436 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:38,436 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:38,462 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:38,462 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:38,463 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:38,463 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:38,463 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:38,463 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:38,463 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:38,489 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:38,489 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:38,489 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:38,489 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:38,489 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:38,489 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-09 12:04:38,489 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:38,489 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:38,515 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:38,515 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-09 12:04:38,515 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:04:38,515 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:04:38,515 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:04:38,516 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:04:38,516 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:04:38,516 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:04:38,529 - INFO - [app.py:727] - Initializing application-wide components
2025-08-09 12:04:38,531 - INFO - [app.py:61] - Successfully started MCP server: Data Mapping Analyst
2025-08-09 12:04:38,531 - INFO - [app.py:61] - Successfully started MCP server: dataengineer
2025-08-09 12:04:38,531 - INFO - [app.py:729] - Application-wide components initialization complete
2025-08-09 12:04:38,532 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-09 12:04:38,532 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-09 12:04:43,329 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-09 12:04:43,336 - INFO - [app.py:185] - User explicitly specified tables: customers
2025-08-09 12:04:43,336 - INFO - [sql_generator.py:37] - Processing query: 'table customers  count'
2025-08-09 12:04:43,338 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:43] "POST /api/query HTTP/1.1" 200 -
2025-08-09 12:04:43,338 - INFO - [sql_generator.py:40] - User explicitly selected tables: customers
2025-08-09 12:04:43,338 - INFO - [intent_agent.py:27] - Intent detection started for query: 'table customers  count'
2025-08-09 12:04:43,338 - INFO - [intent_agent.py:38] - Using default intent 'data_retrieval' without calling LLM
2025-08-09 12:04:43,339 - INFO - [intent_agent.py:41] - Intent detection completed in 0.00s
2025-08-09 12:04:43,339 - INFO - [sql_generator.py:45] - Detected intent: data_retrieval
2025-08-09 12:04:43,339 - INFO - [sql_generator.py:141] - Starting SQL generation process
2025-08-09 12:04:43,339 - INFO - [database.py:80] - Attempting database connection
2025-08-09 12:04:43,340 - INFO - [database.py:84] - Database connection established in 0.00s
2025-08-09 12:04:43,340 - INFO - [column_agent.py:29] - Column pruning started for query: 'table customers  count'
2025-08-09 12:04:43,340 - INFO - [column_agent.py:30] - Processing tables: customers
2025-08-09 12:04:43,341 - INFO - [column_agent.py:38] - Only one table involved (customers). Skipping LLM call and including all columns.
2025-08-09 12:04:43,341 - INFO - [feedback_manager.py:250] - Stage 1: Vector search for 'table customers  count...'
2025-08-09 12:04:43,341 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:04:43,341 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:04:43,370 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:04:43,370 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-09 12:04:43,852 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:43] "GET /api/query/progress/c63cdde5-19a0-4d9b-b0e0-d23fea3a252e HTTP/1.1" 200 -
2025-08-09 12:04:44,355 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:44] "GET /api/query/progress/c63cdde5-19a0-4d9b-b0e0-d23fea3a252e HTTP/1.1" 200 -
2025-08-09 12:04:44,861 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:44] "GET /api/query/progress/c63cdde5-19a0-4d9b-b0e0-d23fea3a252e HTTP/1.1" 200 -
2025-08-09 12:04:45,364 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:45] "GET /api/query/progress/c63cdde5-19a0-4d9b-b0e0-d23fea3a252e HTTP/1.1" 200 -
2025-08-09 12:04:45,860 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:45] "GET /api/query/progress/c63cdde5-19a0-4d9b-b0e0-d23fea3a252e HTTP/1.1" 200 -
2025-08-09 12:04:46,366 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:46] "GET /api/query/progress/c63cdde5-19a0-4d9b-b0e0-d23fea3a252e HTTP/1.1" 200 -
2025-08-09 12:04:46,376 - INFO - [llm_engine.py:59] - Embedding model loaded in 3.01s
2025-08-09 12:04:46,412 - INFO - [llm_engine.py:85] - Generated embedding in 0.03s with shape (384,)
2025-08-09 12:04:46,417 - INFO - [feedback_manager.py:275] - No candidates found from vector search, falling back to text-based search
2025-08-09 12:04:46,418 - INFO - [feedback_manager.py:49] - Attempting database connection
2025-08-09 12:04:46,418 - INFO - [feedback_manager.py:53] - Database connection established in 0.00s
2025-08-09 12:04:46,418 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-09 12:04:46,421 - INFO - [vector_store_client.py:44] - ChromaDB service connection established in 0.00s
2025-08-09 12:04:46,422 - INFO - [feedback_manager.py:415] - Found 1 similar queries using text-based search for 'table customers  count...'
2025-08-09 12:04:46,422 - INFO - [sql_generator.py:280] - Found 1 similar queries with reranking
2025-08-09 12:04:46,422 - INFO - [sql_generator.py:302] - Added similar query #1 from feedback (score: 0.0000): get me count of customers by their state...
2025-08-09 12:04:46,423 - INFO - [azure_client.py:35] - SQL generation started for query: 'table customers  count'
2025-08-09 12:04:46,423 - INFO - [azure_client.py:69] - Including schema information (587 chars)
2025-08-09 12:04:46,423 - INFO - [azure_client.py:97] - Including 1 SQL examples from feedback similarity search
2025-08-09 12:04:46,424 - INFO - [azure_client.py:114] - PROMPT: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: get me count of customers by their state\nSQL: SELECT \n    state,\n    COUNT(customer_id) AS customer_count\nFROM customers\nGROUP BY state\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers  count'}]
2025-08-09 12:04:46,424 - INFO - [llm_engine.py:128] - [SQL_GEN] Completion generation started (format: openai)
2025-08-09 12:04:46,424 - INFO - [llm_engine.py:193] - [SQL_GEN] Prompt: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief ... (truncated)
2025-08-09 12:04:46,424 - INFO - [llm_engine.py:197] - [SQL_GEN] Sending request to gemma-3-27b-it with max_tokens=2000, temperature=0.7, stream=False
2025-08-09 12:04:46,425 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: get me count of customers by their state\nSQL: SELECT \n    state,\n    COUNT(customer_id) AS customer_count\nFROM customers\nGROUP BY state\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers  count'}]
2025-08-09 12:04:46,793 - ERROR - [llm_engine.py:263] - [SQL_GEN] Completion generation error after 0.37s: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/llm_engine.py", line 237, in generate_completion
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 668, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1260, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 937, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
2025-08-09 12:04:46,800 - ERROR - [azure_client.py:138] - SQL generation error after 0.38s: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/azure_client.py", line 117, in generate_sql
    raw_response = self.llm_engine.generate_completion(messages, log_prefix="SQL_GEN")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/text2sql/src/utils/llm_engine.py", line 237, in generate_completion
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 668, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1260, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 937, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
2025-08-09 12:04:46,806 - INFO - [sql_generator.py:444] - SQL generation completed in 3.47s
2025-08-09 12:04:46,807 - INFO - [sql_generator.py:125] - Query processing completed in 3.47s
2025-08-09 12:04:46,860 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:04:46] "GET /api/query/progress/c63cdde5-19a0-4d9b-b0e0-d23fea3a252e HTTP/1.1" 200 -
2025-08-09 12:06:46,416 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:06:46] "GET /knowledge HTTP/1.1" 200 -
2025-08-09 12:06:46,457 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:06:46] "GET /static/js/knowledge-base.js HTTP/1.1" 200 -
2025-08-09 12:06:46,488 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-09 12:06:46,497 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:06:46] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-09 12:06:46,499 - INFO - [knowledge_manager.py:33] - Initializing Knowledge Manager
2025-08-09 12:06:46,542 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-09 12:06:46,545 - INFO - [vector_store_client.py:44] - ChromaDB service connection established in 0.00s
2025-08-09 12:06:46,561 - INFO - [vector_store_client.py:121] - Collection 'knowledge_chunks' already exists
2025-08-09 12:06:46,562 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:06:46,562 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:06:46,589 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:06:46,591 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:06:46] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-09 12:06:55,876 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:06:55] "POST /api/knowledge/query/stream HTTP/1.1" 200 -
2025-08-09 12:06:55,884 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-09 12:06:58,426 - INFO - [llm_engine.py:59] - Embedding model loaded in 2.54s
2025-08-09 12:06:58,471 - INFO - [llm_engine.py:85] - Generated embedding in 0.04s with shape (384,)
2025-08-09 12:06:58,510 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:06:58,510 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:06:58,546 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:06:58,546 - INFO - [llm_engine.py:102] - Loading reranking model 'cross-encoder/ms-marco-MiniLM-L-6-v2'
2025-08-09 12:06:59,633 - INFO - [llm_engine.py:106] - Reranking model loaded in 1.09s
2025-08-09 12:06:59,634 - INFO - [knowledge_manager.py:850] - Reranking 50 chunks using cross-encoder
2025-08-09 12:07:01,139 - INFO - [knowledge_manager.py:858] - Reranking complete, top score: 2.2117366790771484
2025-08-09 12:07:01,144 - INFO - [knowledge_manager.py:734] - Top 3 chunks for query 'what are the various storage types from teradata': ['e87185c0-b3e4-4455-903f-dbca79c3fe4e', 'ffd8e868-01aa-4cf0-8e89-a1fff5f6ecd9', '79a1caee-7a79-43dd-9269-43100b64c7ae']
2025-08-09 12:07:01,144 - INFO - [knowledge_manager.py:740] - Sources for query 'what are the various storage types from teradata': [{'document': 'Teradata_VantageCloud_Enterprise_as_an_AWS_Managed_Application_Cloud_Service_Description_-_Blend.PDF.pdf', 'document_number': 1, 'chunk_id': 'e87185c0-b3e4-4455-903f-dbca79c3fe4e'}]
2025-08-09 12:07:01,144 - INFO - [llm_engine.py:128] - [Knowledge QA] Completion generation started (format: openai)
2025-08-09 12:07:01,145 - INFO - [llm_engine.py:193] - [Knowledge QA] Prompt: [{'role': 'system', 'content': "You are a helpful AI assistant that provides accurate answers based on the given context. \n        If the answer cannot be found in the context, acknowledge that you don't know instead of making up information.\n        Provide clear, concise answers and use markdown formatting in your response to improve readability.\n        \n        IMPORTANT CITATION RULES:\n        - When referencing information from the context, use numbered citations like [1], [2], etc.\n... (truncated)
2025-08-09 12:07:01,145 - INFO - [llm_engine.py:197] - [Knowledge QA] Sending request to gemma-3-27b-it with max_tokens=2000, temperature=0.7, stream=True
2025-08-09 12:07:01,145 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are a helpful AI assistant that provides accurate answers based on the given context. \n        If the answer cannot be found in the context, acknowledge that you don't know instead of making up information.\n        Provide clear, concise answers and use markdown formatting in your response to improve readability.\n        \n        IMPORTANT CITATION RULES:\n        - When referencing information from the context, use numbered citations like [1], [2], etc.\n        - Do NOT repeat the full document names in your response\n        - Use citations sparingly - only at the end of sentences or paragraphs where you reference specific information\n        - The document references will be provided separately at the end, so you don't need to mention document names"}, {'role': 'user', 'content': 'Context information:\n\n\nDocument [1]:\nlogs are also correlated and analyzed. b) Reviewing and approving account management actions c) Monitoring account management operations for unauthorized actions d) Disabling inactive accounts after 90 days e) Disabling VantageCloud accounts after a Teradata user is transferred or terminated\n\nf)  Modifying role-based access when a Teradata user’s system usage or need-to-know\n\nrequirements change\n\nTeradata VantageCloud Enterprise — Cloud Service Description: Blended Pricing\n(Rev. 2023-09-18)\n\nPage 19 of 23\n\n\x0c12.5  Encryption\n\na)  Teradata gives the Customer options for encrypting data-in-transit and data-at-rest. When\nenabled, data is encrypted in transit between Teradata and connecting client sessions.\nData is also secure from public exposure as it traverses network segments in the Cloud\nService Provider’s infrastructure by implementing customer-selected connectivity options.\nData-at-rest is stored in encrypted volumes in the Cloud Service Provider’s storage.\n\nTeradata and connecting client sessions. Data is also secure from public exposure as it traverses network segments in the Cloud Service Provider’s infrastructure by implementing customer-selected connectivity options. Data-at-rest is stored in encrypted volumes in the Cloud Service Provider’s storage.\n\nb)  Enhanced encryption solutions are also available from Teradata’s third-party partners.\n\nAdditional information is provided in the Cloud Service Description Addendum.\n\n12.6  Secure Authentication. Teradata recommends the use of Federated Authentication / Single\n\nSign-on (SSO) and can also provide optional support for Lightweight Directory Access Protocol\n(LDAP) as an authentication method. Teradata Database Authentication (TD2) is provided as a\ndefault database authentication method.\n\na)  Federated Authentication/SSO: Teradata supports Federated Authentication/SSO. This\n\n/ Single Sign-on (SSO) and can also provide optional support for Lightweight Directory Access Protocol (LDAP) as an authentication method. Teradata Database Authentication (TD2) is provided as a default database authentication method. a) Federated Authentication/SSO: Teradata supports Federated Authentication/SSO. This\n\ncapability is specific to Customers that have an identity provider (IdP), enables\nVantageCloud users to log on to the VantageCloud system and supported applications with\na single set of their corporate credentials and enables them to move seamlessly between\napplications. These applications include Teradata Studio, Viewpoint, and certain third-party\napplications. The Customer Identity Provider can be integrated via the Vantage Console.\nThis Federated Authentication/SSO offers the following features:\n\ni.\n\nii.\n\niii.\n\niv.\n\nDocument [1]:\nsection Customer – • Sets up, changes, and manages the Backup Plans using self-service capability utilizing Vantage Console • Defines Backup Lifecycle and Storage Policy Management requirements • Resolves issues causing backup warnings and exceptions 3. VantageCloud Enterprise License Tiers\n\nThe following table shows the categories of features and functions available in the latest version of\nVantageCloud Enterprise for each license tier.\n\nVantageCloud Enterprise License Tiers –\n\nFeatures and Functions\n\nFeatures and Functions\n\nBase\n\nAdvanced\n\nEnterprise\n\nCustomer Support Type\n\nPremier Cloud\n\nPremier Cloud\n\nPremier Cloud\n\nElastic Performance on Demand (EPOD)\nNote: Blended Pricing Option required.\n\nVantage Unit Consumption for\nVantageCloud\nNote: Available for applicable as-a-service\ndeployment options only.\n\nTeradata Columnar\n\nTeradata Intelligent Memory\n\nRow-Level Security\n\nTemporal\n\nWorkload Management\n\nBlock Level Compression\n\nTeradata Native Object Store\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\nt options only.\n\nTeradata Columnar\n\nTeradata Intelligent Memory\n\nRow-Level Security\n\nTemporal\n\nWorkload Management\n\nBlock Level Compression\n\nTeradata Native Object Store\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\nTeradata Integrated\nWorkload Management\n(TIWM)\n\nTeradata Active System\nManagement\n(TASM)\n\n●\n\n●\n\n●\n\n●\n\nTeradata VantageCloud Enterprise — Cloud Service Description: Blended Pricing\n(Rev. 2023-09-18)\n\nPage 4 of 23\n\n\x0c4.  Analytics Database Feature Descriptions\n\nThis section describes the Teradata Analytics Database features that are available in the VantageCloud\nEnterprise license tiers.\n\n4.1  Teradata Columnar gives the Customer the ability to store Customer Data in a table by column,\ninstead of by row. In its simplest form, each column in the table becomes its own column\npartition.\n\n4.2  Teradata Intelligent Memory identifies more frequently used data and places it in memory.\n\n4.3  Row-Level Security allows the Customer to restrict data access on a row-by-row basis in\n\nform, each column in the table becomes its own column partition. 4.2 Teradata Intelligent Memory identifies more frequently used data and places it in memory. 4.3 Row-Level Security allows the Customer to restrict data access on a row-by-row basis in\n\naccordance with Customer-site security policies.\n\n4.4  Temporal tables store and maintain information with respect to time.\n\n4.5  Workload Management can manage VantageCloud workload performance by monitoring\n\nsystem activity and by acting when pre-defined limits are reached.\n\na)  TASM gives administrators the ability to prioritize workloads, tune performance, and\n\nmonitor and manage workload and system health.\n\nb)  TIWM provides basic workload management capabilities (i.e., a subset of TASM) to\n\nCustomers without full TASM.\n\n4.6  Block Level Compression is a required data compression feature and is enabled by default.\n\nDocument [1]:\n(Planned) A minor issue exists; normal operations can continue. Functionality is impacted, but not down. Issue has no business impact and low impact to operations. Additional research or information is needed to address a question. Impacts only a few users.\n\nNo issue exists; normal operations\ncan continue.\n\nNo business impact exists. Teradata uses this severity\nlevel for proactive, planned Cases.\n\nb)  A Change Request is a request to change something about a system. These changes can\ninclude the need to add, modify, configure, upgrade, or even decommission a site or\ndiscontinue use of a service component, application, or other associated elements.\n\ni.\n\nCustomer can submit new “Normal” Change Requests and view existing Change\nRequests in the Support Portal.\n\nii.\n\nTeradata can designate the Change Request as one of three types:\n\na.  Standard – Low risk, pre-approved change plans that follow a specified and\n\ncan submit new “Normal” Change Requests and view existing Change Requests in the Support Portal. ii. Teradata can designate the Change Request as one of three types: a. Standard – Low risk, pre-approved change plans that follow a specified and\n\nrepeatable procedure or work instruction. These changes do not require case-\nby-case approval.\n\nb.  Normal – Changes without predefined plans that require both Customer\n\napproval and approval from the Teradata Cloud Change Advisory Board (i.e., a\nformal approval authority whose function is to control changes to the approved\nVantageCloud architecture).\n\nTeradata VantageCloud Enterprise — Cloud Service Description: Blended Pricing\n(Rev. 2023-09-18)\n\nPage 9 of 23\n\n\x0cc.  Emergency – Unplanned changes necessary for service restoration. These\nchanges require Customer approval and approval from the Teradata Cloud\nChange Advisory Board. An Emergency Change can only be created in one of\nthe following situations:\n\nPage 9 of 23 c. Emergency – Unplanned changes necessary for service restoration. These changes require Customer approval and approval from the Teradata Cloud Change Advisory Board. An Emergency Change can only be created in one of the following situations:\n\n•  The Change is necessary to restore service and is recommended by\n\nTeradata Services SMEs during an S1 case investigation.\n\n•  The change must be for the same account as the Severity 1 case.\n\n•  A critical security vulnerability exists and, if not expeditiously corrected,\n\ncould cause harm to the Cloud system and its Customers.\n\niii.\n\nTeradata will schedule the action taken in response to a Change Request in\nadvance and will coordinate the date and time with both the Customer and the\nassigned Teradata resource.\n\nc)  Service Request has predefined and specific actions, services, or work activities that\n\nDocument References:\n[1] Teradata_VantageCloud_Enterprise_as_an_AWS_Managed_Application_Cloud_Service_Description_-_Blend.PDF.pdf\n\n\nQuestion: what are the various storage types from teradata\n\nProvide a detailed answer to the question based only on the context provided. Use markdown formatting for better readability and numbered citations [1], [2], etc. when referencing specific information.'}]
2025-08-09 12:07:01,474 - ERROR - [llm_engine.py:263] - [Knowledge QA] Completion generation error after 0.33s: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/llm_engine.py", line 203, in generate_completion
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 668, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1260, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 937, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
2025-08-09 12:07:01,480 - INFO - [knowledge_manager.py:1019] - Error generating answer: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
2025-08-09 12:07:01,480 - INFO - [knowledge_manager.py:1020] - Full traceback:
Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/knowledge_manager.py", line 1015, in _generate_answer
    return self.llm_engine.generate_completion(prompt, log_prefix="Knowledge QA", stream=stream)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/text2sql/src/utils/llm_engine.py", line 203, in generate_completion
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 668, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1260, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 937, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]

2025-08-09 12:07:01,483 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:01] "GET /api/knowledge/query/stream?query=what%20are%20the%20various%20storage%20types%20from%20teradata&t=1754712415878 HTTP/1.1" 200 -
2025-08-09 12:07:52,074 - DEBUG - [vector_db_routes.py:53] - Vector database management page requested
2025-08-09 12:07:52,080 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:52] "GET /admin/vector-db HTTP/1.1" 200 -
2025-08-09 12:07:52,115 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:52] "GET /static/js/admin/vector_db.js HTTP/1.1" 200 -
2025-08-09 12:07:52,143 - INFO - [vector_store_client.py:514] - Found collections: ['knowledge_chunks', 'schema_metadata']
2025-08-09 12:07:52,144 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:52] "GET /admin/api/vector-db/collections HTTP/1.1" 200 -
2025-08-09 12:07:52,171 - INFO - [vector_store_client.py:514] - Found collections: ['knowledge_chunks', 'schema_metadata']
2025-08-09 12:07:52,173 - INFO - [vector_store_client.py:514] - Found collections: ['knowledge_chunks', 'schema_metadata']
2025-08-09 12:07:52,178 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:52] "GET /admin/api/vector-db/collections/knowledge_chunks HTTP/1.1" 200 -
2025-08-09 12:07:52,179 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:52] "GET /admin/api/vector-db/collections/schema_metadata HTTP/1.1" 200 -
2025-08-09 12:07:53,898 - INFO - [vector_db_routes.py:244] - GET_COLLECTION_DATA: Requesting data for collection schema_metadata
2025-08-09 12:07:53,900 - INFO - [vector_store_client.py:514] - Found collections: ['knowledge_chunks', 'schema_metadata']
2025-08-09 12:07:53,906 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:53] "GET /admin/api/vector-db/collections/schema_metadata HTTP/1.1" 200 -
2025-08-09 12:07:53,908 - INFO - [vector_store_client.py:514] - Found collections: ['knowledge_chunks', 'schema_metadata']
2025-08-09 12:07:53,908 - INFO - [vector_db_routes.py:256] - GET_COLLECTION_DATA: Available collections: ['knowledge_chunks', 'schema_metadata']
2025-08-09 12:07:53,909 - INFO - [vector_db_routes.py:257] - GET_COLLECTION_DATA: Looking for collection: schema_metadata
2025-08-09 12:07:53,920 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:53] "GET /admin/api/vector-db/collections/schema_metadata/data?limit=20&offset=0 HTTP/1.1" 200 -
2025-08-09 12:07:58,867 - INFO - [vector_db_routes.py:244] - GET_COLLECTION_DATA: Requesting data for collection schema_metadata
2025-08-09 12:07:58,876 - INFO - [vector_store_client.py:514] - Found collections: ['knowledge_chunks', 'schema_metadata']
2025-08-09 12:07:58,876 - INFO - [vector_db_routes.py:256] - GET_COLLECTION_DATA: Available collections: ['knowledge_chunks', 'schema_metadata']
2025-08-09 12:07:58,876 - INFO - [vector_db_routes.py:257] - GET_COLLECTION_DATA: Looking for collection: schema_metadata
2025-08-09 12:07:58,889 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:07:58] "GET /admin/api/vector-db/collections/schema_metadata/data?limit=20&offset=20 HTTP/1.1" 200 -
2025-08-09 12:08:57,171 - DEBUG - [app.py:163] - Main page requested
2025-08-09 12:08:57,173 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:08:57] "GET / HTTP/1.1" 200 -
2025-08-09 12:08:57,233 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-09 12:08:57,240 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:08:57] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-09 12:09:04,702 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:09:04] "GET /knowledge HTTP/1.1" 200 -
2025-08-09 12:09:04,747 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-09 12:09:04,757 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:09:04] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-09 12:09:04,757 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:09:04] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-09 12:09:05,604 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:09:05] "GET /agent HTTP/1.1" 200 -
2025-08-09 12:09:05,640 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:09:05] "GET /static/js/tool-confirmation.js HTTP/1.1" 200 -
2025-08-09 12:09:05,642 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:09:05] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-09 12:09:05,653 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-09 12:09:05,663 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:09:05] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-09 12:09:05,667 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:09:05] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-09 12:09:15,588 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-09 12:09:15,588 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:09:15,588 - INFO - [llm_engine.py:31] - Using model: gemma-3-27b-it
2025-08-09 12:09:15,620 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:09:15,620 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-09 12:09:15,620 - INFO - [llm_engine.py:128] - [MCP-ServerSelection] Completion generation started (format: openai)
2025-08-09 12:09:15,620 - INFO - [llm_engine.py:193] - [MCP-ServerSelection] Prompt: [{'role': 'system', 'content': "You are a server selection assistant. Respond ONLY with the ID of the best server for the user's query."}, {'role': 'user', 'content': 'Select the most appropriate MCP server for this query: \n\nQuery: count of records from customer table\n\nAvailable servers:\n[\n  {\n    "id": 6,\n    "name": "Data Mapping Analyst",\n    "description": "Data mapping analyst",\n    "tools": ""\n  },\n  {\n    "id": 1,\n    "name": "dataengineer",\n    "description": "MCP server f... (truncated)
2025-08-09 12:09:15,621 - INFO - [llm_engine.py:197] - [MCP-ServerSelection] Sending request to gemma-3-27b-it with max_tokens=2000, temperature=0.7, stream=False
2025-08-09 12:09:15,621 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are a server selection assistant. Respond ONLY with the ID of the best server for the user's query."}, {'role': 'user', 'content': 'Select the most appropriate MCP server for this query: \n\nQuery: count of records from customer table\n\nAvailable servers:\n[\n  {\n    "id": 6,\n    "name": "Data Mapping Analyst",\n    "description": "Data mapping analyst",\n    "tools": ""\n  },\n  {\n    "id": 1,\n    "name": "dataengineer",\n    "description": "MCP server for data engineering tasks",\n    "tools": ""\n  }\n]\n\nRespond ONLY with the server ID number.'}]
2025-08-09 12:09:15,957 - ERROR - [llm_engine.py:263] - [MCP-ServerSelection] Completion generation error after 0.34s: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/llm_engine.py", line 237, in generate_completion
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 668, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1260, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 937, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
2025-08-09 12:09:15,958 - ERROR - [mcp_client_manager.py:1236] - Error selecting MCP server for query
Traceback (most recent call last):
  File "/home/vijay/gitrepo/text2sql/src/utils/mcp_client_manager.py", line 1208, in select_server_for_query
    response = llm_engine.generate_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/text2sql/src/utils/llm_engine.py", line 237, in generate_completion
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 668, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1260, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 937, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-27b-it', 'status': 'INVALID_ARGUMENT'}}]
2025-08-09 12:09:15,961 - INFO - [mcp_client_manager.py:261] - Connecting to HTTP MCP server: Data Mapping Analyst at http://localhost:8003/sse
2025-08-09 12:09:15,961 - INFO - [mcp_client_manager.py:267] - Creating SSE client for http://localhost:8003/sse
2025-08-09 12:09:15,961 - INFO - [mcp_client_manager.py:271] - Entering SSE client async context
2025-08-09 12:09:16,204 - ERROR - [mcp_client_manager.py:275] - Error connecting to SSE endpoint: http://localhost:8003/sse - unhandled errors in a TaskGroup (1 sub-exception)
2025-08-09 12:12:12,927 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-09 12:12:12,928 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-09 12:12:12,928 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:12:12,929 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-09 12:12:12,929 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:12:12,930 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-09 12:12:12,930 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:12:12,931 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-09 12:12:12,931 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:12:12,932 - INFO - [database.py:294] - Closing database connection
2025-08-09 12:12:12,933 - INFO - [database.py:297] - Database engine disposed
2025-08-09 12:12:12,933 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-09 12:12:12,934 - DEBUG - [feedback_manager.py:788] - SQLite database engine disposed
2025-08-09 12:12:12,934 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-09 12:12:12,936 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-09 12:12:12,936 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-09 12:12:12,936 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:12:12,937 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-09 12:12:12,937 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:12:12,937 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-09 12:12:12,938 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:12:12,939 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-09 12:12:12,940 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:12:12,940 - INFO - [database.py:294] - Closing database connection
2025-08-09 12:12:12,940 - INFO - [database.py:297] - Database engine disposed
2025-08-09 12:12:12,941 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-09 12:12:12,941 - DEBUG - [feedback_manager.py:788] - SQLite database engine disposed
2025-08-09 12:12:12,941 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-09 12:12:16,267 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:16,268 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:16,268 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:16,268 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:16,269 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:12:19,403 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-09 12:12:19,406 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:19,406 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:19,434 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:19,434 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:19,434 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:19,434 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:19,435 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:19,435 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:19,435 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:19,461 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:19,461 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:19,461 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:19,462 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:19,462 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:19,462 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:19,462 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:19,488 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:19,489 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:19,489 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:19,489 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:19,489 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:19,489 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-09 12:12:19,489 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:19,489 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:19,515 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:19,515 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-09 12:12:19,516 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:12:19,516 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:19,516 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:19,516 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:19,516 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:19,516 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:12:19,521 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-09 12:12:19,535 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-09 12:12:19,537 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-09 12:12:19,538 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-09 12:12:19,566 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:19,566 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:19,594 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:19,594 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:19,594 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:19,595 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:19,595 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:19,595 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:19,595 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:19,620 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:19,621 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:19,621 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:19,621 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:19,621 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:19,621 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:19,621 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:19,647 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:19,647 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:19,647 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:19,648 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:19,648 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:19,648 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-09 12:12:19,648 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:19,648 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:19,675 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:19,675 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-09 12:12:19,675 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:12:19,675 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:12:19,676 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:12:19,676 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:12:19,676 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:12:19,676 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:12:19,697 - INFO - [app.py:727] - Initializing application-wide components
2025-08-09 12:12:19,699 - INFO - [app.py:61] - Successfully started MCP server: Data Mapping Analyst
2025-08-09 12:12:19,700 - INFO - [app.py:61] - Successfully started MCP server: dataengineer
2025-08-09 12:12:19,700 - INFO - [app.py:729] - Application-wide components initialization complete
2025-08-09 12:12:19,701 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-09 12:12:19,701 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-09 12:12:23,898 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-09 12:12:23,904 - DEBUG - [app.py:163] - Main page requested
2025-08-09 12:12:23,918 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:23] "GET / HTTP/1.1" 200 -
2025-08-09 12:12:24,025 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-09 12:12:24,036 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:24] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-09 12:12:25,592 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-09 12:12:25,599 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:25] "GET /api/tables/suggestions?workspace=dfd&query= HTTP/1.1" 200 -
2025-08-09 12:12:28,861 - INFO - [app.py:185] - User explicitly specified tables: customers
2025-08-09 12:12:28,862 - INFO - [sql_generator.py:37] - Processing query: 'table customers  count'
2025-08-09 12:12:28,862 - INFO - [sql_generator.py:40] - User explicitly selected tables: customers
2025-08-09 12:12:28,863 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:28] "POST /api/query HTTP/1.1" 200 -
2025-08-09 12:12:28,863 - INFO - [intent_agent.py:27] - Intent detection started for query: 'table customers  count'
2025-08-09 12:12:28,864 - INFO - [intent_agent.py:38] - Using default intent 'data_retrieval' without calling LLM
2025-08-09 12:12:28,864 - INFO - [intent_agent.py:41] - Intent detection completed in 0.00s
2025-08-09 12:12:28,864 - INFO - [sql_generator.py:45] - Detected intent: data_retrieval
2025-08-09 12:12:28,864 - INFO - [sql_generator.py:141] - Starting SQL generation process
2025-08-09 12:12:28,864 - INFO - [database.py:80] - Attempting database connection
2025-08-09 12:12:28,865 - INFO - [database.py:84] - Database connection established in 0.00s
2025-08-09 12:12:28,866 - INFO - [column_agent.py:29] - Column pruning started for query: 'table customers  count'
2025-08-09 12:12:28,867 - INFO - [column_agent.py:30] - Processing tables: customers
2025-08-09 12:12:28,867 - INFO - [column_agent.py:38] - Only one table involved (customers). Skipping LLM call and including all columns.
2025-08-09 12:12:28,867 - INFO - [feedback_manager.py:250] - Stage 1: Vector search for 'table customers  count...'
2025-08-09 12:12:28,868 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:12:28,868 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:12:28,902 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:12:28,902 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-09 12:12:29,376 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:29] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:29,881 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:29] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:30,373 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:30] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:30,898 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:30] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:31,376 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:31] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:31,382 - INFO - [llm_engine.py:59] - Embedding model loaded in 2.48s
2025-08-09 12:12:31,408 - INFO - [llm_engine.py:85] - Generated embedding in 0.03s with shape (384,)
2025-08-09 12:12:31,414 - INFO - [feedback_manager.py:275] - No candidates found from vector search, falling back to text-based search
2025-08-09 12:12:31,414 - INFO - [feedback_manager.py:49] - Attempting database connection
2025-08-09 12:12:31,415 - INFO - [feedback_manager.py:53] - Database connection established in 0.00s
2025-08-09 12:12:31,415 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-09 12:12:31,417 - INFO - [vector_store_client.py:44] - ChromaDB service connection established in 0.00s
2025-08-09 12:12:31,419 - INFO - [feedback_manager.py:415] - Found 1 similar queries using text-based search for 'table customers  count...'
2025-08-09 12:12:31,419 - INFO - [sql_generator.py:280] - Found 1 similar queries with reranking
2025-08-09 12:12:31,419 - INFO - [sql_generator.py:302] - Added similar query #1 from feedback (score: 0.0000): get me count of customers by their state...
2025-08-09 12:12:31,419 - INFO - [azure_client.py:35] - SQL generation started for query: 'table customers  count'
2025-08-09 12:12:31,419 - INFO - [azure_client.py:69] - Including schema information (587 chars)
2025-08-09 12:12:31,420 - INFO - [azure_client.py:97] - Including 1 SQL examples from feedback similarity search
2025-08-09 12:12:31,420 - INFO - [azure_client.py:114] - PROMPT: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: get me count of customers by their state\nSQL: SELECT \n    state,\n    COUNT(customer_id) AS customer_count\nFROM customers\nGROUP BY state\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers  count'}]
2025-08-09 12:12:31,420 - INFO - [llm_engine.py:128] - [SQL_GEN] Completion generation started (format: openai)
2025-08-09 12:12:31,421 - INFO - [llm_engine.py:193] - [SQL_GEN] Prompt: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief ... (truncated)
2025-08-09 12:12:31,421 - INFO - [llm_engine.py:197] - [SQL_GEN] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-09 12:12:31,421 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: get me count of customers by their state\nSQL: SELECT \n    state,\n    COUNT(customer_id) AS customer_count\nFROM customers\nGROUP BY state\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers  count'}]
2025-08-09 12:12:31,898 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:31] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:32,175 - INFO - [llm_engine.py:245] - [SQL_GEN] Model response received in 0.75s
2025-08-09 12:12:32,176 - INFO - [llm_engine.py:254] - [SQL_GEN] Raw model response: 'Here's a query that counts the total number of customers.

```sql
SELECT 
    COUNT(customer_id) AS total_customers
FROM customers;
```'
2025-08-09 12:12:32,176 - INFO - [llm_engine.py:257] - [SQL_GEN] Completion generation completed in 0.76s
2025-08-09 12:12:32,176 - INFO - [llm_engine.py:258] - **************************
2025-08-09 12:12:32,176 - INFO - [azure_client.py:150] - Parsing SQL from model response
2025-08-09 12:12:32,176 - INFO - [azure_client.py:157] - Found SQL code block in response
2025-08-09 12:12:32,176 - INFO - [azure_client.py:171] - Extracted SQL query (65 chars) and explanation (57 chars)
2025-08-09 12:12:32,176 - INFO - [azure_client.py:124] - Generated SQL: SELECT 
    COUNT(customer_id) AS total_customers
FROM customers;
2025-08-09 12:12:32,177 - INFO - [azure_client.py:132] - SQL generation completed in 0.76s
2025-08-09 12:12:32,177 - INFO - [database.py:101] - Executing SQL query: SELECT 
    COUNT(customer_id) AS total_customers
FROM customers;
2025-08-09 12:12:32,177 - INFO - [database.py:112] - Query execution started
2025-08-09 12:12:32,178 - INFO - [database.py:117] - Query execution completed in 0.00s
2025-08-09 12:12:32,179 - INFO - [database.py:122] - Query returned 1 rows with 1 columns
2025-08-09 12:12:32,179 - INFO - [database.py:131] - Query processing completed in 0.00s
2025-08-09 12:12:32,181 - INFO - [sql_generator.py:348] - Analyzing query results for dashboard potential
2025-08-09 12:12:32,181 - INFO - [azure_client.py:197] - Dashboard analysis started for query: 'table customers  count'
2025-08-09 12:12:32,181 - INFO - [llm_engine.py:128] - [DASHBOARD_ANALYSIS] Completion generation started (format: openai)
2025-08-09 12:12:32,181 - INFO - [llm_engine.py:193] - [DASHBOARD_ANALYSIS] Prompt: [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axi... (truncated)
2025-08-09 12:12:32,182 - INFO - [llm_engine.py:197] - [DASHBOARD_ANALYSIS] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-09 12:12:32,182 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axis\n5. Suggest meaningful labels and title\n\nReturn your analysis in JSON format exactly like this:\n{\n  "is_suitable": true_or_false,\n  "reason": "brief explanation of why it is or isn\'t suitable",\n  "chart_type": "recommended chart type if suitable",\n  "x_axis": {\n    "column": "column_name for x-axis",\n    "label": "suggested x-axis label"\n  },\n  "y_axis": {\n    "column": "column_name for y-axis",\n    "label": "suggested y-axis label"\n  },\n  "title": "suggested chart title"\n}\n\nMake decisions based on these criteria:\n- Bar charts are good for comparing categories\n- Line charts are good for time series \n- Pie charts are good for part-to-whole relationships (under 7 categories)\n- Scatter plots are good for showing relationships between numeric values\n- Data needs at least one numeric column for most visualizations'}, {'role': 'user', 'content': 'Query: table customers  count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\nColumns: total_customers\nData Sample:\nRow 1: {"total_customers": 4}\n\n\nAnalyze if this data is suitable for a dashboard visualization. If so, provide recommendations in the required JSON format.'}]
2025-08-09 12:12:32,385 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:32] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:32,873 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:32] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:33,376 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:33] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:12:33,482 - INFO - [llm_engine.py:245] - [DASHBOARD_ANALYSIS] Model response received in 1.30s
2025-08-09 12:12:33,483 - INFO - [llm_engine.py:254] - [DASHBOARD_ANALYSIS] Raw model response: '```json
{
  "is_suitable": true,
  "reason": "The data contains a single numeric value representing the total number of customers, which can be visualized to provide a quick overview.",
  "chart_type": "Number",
  "x_axis": {
    "column": null,
    "label": null
  },
  "y_axis": {
    "column": "total_customers",
    "label": "Total Customers"
  },
  "title": "Total Customers"
}
```'
2025-08-09 12:12:33,483 - INFO - [llm_engine.py:257] - [DASHBOARD_ANALYSIS] Completion generation completed in 1.30s
2025-08-09 12:12:33,483 - INFO - [llm_engine.py:258] - **************************
2025-08-09 12:12:33,483 - INFO - [azure_client.py:255] - Dashboard analysis results: suitable=True
2025-08-09 12:12:33,484 - INFO - [azure_client.py:264] - Dashboard analysis completed in 1.30s
2025-08-09 12:12:33,484 - INFO - [sql_generator.py:366] - Dashboard analysis completed: suitable=True
2025-08-09 12:12:33,484 - INFO - [sql_generator.py:444] - SQL generation completed in 4.62s
2025-08-09 12:12:33,484 - INFO - [sql_generator.py:125] - Query processing completed in 4.62s
2025-08-09 12:12:33,897 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:12:33] "GET /api/query/progress/67ed228b-c2de-4a99-aaa9-0e84e1eafbe6 HTTP/1.1" 200 -
2025-08-09 12:13:21,770 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:21] "GET /knowledge HTTP/1.1" 200 -
2025-08-09 12:13:21,802 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:21] "[36mGET /static/js/knowledge-base.js HTTP/1.1[0m" 304 -
2025-08-09 12:13:21,839 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-09 12:13:21,863 - INFO - [knowledge_manager.py:33] - Initializing Knowledge Manager
2025-08-09 12:13:21,864 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:21] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-09 12:13:21,896 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-09 12:13:21,899 - INFO - [vector_store_client.py:44] - ChromaDB service connection established in 0.00s
2025-08-09 12:13:21,903 - INFO - [vector_store_client.py:121] - Collection 'knowledge_chunks' already exists
2025-08-09 12:13:21,903 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:13:21,904 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:13:21,937 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:13:21,938 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:21] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-09 12:13:23,351 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:23] "GET /agent HTTP/1.1" 200 -
2025-08-09 12:13:23,387 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:23] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-09 12:13:23,391 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:23] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-09 12:13:23,401 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-09 12:13:23,405 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:23] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-09 12:13:23,413 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:23] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-09 12:13:32,614 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-09 12:13:32,615 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:13:32,615 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:13:32,655 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:13:32,656 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-09 12:13:32,656 - INFO - [llm_engine.py:128] - [MCP-ServerSelection] Completion generation started (format: openai)
2025-08-09 12:13:32,656 - INFO - [llm_engine.py:193] - [MCP-ServerSelection] Prompt: [{'role': 'system', 'content': "You are a server selection assistant. Respond ONLY with the ID of the best server for the user's query."}, {'role': 'user', 'content': 'Select the most appropriate MCP server for this query: \n\nQuery: get me count of records from customers table\n\nAvailable servers:\n[\n  {\n    "id": 6,\n    "name": "Data Mapping Analyst",\n    "description": "Data mapping analyst",\n    "tools": ""\n  },\n  {\n    "id": 1,\n    "name": "dataengineer",\n    "description": "MCP ... (truncated)
2025-08-09 12:13:32,656 - INFO - [llm_engine.py:197] - [MCP-ServerSelection] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-09 12:13:32,656 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are a server selection assistant. Respond ONLY with the ID of the best server for the user's query."}, {'role': 'user', 'content': 'Select the most appropriate MCP server for this query: \n\nQuery: get me count of records from customers table\n\nAvailable servers:\n[\n  {\n    "id": 6,\n    "name": "Data Mapping Analyst",\n    "description": "Data mapping analyst",\n    "tools": ""\n  },\n  {\n    "id": 1,\n    "name": "dataengineer",\n    "description": "MCP server for data engineering tasks",\n    "tools": ""\n  }\n]\n\nRespond ONLY with the server ID number.'}]
2025-08-09 12:13:33,240 - INFO - [llm_engine.py:245] - [MCP-ServerSelection] Model response received in 0.58s
2025-08-09 12:13:33,240 - INFO - [llm_engine.py:254] - [MCP-ServerSelection] Raw model response: '1
'
2025-08-09 12:13:33,240 - INFO - [llm_engine.py:257] - [MCP-ServerSelection] Completion generation completed in 0.58s
2025-08-09 12:13:33,241 - INFO - [llm_engine.py:258] - **************************
2025-08-09 12:13:33,242 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:13:33,242 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:13:33,242 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:13:33,251 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:13:33,252 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:13:33,252 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:13:33,252 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:13:34,019 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:13:34,025 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:13:34,046 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:13:34] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-09 12:13:34,047 - INFO - [agent_routes.py:112] - Processing query with 1 previous messages for context
2025-08-09 12:13:34,047 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-09 12:13:34,047 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:13:34,055 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:13:34,055 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:13:34,055 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:13:34,055 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:13:34,056 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:13:34,056 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:13:34,057 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:13:34,057 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:13:34,057 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:13:34,057 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:13:34,774 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:13:34,779 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:13:34,779 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-09 12:13:34,779 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: get me count of records from customers table
2025-08-09 12:13:34,780 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-09 12:13:34,780 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. I'll help you solve tasks by using tools and accessing resources. You can ask follow-up questions, and I'll maintain context from our conversation. How can I help you today?"}, {'role': 'user', 'content': 'get me count of records from customers table'}]
2025-08-09 12:13:34,780 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (1 previous messages)
2025-08-09 12:13:34,781 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-09 12:13:34,781 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:13:34,781 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:13:34,781 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:13:34,781 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:13:35,502 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.72s
2025-08-09 12:13:35,503 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-09 12:13:35,504 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.72s
2025-08-09 12:13:35,504 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:13:35,505 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='None', has_tool_calls=True
2025-08-09 12:13:35,505 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 1/5)
2025-08-09 12:13:35,506 - INFO - [mcp_client_manager.py:519] - Calling tool 'get_table_row_count' with args: {'table_name': 'customers'}
2025-08-09 12:13:35,506 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling get_table_row_count via MCP session
2025-08-09 12:13:35,520 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: get_table_row_count completed successfully
2025-08-09 12:13:35,520 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-09 12:13:35,521 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:13:35,521 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:13:35,521 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:13:35,522 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:13:36,425 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.90s
2025-08-09 12:13:36,425 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'I encountered an error while trying to get the row count from the 'customers' table. It seems like the table does not exist.
'
2025-08-09 12:13:36,425 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.90s
2025-08-09 12:13:36,425 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:13:36,425 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='I encountered an error while trying to get the row count from the 'customers' table. It seems like the table does not exist.
', has_tool_calls=False
2025-08-09 12:13:36,425 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': "I encountered an error while trying to get the row count from the 'customers' table. It seems like the table does not exist.\n"}
2025-08-09 12:13:36,426 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-09 12:13:36,426 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-09 12:13:36,426 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:13:36,436 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:13:36,436 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:13:36,436 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:13:36,437 - INFO - [agent_routes.py:250] - Agent audit - Collected 8 response parts
2025-08-09 12:13:36,437 - DEBUG - [agent_routes.py:251] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | STATUS: Processing tool results... | LLM_RESPONSE: I encountered an error while trying to get the row count from the 'customers' table. It seems like the table does not exist.
 | FALLBACK_llm_response: I encountered an error while trying to get the row count from the 'customers' table. It seems like the table does not exist.
 | STATUS: Processing complete. |...
2025-08-09 12:14:40,806 - INFO - [llm_engine.py:128] - [MCP-ServerSelection] Completion generation started (format: openai)
2025-08-09 12:14:40,807 - INFO - [llm_engine.py:193] - [MCP-ServerSelection] Prompt: [{'role': 'system', 'content': "You are a server selection assistant. Respond ONLY with the ID of the best server for the user's query."}, {'role': 'user', 'content': 'Select the most appropriate MCP server for this query: \n\nQuery: how about customer\n\nAvailable servers:\n[\n  {\n    "id": 6,\n    "name": "Data Mapping Analyst",\n    "description": "Data mapping analyst",\n    "tools": ""\n  },\n  {\n    "id": 1,\n    "name": "dataengineer",\n    "description": "MCP server for data engineerin... (truncated)
2025-08-09 12:14:40,807 - INFO - [llm_engine.py:197] - [MCP-ServerSelection] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-09 12:14:40,808 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are a server selection assistant. Respond ONLY with the ID of the best server for the user's query."}, {'role': 'user', 'content': 'Select the most appropriate MCP server for this query: \n\nQuery: how about customer\n\nAvailable servers:\n[\n  {\n    "id": 6,\n    "name": "Data Mapping Analyst",\n    "description": "Data mapping analyst",\n    "tools": ""\n  },\n  {\n    "id": 1,\n    "name": "dataengineer",\n    "description": "MCP server for data engineering tasks",\n    "tools": ""\n  }\n]\n\nRespond ONLY with the server ID number.'}]
2025-08-09 12:14:41,424 - INFO - [llm_engine.py:245] - [MCP-ServerSelection] Model response received in 0.62s
2025-08-09 12:14:41,425 - INFO - [llm_engine.py:254] - [MCP-ServerSelection] Raw model response: '6
'
2025-08-09 12:14:41,425 - INFO - [llm_engine.py:257] - [MCP-ServerSelection] Completion generation completed in 0.62s
2025-08-09 12:14:41,426 - INFO - [llm_engine.py:258] - **************************
2025-08-09 12:14:41,429 - INFO - [mcp_client_manager.py:261] - Connecting to HTTP MCP server: Data Mapping Analyst at http://localhost:8003/sse
2025-08-09 12:14:41,431 - INFO - [mcp_client_manager.py:267] - Creating SSE client for http://localhost:8003/sse
2025-08-09 12:14:41,431 - INFO - [mcp_client_manager.py:271] - Entering SSE client async context
2025-08-09 12:14:41,482 - ERROR - [mcp_client_manager.py:275] - Error connecting to SSE endpoint: http://localhost:8003/sse - unhandled errors in a TaskGroup (1 sub-exception)
2025-08-09 12:15:03,477 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:15:03] "GET /agent HTTP/1.1" 200 -
2025-08-09 12:15:03,527 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-09 12:15:03,534 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:15:03] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-09 12:15:03,539 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:15:03] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-09 12:15:11,754 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:15:11,754 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:15:11,755 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:15:11,757 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:15:11,758 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:15:11,759 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:15:11,759 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:15:12,549 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:15:12,556 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:15:12,575 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:15:12] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-09 12:15:12,575 - INFO - [agent_routes.py:112] - Processing query with 1 previous messages for context
2025-08-09 12:15:12,576 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-09 12:15:12,576 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:15:12,589 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:15:12,589 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:15:12,589 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:15:12,589 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:15:12,589 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:15:12,590 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:15:12,591 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:15:12,591 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:15:12,592 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:15:12,592 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:15:13,418 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:15:13,424 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:15:13,425 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-09 12:15:13,425 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: get me count of customers
2025-08-09 12:15:13,425 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-09 12:15:13,425 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. I'll help you solve tasks by using tools and accessing resources. You can ask follow-up questions, and I'll maintain context from our conversation. How can I help you today?"}, {'role': 'user', 'content': 'get me count of customers'}]
2025-08-09 12:15:13,426 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (1 previous messages)
2025-08-09 12:15:13,426 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-09 12:15:13,426 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:15:13,426 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:15:13,426 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:15:13,427 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:15:14,106 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.68s
2025-08-09 12:15:14,106 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-09 12:15:14,106 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.68s
2025-08-09 12:15:14,106 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:15:14,107 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='None', has_tool_calls=True
2025-08-09 12:15:14,107 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 1/5)
2025-08-09 12:15:14,107 - INFO - [mcp_client_manager.py:519] - Calling tool 'get_table_row_count' with args: {'table_name': 'customers'}
2025-08-09 12:15:14,107 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling get_table_row_count via MCP session
2025-08-09 12:15:14,113 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: get_table_row_count completed successfully
2025-08-09 12:15:14,113 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-09 12:15:14,114 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:15:14,114 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:15:14,114 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:15:14,114 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:15:15,154 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 1.04s
2025-08-09 12:15:15,154 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.
'
2025-08-09 12:15:15,154 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 1.04s
2025-08-09 12:15:15,154 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:15:15,155 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.
', has_tool_calls=False
2025-08-09 12:15:15,155 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': "I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.\n"}
2025-08-09 12:15:15,155 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-09 12:15:15,155 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-09 12:15:15,155 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:15:15,165 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:15:15,166 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:15:15,166 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:15:15,166 - INFO - [agent_routes.py:250] - Agent audit - Collected 8 response parts
2025-08-09 12:15:15,166 - DEBUG - [agent_routes.py:251] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | STATUS: Processing tool results... | LLM_RESPONSE: I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.
 | FALLBACK_llm_response: I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.
 | STATUS: Processing complete. | STATUS: Agent p...
2025-08-09 12:15:38,937 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:15:38,937 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:15:38,937 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:15:38,940 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:15:38,940 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:15:38,941 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:15:38,941 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:15:39,704 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:15:39,711 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:15:39,717 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:15:39] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-09 12:15:39,717 - INFO - [agent_routes.py:112] - Processing query with 3 previous messages for context
2025-08-09 12:15:39,717 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-09 12:15:39,718 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:15:39,727 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:15:39,727 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:15:39,727 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:15:39,727 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:15:39,727 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:15:39,727 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:15:39,728 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:15:39,728 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:15:39,729 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:15:39,729 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:15:40,444 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:15:40,449 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:15:40,450 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-09 12:15:40,450 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: how about name customer
2025-08-09 12:15:40,450 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-09 12:15:40,450 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. I'll help you solve tasks by using tools and accessing resources. You can ask follow-up questions, and I'll maintain context from our conversation. How can I help you today?"}, {'role': 'user', 'content': 'get me count of customers'}, {'role': 'assistant', 'content': "I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.\n"}, {'role': 'user', 'content': 'how about name customer'}]
2025-08-09 12:15:40,450 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (3 previous messages)
2025-08-09 12:15:40,450 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-09 12:15:40,451 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:15:40,451 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:15:40,451 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:15:40,451 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:15:41,139 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.69s
2025-08-09 12:15:41,139 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'I am sorry, but I was not able to retrieve the row count for the 'customer' table because the table does not exist.
'
2025-08-09 12:15:41,139 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.69s
2025-08-09 12:15:41,139 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:15:41,140 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='I am sorry, but I was not able to retrieve the row count for the 'customer' table because the table does not exist.
', has_tool_calls=False
2025-08-09 12:15:41,140 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': "I am sorry, but I was not able to retrieve the row count for the 'customer' table because the table does not exist.\n"}
2025-08-09 12:15:41,140 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-09 12:15:41,141 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-09 12:15:41,141 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:15:41,153 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:15:41,154 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:15:41,154 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:15:41,154 - INFO - [agent_routes.py:250] - Agent audit - Collected 7 response parts
2025-08-09 12:15:41,154 - DEBUG - [agent_routes.py:251] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | LLM_RESPONSE: I am sorry, but I was not able to retrieve the row count for the 'customer' table because the table does not exist.
 | FALLBACK_llm_response: I am sorry, but I was not able to retrieve the row count for the 'customer' table because the table does not exist.
 | STATUS: Processing complete. | STATUS: Agent processing completed....
2025-08-09 12:16:51,768 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:16:51,768 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:16:51,769 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:16:51,771 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:16:51,772 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:16:51,772 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:16:51,772 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:16:52,567 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:16:52,574 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:16:52,592 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:16:52] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-09 12:16:52,592 - INFO - [agent_routes.py:112] - Processing query with 4 previous messages for context
2025-08-09 12:16:52,593 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-09 12:16:52,593 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:16:52,602 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:16:52,602 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:16:52,602 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:16:52,603 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:16:52,603 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:16:52,603 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:16:52,604 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:16:52,604 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:16:52,604 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:16:52,605 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:16:53,324 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:16:53,330 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:16:53,330 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-09 12:16:53,330 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: use the tools given to you and find me count of customers
2025-08-09 12:16:53,330 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-09 12:16:53,331 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. I'll help you solve tasks by using tools and accessing resources. You can ask follow-up questions, and I'll maintain context from our conversation. How can I help you today?"}, {'role': 'user', 'content': 'get me count of customers'}, {'role': 'user', 'content': 'how about name customer'}, {'role': 'assistant', 'content': "I am sorry, but I was not able to retrieve the row count for the 'customer' table because the table does not exist.\n"}, {'role': 'user', 'content': 'use the tools given to you and find me count of customers'}]
2025-08-09 12:16:53,331 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (4 previous messages)
2025-08-09 12:16:53,331 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-09 12:16:53,331 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:16:53,332 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:16:53,332 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:16:53,332 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:16:54,586 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 1.25s
2025-08-09 12:16:54,587 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-09 12:16:54,587 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 1.26s
2025-08-09 12:16:54,588 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:16:54,588 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='None', has_tool_calls=True
2025-08-09 12:16:54,589 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 1/5)
2025-08-09 12:16:54,589 - INFO - [mcp_client_manager.py:519] - Calling tool 'get_table_row_count' with args: {'table_name': 'customers'}
2025-08-09 12:16:54,590 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling get_table_row_count via MCP session
2025-08-09 12:16:54,603 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: get_table_row_count completed successfully
2025-08-09 12:16:54,604 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-09 12:16:54,604 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:16:54,605 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:16:54,605 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:16:54,605 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:16:55,226 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.62s
2025-08-09 12:16:55,227 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.
'
2025-08-09 12:16:55,227 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.62s
2025-08-09 12:16:55,227 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:16:55,227 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.
', has_tool_calls=False
2025-08-09 12:16:55,227 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': "I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.\n"}
2025-08-09 12:16:55,228 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-09 12:16:55,228 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-09 12:16:55,228 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:16:55,238 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:16:55,238 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:16:55,238 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:16:55,239 - INFO - [agent_routes.py:250] - Agent audit - Collected 8 response parts
2025-08-09 12:16:55,239 - DEBUG - [agent_routes.py:251] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | STATUS: Processing tool results... | LLM_RESPONSE: I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.
 | FALLBACK_llm_response: I am sorry, but I was not able to retrieve the row count for the 'customers' table because the table does not exist.
 | STATUS: Processing complete. | STATUS: Agent p...
2025-08-09 12:17:37,480 - DEBUG - [mcp_client_manager.py:606] - Cleanup for dataengineer skipped - already cleaned up
2025-08-09 12:17:37,480 - DEBUG - [mcp_client_manager.py:606] - Cleanup for dataengineer skipped - already cleaned up
2025-08-09 12:17:37,480 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-09 12:17:37,481 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-09 12:17:37,481 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:17:37,481 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-09 12:17:37,482 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:17:37,482 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-09 12:17:37,482 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:17:37,482 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-09 12:17:37,483 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:17:37,483 - INFO - [database.py:294] - Closing database connection
2025-08-09 12:17:37,483 - INFO - [database.py:297] - Database engine disposed
2025-08-09 12:17:37,484 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-09 12:17:37,484 - DEBUG - [feedback_manager.py:788] - SQLite database engine disposed
2025-08-09 12:17:37,484 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-09 12:17:37,485 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-09 12:17:37,485 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-09 12:17:37,486 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:17:37,486 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-09 12:17:37,486 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:17:37,486 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-09 12:17:37,487 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:17:37,487 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-09 12:17:37,487 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-09 12:17:37,487 - INFO - [database.py:294] - Closing database connection
2025-08-09 12:17:37,488 - INFO - [database.py:297] - Database engine disposed
2025-08-09 12:17:37,488 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-09 12:17:37,488 - DEBUG - [feedback_manager.py:788] - SQLite database engine disposed
2025-08-09 12:17:37,489 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-09 12:17:40,367 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:40,368 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:40,368 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:40,368 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:40,370 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:17:43,497 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-09 12:17:43,500 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:43,500 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:43,527 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:43,527 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:43,527 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:43,528 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:43,528 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:43,528 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:43,528 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:43,554 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:43,554 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:43,554 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:43,554 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:43,554 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:43,554 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:43,554 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:43,581 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:43,581 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:43,582 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:43,582 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:43,582 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:43,582 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-09 12:17:43,582 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:43,582 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:43,608 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:43,608 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-09 12:17:43,608 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:17:43,609 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:43,609 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:43,609 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:43,609 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:43,609 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:17:43,614 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-09 12:17:43,628 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-09 12:17:43,630 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-09 12:17:43,631 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-09 12:17:43,658 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:43,658 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:43,688 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:43,688 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:43,689 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:43,689 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:43,689 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:43,689 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:43,689 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:43,718 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:43,718 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:43,718 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:43,718 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:43,718 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:43,718 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:43,719 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:43,745 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:43,746 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:43,746 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:43,746 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:43,746 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:43,746 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-09 12:17:43,746 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:43,746 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:43,773 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:43,773 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-09 12:17:43,773 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:17:43,774 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/text2sql/config/data/schema.json
2025-08-09 12:17:43,774 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 12:17:43,774 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/text2sql/config/data/condition.json
2025-08-09 12:17:43,774 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 12:17:43,774 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 12:17:43,787 - INFO - [app.py:727] - Initializing application-wide components
2025-08-09 12:17:43,789 - INFO - [app.py:61] - Successfully started MCP server: Data Mapping Analyst
2025-08-09 12:17:43,789 - INFO - [app.py:61] - Successfully started MCP server: dataengineer
2025-08-09 12:17:43,789 - INFO - [app.py:729] - Application-wide components initialization complete
2025-08-09 12:17:43,791 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-09 12:17:43,791 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-09 12:17:52,278 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-09 12:17:52,298 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:17:52] "GET /agent HTTP/1.1" 200 -
2025-08-09 12:17:52,346 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-09 12:17:52,357 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:17:52] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-09 12:17:52,360 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:17:52] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-09 12:17:55,876 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-09 12:17:55,876 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-09 12:17:55,876 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-09 12:17:55,910 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-09 12:17:55,910 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-09 12:17:55,910 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:17:55,910 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:17:55,911 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:17:55,916 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:17:55,916 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:17:55,916 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:17:55,917 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:17:56,819 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:17:56,827 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:17:56,852 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:17:56] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-09 12:17:56,853 - INFO - [agent_routes.py:112] - Processing query with 1 previous messages for context
2025-08-09 12:17:56,853 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-09 12:17:56,853 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:17:56,863 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:17:56,863 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:17:56,863 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:17:56,864 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:17:56,864 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:17:56,864 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:17:56,865 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:17:56,865 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:17:56,866 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:17:56,866 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:17:57,607 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:17:57,612 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:17:57,613 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-09 12:17:57,613 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: use the tools given to you and find me count of customers
2025-08-09 12:17:57,613 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-09 12:17:57,613 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. I'll help you solve tasks by using tools and accessing resources. You can ask follow-up questions, and I'll maintain context from our conversation. How can I help you today?"}, {'role': 'user', 'content': 'use the tools given to you and find me count of customers'}]
2025-08-09 12:17:57,613 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (1 previous messages)
2025-08-09 12:17:57,613 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-09 12:17:57,614 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:17:57,614 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:17:57,614 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:17:57,614 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:17:58,763 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 1.15s
2025-08-09 12:17:58,764 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-09 12:17:58,764 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 1.15s
2025-08-09 12:17:58,765 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:17:58,765 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='None', has_tool_calls=True
2025-08-09 12:17:58,765 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 1/5)
2025-08-09 12:17:58,766 - INFO - [mcp_client_manager.py:519] - Calling tool 'get_table_row_count' with args: {'table_name': 'customers'}
2025-08-09 12:17:58,766 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling get_table_row_count via MCP session
2025-08-09 12:17:58,778 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: meta=None content=[TextContent(type='text', text='{"success": false, "table_name": "customers", "row_count": null, "errors": ["Database error counting rows for customers: no such table: customers"]}', annotations=None)] isError=False completed successfully
2025-08-09 12:17:58,779 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-09 12:17:58,779 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:17:58,780 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:17:58,780 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:17:58,780 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:17:59,741 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.96s
2025-08-09 12:17:59,741 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'I encountered an error: the table 'customers' does not exist.  I will now list the available tables to see what tables are available.
'
2025-08-09 12:17:59,742 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-09 12:17:59,743 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.96s
2025-08-09 12:17:59,743 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:17:59,744 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='I encountered an error: the table 'customers' does not exist.  I will now list the available tables to see what tables are available.
', has_tool_calls=True
2025-08-09 12:17:59,745 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': "I encountered an error: the table 'customers' does not exist.  I will now list the available tables to see what tables are available.\n"}
2025-08-09 12:17:59,746 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 2/5)
2025-08-09 12:17:59,746 - INFO - [mcp_client_manager.py:519] - Calling tool 'execute_sql_query' with args: {'query': "SELECT name FROM sqlite_master WHERE type='table';"}
2025-08-09 12:17:59,747 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling execute_sql_query via MCP session
2025-08-09 12:17:59,760 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: meta=None content=[TextContent(type='text', text='{"success": true, "data": [], "columns": ["name"], "errors": []}', annotations=None)] isError=False completed successfully
2025-08-09 12:17:59,761 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-09 12:17:59,761 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:17:59,762 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:17:59,762 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:17:59,762 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:18:00,324 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.56s
2025-08-09 12:18:00,324 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'There are no tables in the database.
'
2025-08-09 12:18:00,324 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.56s
2025-08-09 12:18:00,325 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:18:00,325 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='There are no tables in the database.
', has_tool_calls=False
2025-08-09 12:18:00,326 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': 'There are no tables in the database.\n'}
2025-08-09 12:18:00,326 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-09 12:18:00,327 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-09 12:18:00,327 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:18:00,343 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:18:00,343 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:18:00,343 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:18:00,344 - INFO - [agent_routes.py:250] - Agent audit - Collected 11 response parts
2025-08-09 12:18:00,344 - DEBUG - [agent_routes.py:251] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | STATUS: Processing tool results... | LLM_RESPONSE: I encountered an error: the table 'customers' does not exist.  I will now list the available tables to see what tables are available.
 | FALLBACK_llm_response: I encountered an error: the table 'customers' does not exist.  I will now list the available tables to see what tables are available.
 | STATUS: Proc...
2025-08-09 12:19:00,289 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:19:00,289 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:19:00,290 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:19:00,292 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:19:00,292 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:19:00,292 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:19:00,292 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:19:01,132 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:19:01,137 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:19:01,144 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:19:01] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-09 12:19:01,144 - INFO - [agent_routes.py:112] - Processing query with 3 previous messages for context
2025-08-09 12:19:01,145 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-09 12:19:01,145 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:19:01,154 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:19:01,155 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:19:01,155 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:19:01,155 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:19:01,155 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:19:01,155 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:19:01,156 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:19:01,156 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:19:01,157 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:19:01,157 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:19:01,911 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:19:01,917 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:19:01,917 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-09 12:19:01,918 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: get me list of tables
2025-08-09 12:19:01,918 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-09 12:19:01,918 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. I'll help you solve tasks by using tools and accessing resources. You can ask follow-up questions, and I'll maintain context from our conversation. How can I help you today?"}, {'role': 'user', 'content': 'use the tools given to you and find me count of customers'}, {'role': 'assistant', 'content': 'There are no tables in the database.\n'}, {'role': 'user', 'content': 'get me list of tables'}]
2025-08-09 12:19:01,918 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (3 previous messages)
2025-08-09 12:19:01,918 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-09 12:19:01,919 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:19:01,919 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:19:01,919 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:19:01,919 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:19:02,595 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.68s
2025-08-09 12:19:02,596 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'I am sorry, I can't list tables. I can only get the row count of a table if you provide the table name.
'
2025-08-09 12:19:02,597 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.68s
2025-08-09 12:19:02,597 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:19:02,598 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='I am sorry, I can't list tables. I can only get the row count of a table if you provide the table name.
', has_tool_calls=False
2025-08-09 12:19:02,598 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': "I am sorry, I can't list tables. I can only get the row count of a table if you provide the table name.\n"}
2025-08-09 12:19:02,600 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-09 12:19:02,600 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-09 12:19:02,600 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:19:02,620 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:19:02,620 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:19:02,620 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:19:02,621 - INFO - [agent_routes.py:250] - Agent audit - Collected 7 response parts
2025-08-09 12:19:02,621 - DEBUG - [agent_routes.py:251] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | LLM_RESPONSE: I am sorry, I can't list tables. I can only get the row count of a table if you provide the table name.
 | FALLBACK_llm_response: I am sorry, I can't list tables. I can only get the row count of a table if you provide the table name.
 | STATUS: Processing complete. | STATUS: Agent processing completed....
2025-08-09 12:19:25,201 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:19:25] "GET /agent HTTP/1.1" 200 -
2025-08-09 12:19:25,251 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-09 12:19:25,260 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:19:25] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-09 12:19:25,261 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:19:25] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-09 12:19:28,617 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:19:28,618 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:19:28,618 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:19:28,620 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:19:28,621 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:19:28,621 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:19:28,621 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:19:29,450 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:19:29,457 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:19:29,474 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:19:29] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-09 12:19:29,475 - INFO - [agent_routes.py:112] - Processing query with 1 previous messages for context
2025-08-09 12:19:29,475 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-09 12:19:29,475 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:19:29,485 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:19:29,486 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:19:29,486 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:19:29,486 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:19:29,486 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-09 12:19:29,486 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-09 12:19:29,487 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-09 12:19:29,487 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-09 12:19:29,487 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-09 12:19:29,488 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-09 12:19:30,192 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-09 12:19:30,198 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-09 12:19:30,198 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-09 12:19:30,198 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: get me list of tables
2025-08-09 12:19:30,198 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-09 12:19:30,198 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. I'll help you solve tasks by using tools and accessing resources. You can ask follow-up questions, and I'll maintain context from our conversation. How can I help you today?"}, {'role': 'user', 'content': 'get me list of tables'}]
2025-08-09 12:19:30,198 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (1 previous messages)
2025-08-09 12:19:30,199 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-09 12:19:30,199 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-09 12:19:30,199 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-09 12:19:30,199 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-09 12:19:30,199 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.0-flash-lite with max_tokens=1500, temperature=0.7
2025-08-09 12:19:31,046 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 0.85s
2025-08-09 12:19:31,047 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'I am sorry, I cannot directly list the tables in the database. However, I can get the row count for a specific table if you provide the table name. I can also list the available mappings. Would you like me to list the mappings?
'
2025-08-09 12:19:31,048 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 0.85s
2025-08-09 12:19:31,049 - INFO - [llm_engine.py:389] - **************************
2025-08-09 12:19:31,050 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='I am sorry, I cannot directly list the tables in the database. However, I can get the row count for a specific table if you provide the table name. I can also list the available mappings. Would you like me to list the mappings?
', has_tool_calls=False
2025-08-09 12:19:31,051 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': 'I am sorry, I cannot directly list the tables in the database. However, I can get the row count for a specific table if you provide the table name. I can also list the available mappings. Would you like me to list the mappings?\n'}
2025-08-09 12:19:31,052 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-09 12:19:31,053 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-09 12:19:31,053 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-09 12:19:31,074 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-09 12:19:31,074 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-09 12:19:31,074 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-09 12:19:31,075 - INFO - [agent_routes.py:250] - Agent audit - Collected 7 response parts
2025-08-09 12:19:31,075 - DEBUG - [agent_routes.py:251] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | LLM_RESPONSE: I am sorry, I cannot directly list the tables in the database. However, I can get the row count for a specific table if you provide the table name. I can also list the available mappings. Would you like me to list the mappings?
 | FALLBACK_llm_response: I am sorry, I cannot directly list the tables in the database. However, I can get the row co...
2025-08-09 12:21:47,985 - DEBUG - [app.py:163] - Main page requested
2025-08-09 12:21:47,988 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:21:47] "GET / HTTP/1.1" 200 -
2025-08-09 12:21:48,097 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-09 12:21:48,103 - INFO - [_internal.py:97] - 127.0.0.1 - - [09/Aug/2025 12:21:48] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-09 04:35:27,381 - INFO - [schema_manager.py:48] - Loading schema from /home/runner/work/text2sql/text2sql/config/data/schema.json
2025-08-09 04:35:27,382 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 04:35:27,383 - INFO - [schema_manager.py:274] - Loading join conditions from /home/runner/work/text2sql/text2sql/config/data/condition.json
2025-08-09 04:35:27,383 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 04:35:27,391 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-09 04:36:04,454 - INFO - [schema_manager.py:48] - Loading schema from /home/runner/work/text2sql/text2sql/config/data/schema.json
2025-08-09 04:36:04,454 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-09 04:36:04,454 - INFO - [schema_manager.py:274] - Loading join conditions from /home/runner/work/text2sql/text2sql/config/data/condition.json
2025-08-09 04:36:04,455 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-09 04:36:04,456 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-10 23:47:49,388 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:49,388 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:49,388 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:49,388 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:49,396 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-10 23:47:54,866 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-10 23:47:54,885 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:47:54,885 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:47:54,919 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:47:54,919 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:54,919 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:54,919 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:54,920 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:54,920 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:47:54,920 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:47:54,950 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:47:54,950 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:54,950 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:54,950 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:54,950 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:54,951 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:47:54,951 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:47:54,982 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:47:54,982 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:54,982 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:54,982 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:54,982 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:54,982 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-10 23:47:54,983 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:47:54,983 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:47:55,012 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:47:55,012 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-10 23:47:55,012 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-10 23:47:55,012 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:55,013 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:55,013 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:55,013 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:55,013 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-10 23:47:55,023 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-10 23:47:55,039 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-10 23:47:55,041 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-10 23:47:55,042 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-10 23:47:55,076 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:47:55,076 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:47:55,108 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:47:55,108 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:55,108 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:55,108 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:55,109 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:55,109 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:47:55,109 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:47:55,140 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:47:55,140 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:55,141 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:55,141 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:55,141 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:55,141 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:47:55,141 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:47:55,172 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:47:55,172 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:55,172 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:55,172 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:55,172 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:55,173 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-10 23:47:55,173 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:47:55,173 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:47:55,204 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:47:55,204 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-10 23:47:55,204 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-10 23:47:55,204 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-10 23:47:55,205 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-10 23:47:55,205 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-10 23:47:55,205 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-10 23:47:55,205 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-10 23:47:55,223 - INFO - [app.py:727] - Initializing application-wide components
2025-08-10 23:47:55,226 - INFO - [app.py:61] - Successfully started MCP server: dataengineer
2025-08-10 23:47:55,226 - INFO - [app.py:729] - Application-wide components initialization complete
2025-08-10 23:47:55,227 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-10 23:47:55,227 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-10 23:48:03,714 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:03] "[32mGET / HTTP/1.1[0m" 302 -
2025-08-10 23:48:03,989 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:03] "GET /login?next=http://localhost:5000/ HTTP/1.1" 200 -
2025-08-10 23:48:04,081 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:04] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-10 23:48:04,398 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:04] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-10 23:48:04,406 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:04] "GET /static/css/glassmorphism1.css HTTP/1.1" 200 -
2025-08-10 23:48:04,426 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:04] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-10 23:48:04,428 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:04] "GET /static/css/auth.css HTTP/1.1" 200 -
2025-08-10 23:48:04,434 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:04] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-10 23:48:04,632 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:04] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-10 23:48:17,317 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-10 23:48:17,671 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:17] "[32mPOST /login HTTP/1.1[0m" 302 -
2025-08-10 23:48:17,994 - DEBUG - [app.py:163] - Main page requested
2025-08-10 23:48:18,015 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET / HTTP/1.1" 200 -
2025-08-10 23:48:18,232 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-10 23:48:18,377 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-10 23:48:18,396 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-10 23:48:18,424 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-10 23:48:18,425 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-10 23:48:18,432 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-10 23:48:18,550 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-10 23:48:18,693 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-10 23:48:18,721 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-10 23:48:18,733 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-10 23:48:18,736 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-10 23:48:18,739 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:18] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-10 23:48:19,094 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-10 23:48:19,121 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:19] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-10 23:48:23,796 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-10 23:48:23,988 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:23] "GET /api/tables/suggestions?workspace=dfd&query= HTTP/1.1" 200 -
2025-08-10 23:48:27,283 - INFO - [app.py:185] - User explicitly specified tables: customers
2025-08-10 23:48:27,285 - INFO - [sql_generator.py:37] - Processing query: 'table customers count'
2025-08-10 23:48:27,287 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:27] "POST /api/query HTTP/1.1" 200 -
2025-08-10 23:48:27,288 - INFO - [sql_generator.py:40] - User explicitly selected tables: customers
2025-08-10 23:48:27,289 - INFO - [intent_agent.py:27] - Intent detection started for query: 'table customers count'
2025-08-10 23:48:27,290 - INFO - [intent_agent.py:38] - Using default intent 'data_retrieval' without calling LLM
2025-08-10 23:48:27,291 - INFO - [intent_agent.py:41] - Intent detection completed in 0.00s
2025-08-10 23:48:27,291 - INFO - [sql_generator.py:45] - Detected intent: data_retrieval
2025-08-10 23:48:27,292 - INFO - [sql_generator.py:141] - Starting SQL generation process
2025-08-10 23:48:27,292 - INFO - [database.py:80] - Attempting database connection
2025-08-10 23:48:27,294 - INFO - [database.py:84] - Database connection established in 0.00s
2025-08-10 23:48:27,294 - INFO - [column_agent.py:29] - Column pruning started for query: 'table customers count'
2025-08-10 23:48:27,295 - INFO - [column_agent.py:30] - Processing tables: customers
2025-08-10 23:48:27,295 - INFO - [column_agent.py:38] - Only one table involved (customers). Skipping LLM call and including all columns.
2025-08-10 23:48:27,295 - INFO - [feedback_manager.py:250] - Stage 1: Vector search for 'table customers count...'
2025-08-10 23:48:27,296 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:48:27,296 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:48:27,339 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:48:27,339 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-10 23:48:27,799 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:27] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:28,565 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:28] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:28,831 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:28] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:29,227 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:29] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:30,023 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:30] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:30,264 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:30] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:30,420 - INFO - [llm_engine.py:59] - Embedding model loaded in 3.08s
2025-08-10 23:48:30,553 - INFO - [llm_engine.py:85] - Generated embedding in 0.13s with shape (384,)
2025-08-10 23:48:30,565 - INFO - [feedback_manager.py:278] - Found 1 initial candidates from vector search
2025-08-10 23:48:30,565 - INFO - [feedback_manager.py:346] - Less than 2 candidates, skipping reranking
2025-08-10 23:48:30,565 - INFO - [sql_generator.py:280] - Found 1 similar queries with reranking
2025-08-10 23:48:30,565 - INFO - [sql_generator.py:302] - Added similar query #1 from manual (score: 0.6487): @customers count...
2025-08-10 23:48:30,565 - INFO - [azure_client.py:35] - SQL generation started for query: 'table customers count'
2025-08-10 23:48:30,566 - INFO - [azure_client.py:69] - Including schema information (587 chars)
2025-08-10 23:48:30,567 - INFO - [azure_client.py:97] - Including 1 SQL examples from manual similarity search
2025-08-10 23:48:30,567 - INFO - [azure_client.py:114] - PROMPT: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: @customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers count'}]
2025-08-10 23:48:30,567 - INFO - [llm_engine.py:128] - [SQL_GEN] Completion generation started (format: openai)
2025-08-10 23:48:30,568 - INFO - [llm_engine.py:193] - [SQL_GEN] Prompt: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief ... (truncated)
2025-08-10 23:48:30,568 - INFO - [llm_engine.py:197] - [SQL_GEN] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-10 23:48:30,568 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: @customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers count'}]
2025-08-10 23:48:30,671 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:30] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:31,371 - INFO - [llm_engine.py:245] - [SQL_GEN] Model response received in 0.80s
2025-08-10 23:48:31,372 - INFO - [llm_engine.py:254] - [SQL_GEN] Raw model response: 'Here's a query that will count the total number of customers in the `customers` table.

```sql
SELECT 
    COUNT(customer_id) AS total_customers
FROM customers;
```'
2025-08-10 23:48:31,373 - INFO - [llm_engine.py:257] - [SQL_GEN] Completion generation completed in 0.81s
2025-08-10 23:48:31,374 - INFO - [llm_engine.py:258] - **************************
2025-08-10 23:48:31,375 - INFO - [azure_client.py:150] - Parsing SQL from model response
2025-08-10 23:48:31,376 - INFO - [azure_client.py:157] - Found SQL code block in response
2025-08-10 23:48:31,376 - INFO - [azure_client.py:171] - Extracted SQL query (65 chars) and explanation (86 chars)
2025-08-10 23:48:31,377 - INFO - [azure_client.py:124] - Generated SQL: SELECT 
    COUNT(customer_id) AS total_customers
FROM customers;
2025-08-10 23:48:31,378 - INFO - [azure_client.py:132] - SQL generation completed in 0.81s
2025-08-10 23:48:31,379 - INFO - [database.py:101] - Executing SQL query: SELECT 
    COUNT(customer_id) AS total_customers
FROM customers;
2025-08-10 23:48:31,380 - INFO - [database.py:112] - Query execution started
2025-08-10 23:48:31,389 - INFO - [database.py:117] - Query execution completed in 0.01s
2025-08-10 23:48:31,402 - INFO - [database.py:122] - Query returned 1 rows with 1 columns
2025-08-10 23:48:31,403 - INFO - [database.py:131] - Query processing completed in 0.02s
2025-08-10 23:48:31,409 - INFO - [sql_generator.py:348] - Analyzing query results for dashboard potential
2025-08-10 23:48:31,410 - INFO - [azure_client.py:197] - Dashboard analysis started for query: 'table customers count'
2025-08-10 23:48:31,411 - INFO - [llm_engine.py:128] - [DASHBOARD_ANALYSIS] Completion generation started (format: openai)
2025-08-10 23:48:31,413 - INFO - [llm_engine.py:193] - [DASHBOARD_ANALYSIS] Prompt: [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axi... (truncated)
2025-08-10 23:48:31,414 - INFO - [llm_engine.py:197] - [DASHBOARD_ANALYSIS] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-10 23:48:31,417 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axis\n5. Suggest meaningful labels and title\n\nReturn your analysis in JSON format exactly like this:\n{\n  "is_suitable": true_or_false,\n  "reason": "brief explanation of why it is or isn\'t suitable",\n  "chart_type": "recommended chart type if suitable",\n  "x_axis": {\n    "column": "column_name for x-axis",\n    "label": "suggested x-axis label"\n  },\n  "y_axis": {\n    "column": "column_name for y-axis",\n    "label": "suggested y-axis label"\n  },\n  "title": "suggested chart title"\n}\n\nMake decisions based on these criteria:\n- Bar charts are good for comparing categories\n- Line charts are good for time series \n- Pie charts are good for part-to-whole relationships (under 7 categories)\n- Scatter plots are good for showing relationships between numeric values\n- Data needs at least one numeric column for most visualizations'}, {'role': 'user', 'content': 'Query: table customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\nColumns: total_customers\nData Sample:\nRow 1: {"total_customers": 4}\n\n\nAnalyze if this data is suitable for a dashboard visualization. If so, provide recommendations in the required JSON format.'}]
2025-08-10 23:48:31,465 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:31] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:33,788 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:33] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:34,194 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:34] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:34,751 - INFO - [llm_engine.py:245] - [DASHBOARD_ANALYSIS] Model response received in 3.34s
2025-08-10 23:48:34,752 - INFO - [llm_engine.py:254] - [DASHBOARD_ANALYSIS] Raw model response: '```json
{
  "is_suitable": false,
  "reason": "The data only contains a single numeric value representing the total number of customers. This is not suitable for any of the standard dashboard visualizations as it lacks categorical data to compare against or a time series to track. A single number can be displayed with a 'KPI' or 'Number' visualization.",
  "chart_type": null,
  "x_axis": null,
  "y_axis": null,
  "title": null
}
```'
2025-08-10 23:48:34,752 - INFO - [llm_engine.py:257] - [DASHBOARD_ANALYSIS] Completion generation completed in 3.34s
2025-08-10 23:48:34,753 - INFO - [llm_engine.py:258] - **************************
2025-08-10 23:48:34,754 - INFO - [azure_client.py:255] - Dashboard analysis results: suitable=False
2025-08-10 23:48:34,754 - INFO - [azure_client.py:264] - Dashboard analysis completed in 3.34s
2025-08-10 23:48:34,754 - INFO - [sql_generator.py:366] - Dashboard analysis completed: suitable=False
2025-08-10 23:48:34,755 - INFO - [sql_generator.py:444] - SQL generation completed in 7.46s
2025-08-10 23:48:34,756 - INFO - [sql_generator.py:125] - Query processing completed in 7.47s
2025-08-10 23:48:34,976 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:34] "GET /api/query/progress/e5c4ec4f-8c1c-454d-b109-6d242e58db59 HTTP/1.1" 200 -
2025-08-10 23:48:44,135 - INFO - [app.py:185] - User explicitly specified tables: customers
2025-08-10 23:48:44,136 - INFO - [sql_generator.py:37] - Processing query: 'table customers all records'
2025-08-10 23:48:44,137 - INFO - [sql_generator.py:40] - User explicitly selected tables: customers
2025-08-10 23:48:44,137 - INFO - [intent_agent.py:27] - Intent detection started for query: 'table customers all records'
2025-08-10 23:48:44,138 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:44] "POST /api/query HTTP/1.1" 200 -
2025-08-10 23:48:44,139 - INFO - [intent_agent.py:38] - Using default intent 'data_retrieval' without calling LLM
2025-08-10 23:48:44,140 - INFO - [intent_agent.py:41] - Intent detection completed in 0.00s
2025-08-10 23:48:44,140 - INFO - [sql_generator.py:45] - Detected intent: data_retrieval
2025-08-10 23:48:44,140 - INFO - [sql_generator.py:141] - Starting SQL generation process
2025-08-10 23:48:44,140 - INFO - [database.py:80] - Attempting database connection
2025-08-10 23:48:44,142 - INFO - [database.py:84] - Database connection established in 0.00s
2025-08-10 23:48:44,143 - INFO - [column_agent.py:29] - Column pruning started for query: 'table customers all records'
2025-08-10 23:48:44,143 - INFO - [column_agent.py:30] - Processing tables: customers
2025-08-10 23:48:44,144 - INFO - [column_agent.py:38] - Only one table involved (customers). Skipping LLM call and including all columns.
2025-08-10 23:48:44,144 - INFO - [feedback_manager.py:250] - Stage 1: Vector search for 'table customers all records...'
2025-08-10 23:48:44,144 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:48:44,144 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:48:44,181 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:48:44,182 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-10 23:48:44,941 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:44] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:45,173 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:45] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:45,574 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:45] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:46,351 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:46] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:46,599 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:46] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:47,003 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:47] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:47,343 - INFO - [llm_engine.py:59] - Embedding model loaded in 3.16s
2025-08-10 23:48:47,465 - INFO - [llm_engine.py:85] - Generated embedding in 0.12s with shape (384,)
2025-08-10 23:48:47,483 - INFO - [feedback_manager.py:278] - Found 1 initial candidates from vector search
2025-08-10 23:48:47,483 - INFO - [feedback_manager.py:346] - Less than 2 candidates, skipping reranking
2025-08-10 23:48:47,483 - INFO - [sql_generator.py:280] - Found 1 similar queries with reranking
2025-08-10 23:48:47,484 - INFO - [sql_generator.py:302] - Added similar query #1 from manual (score: 0.4983): @customers count...
2025-08-10 23:48:47,484 - INFO - [azure_client.py:35] - SQL generation started for query: 'table customers all records'
2025-08-10 23:48:47,484 - INFO - [azure_client.py:69] - Including schema information (587 chars)
2025-08-10 23:48:47,485 - INFO - [azure_client.py:97] - Including 1 SQL examples from manual similarity search
2025-08-10 23:48:47,485 - INFO - [azure_client.py:114] - PROMPT: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: @customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers all records'}]
2025-08-10 23:48:47,486 - INFO - [llm_engine.py:128] - [SQL_GEN] Completion generation started (format: openai)
2025-08-10 23:48:47,486 - INFO - [llm_engine.py:193] - [SQL_GEN] Prompt: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief ... (truncated)
2025-08-10 23:48:47,486 - INFO - [llm_engine.py:197] - [SQL_GEN] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-10 23:48:47,486 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: @customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: table customers all records'}]
2025-08-10 23:48:47,780 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:47] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:48,038 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:48] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:48,306 - INFO - [llm_engine.py:245] - [SQL_GEN] Model response received in 0.82s
2025-08-10 23:48:48,307 - INFO - [llm_engine.py:254] - [SQL_GEN] Raw model response: 'Here's a query that will retrieve all records from the customers table.

```sql
SELECT 
    *
FROM customers;
```'
2025-08-10 23:48:48,308 - INFO - [llm_engine.py:257] - [SQL_GEN] Completion generation completed in 0.82s
2025-08-10 23:48:48,309 - INFO - [llm_engine.py:258] - **************************
2025-08-10 23:48:48,309 - INFO - [azure_client.py:150] - Parsing SQL from model response
2025-08-10 23:48:48,311 - INFO - [azure_client.py:157] - Found SQL code block in response
2025-08-10 23:48:48,312 - INFO - [azure_client.py:171] - Extracted SQL query (29 chars) and explanation (71 chars)
2025-08-10 23:48:48,312 - INFO - [azure_client.py:124] - Generated SQL: SELECT 
    *
FROM customers;
2025-08-10 23:48:48,314 - INFO - [azure_client.py:132] - SQL generation completed in 0.83s
2025-08-10 23:48:48,315 - INFO - [database.py:101] - Executing SQL query: SELECT 
    *
FROM customers;
2025-08-10 23:48:48,317 - INFO - [database.py:112] - Query execution started
2025-08-10 23:48:48,328 - INFO - [database.py:117] - Query execution completed in 0.01s
2025-08-10 23:48:48,336 - INFO - [database.py:122] - Query returned 4 rows with 11 columns
2025-08-10 23:48:48,336 - INFO - [database.py:131] - Query processing completed in 0.02s
2025-08-10 23:48:48,342 - INFO - [sql_generator.py:348] - Analyzing query results for dashboard potential
2025-08-10 23:48:48,343 - INFO - [azure_client.py:197] - Dashboard analysis started for query: 'table customers all records'
2025-08-10 23:48:48,343 - INFO - [llm_engine.py:128] - [DASHBOARD_ANALYSIS] Completion generation started (format: openai)
2025-08-10 23:48:48,344 - INFO - [llm_engine.py:193] - [DASHBOARD_ANALYSIS] Prompt: [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axi... (truncated)
2025-08-10 23:48:48,344 - INFO - [llm_engine.py:197] - [DASHBOARD_ANALYSIS] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-10 23:48:48,344 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axis\n5. Suggest meaningful labels and title\n\nReturn your analysis in JSON format exactly like this:\n{\n  "is_suitable": true_or_false,\n  "reason": "brief explanation of why it is or isn\'t suitable",\n  "chart_type": "recommended chart type if suitable",\n  "x_axis": {\n    "column": "column_name for x-axis",\n    "label": "suggested x-axis label"\n  },\n  "y_axis": {\n    "column": "column_name for y-axis",\n    "label": "suggested y-axis label"\n  },\n  "title": "suggested chart title"\n}\n\nMake decisions based on these criteria:\n- Bar charts are good for comparing categories\n- Line charts are good for time series \n- Pie charts are good for part-to-whole relationships (under 7 categories)\n- Scatter plots are good for showing relationships between numeric values\n- Data needs at least one numeric column for most visualizations'}, {'role': 'user', 'content': 'Query: table customers all records\nSQL: SELECT \n    *\nFROM customers;\nColumns: customer_id, first_name, last_name, email, phone, address, city, state, country, postal_code, registration_date\nData Sample:\nRow 1: {"customer_id": 1, "first_name": "John", "last_name": "Doe", "email": "john.doe@example.com", "phone": "123-456-7890", "address": "123 Main St", "city": "New York", "state": "NY", "country": "USA", "postal_code": "10001", "registration_date": "2023-01-15"}\nRow 2: {"customer_id": 2, "first_name": "Jane", "last_name": "Smith", "email": "jane.smith@example.com", "phone": "987-654-3210", "address": "456 Oak Ave", "city": "Los Angeles", "state": "CA", "country": "USA", "postal_code": "90001", "registration_date": "2023-02-20"}\nRow 3: {"customer_id": 3, "first_name": "Alice", "last_name": "Johnson", "email": "alice@example.com", "phone": "555-123-4567", "address": "789 Pine St", "city": "Chicago", "state": "IL", "country": "USA", "postal_code": "60007", "registration_date": "2023-03-10"}\nRow 4: {"customer_id": 4, "first_name": "Bob", "last_name": "Williams", "email": "bob@example.com", "phone": "555-987-6543", "address": "101 Maple Dr", "city": "Houston", "state": "TX", "country": "USA", "postal_code": "77002", "registration_date": "2023-01-05"}\n\n\nAnalyze if this data is suitable for a dashboard visualization. If so, provide recommendations in the required JSON format.'}]
2025-08-10 23:48:48,427 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:48] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:49,200 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:49] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:49,439 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:49] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:49,758 - INFO - [llm_engine.py:245] - [DASHBOARD_ANALYSIS] Model response received in 1.41s
2025-08-10 23:48:49,758 - INFO - [llm_engine.py:254] - [DASHBOARD_ANALYSIS] Raw model response: '```json
{
  "is_suitable": true,
  "reason": "The data contains categorical data (city, state, country) and date data (registration_date), which can be used to create visualizations.  It would require aggregation to create meaningful charts.",
  "chart_type": "bar",
  "x_axis": {
    "column": "city",
    "label": "City"
  },
  "y_axis": {
    "column": "customer_id",
    "label": "Number of Customers"
  },
  "title": "Number of Customers by City"
}
```'
2025-08-10 23:48:49,759 - INFO - [llm_engine.py:257] - [DASHBOARD_ANALYSIS] Completion generation completed in 1.42s
2025-08-10 23:48:49,760 - INFO - [llm_engine.py:258] - **************************
2025-08-10 23:48:49,760 - INFO - [azure_client.py:255] - Dashboard analysis results: suitable=True
2025-08-10 23:48:49,760 - INFO - [azure_client.py:264] - Dashboard analysis completed in 1.42s
2025-08-10 23:48:49,761 - INFO - [sql_generator.py:366] - Dashboard analysis completed: suitable=True
2025-08-10 23:48:49,761 - INFO - [sql_generator.py:444] - SQL generation completed in 5.62s
2025-08-10 23:48:49,762 - INFO - [sql_generator.py:125] - Query processing completed in 5.63s
2025-08-10 23:48:49,854 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:49] "GET /api/query/progress/e777c2dc-0e29-4f85-a23a-7590012b0700 HTTP/1.1" 200 -
2025-08-10 23:48:57,240 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:57] "GET /query-editor HTTP/1.1" 200 -
2025-08-10 23:48:57,392 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:57] "GET /static/js/query-editor.js HTTP/1.1" 200 -
2025-08-10 23:48:57,632 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-10 23:48:57,662 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:57] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-10 23:48:58,988 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:58] "GET /knowledge HTTP/1.1" 200 -
2025-08-10 23:48:59,337 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:59] "GET /static/js/knowledge-base.js HTTP/1.1" 200 -
2025-08-10 23:48:59,583 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-10 23:48:59,618 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:59] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-10 23:48:59,674 - INFO - [knowledge_manager.py:33] - Initializing Knowledge Manager
2025-08-10 23:48:59,820 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-10 23:48:59,824 - INFO - [vector_store_client.py:44] - ChromaDB service connection established in 0.00s
2025-08-10 23:48:59,834 - INFO - [vector_store_client.py:121] - Collection 'knowledge_chunks' already exists
2025-08-10 23:48:59,834 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:48:59,834 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:48:59,877 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:48:59,878 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:48:59] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-10 23:49:04,674 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:04] "POST /api/knowledge/query/stream HTTP/1.1" 200 -
2025-08-10 23:49:04,977 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-10 23:49:10,092 - INFO - [llm_engine.py:59] - Embedding model loaded in 5.11s
2025-08-10 23:49:10,138 - INFO - [llm_engine.py:85] - Generated embedding in 0.04s with shape (384,)
2025-08-10 23:49:10,219 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:49:10,219 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:49:10,255 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:49:10,255 - INFO - [llm_engine.py:102] - Loading reranking model 'cross-encoder/ms-marco-MiniLM-L-6-v2'
2025-08-10 23:49:11,519 - INFO - [llm_engine.py:106] - Reranking model loaded in 1.26s
2025-08-10 23:49:11,519 - INFO - [knowledge_manager.py:850] - Reranking 50 chunks using cross-encoder
2025-08-10 23:49:13,267 - INFO - [knowledge_manager.py:858] - Reranking complete, top score: 6.662622451782227
2025-08-10 23:49:13,273 - INFO - [knowledge_manager.py:734] - Top 3 chunks for query 'what does cloudera policy say': ['8d03acd7-2d3e-4383-a59d-1de619c4f3d1', '7fda737f-e9eb-471d-a6d8-ee37af597548', '487e0c0f-4302-47c2-bd7f-4af2481792dd']
2025-08-10 23:49:13,275 - INFO - [knowledge_manager.py:740] - Sources for query 'what does cloudera policy say': [{'document': 'faq.txt', 'document_number': 1, 'chunk_id': '8d03acd7-2d3e-4383-a59d-1de619c4f3d1'}]
2025-08-10 23:49:13,276 - INFO - [llm_engine.py:128] - [Knowledge QA] Completion generation started (format: openai)
2025-08-10 23:49:13,277 - INFO - [llm_engine.py:193] - [Knowledge QA] Prompt: [{'role': 'system', 'content': "You are a helpful AI assistant that provides accurate answers based on the given context. \n        If the answer cannot be found in the context, acknowledge that you don't know instead of making up information.\n        Provide clear, concise answers and use markdown formatting in your response to improve readability.\n        \n        IMPORTANT CITATION RULES:\n        - When referencing information from the context, use numbered citations like [1], [2], etc.\n... (truncated)
2025-08-10 23:49:13,277 - INFO - [llm_engine.py:197] - [Knowledge QA] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=True
2025-08-10 23:49:13,277 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are a helpful AI assistant that provides accurate answers based on the given context. \n        If the answer cannot be found in the context, acknowledge that you don't know instead of making up information.\n        Provide clear, concise answers and use markdown formatting in your response to improve readability.\n        \n        IMPORTANT CITATION RULES:\n        - When referencing information from the context, use numbered citations like [1], [2], etc.\n        - Do NOT repeat the full document names in your response\n        - Use citations sparingly - only at the end of sentences or paragraphs where you reference specific information\n        - The document references will be provided separately at the end, so you don't need to mention document names"}, {'role': 'user', 'content': 'Context information:\n\n\nDocument [1]:\nWhat is the purpose of the Cloudera on cloud (formerly, Public Cloud Data Services) End of Support (EOS) policy guidelines?\n\nThe purpose of our support policy is to provide customers with a clear understanding of the lifecycle of our data services and the associated support policies. These guidelines help customers plan their cloud strategies and investments by providing transparency around the availability, support, and end-of-life dates for each service.\n\nBy adhering to these guidelines, we are committed to providing customers with the highest level of service and support, as well as ensuring that our cloud services meet the evolving needs of our customers. We understand that our customers rely on our services to support their business operations, and we are committed to providing the support and resources necessary to ensure their success.\n\nWhen does the Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy go into effect?\n\nrely on our services to support their business operations, and we are committed to providing the support and resources necessary to ensure their success. When does the Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy go into effect?\n\nThe policy goes into effect immediately and applies to all upcoming Cloudera on cloud (formerly, Public Cloud Data Services) releases. Please refer to the Current End of Support (EoS) Dates table for each Cloudera on cloud (formerly, Public Cloud Data Services) to understand EOS dates for already released versions.\n\nWhy is the Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy different from the Cloudera on cloud policy?\n\nDocument [1]:\nDates table for each Cloudera on cloud (formerly, Public Cloud Data Services) to understand EOS dates for already released versions. Why is the Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy different from the Cloudera on cloud policy?\n\nOur Cloudera on cloud (formerly, Public Cloud Data Services) are built on Kubernetes, a popular open-source container orchestration platform. Cloudera relies on Kubernetes services provided by our cloud providers (like AWS EKS, Azure AKS, and GCP GKE). By leveraging Kubernetes, our data services can automatically scale to meet the changing demands of our customers, ensuring that resources are allocated efficiently and effectively.  Containerization technology is moving at a fast pace, with new versions of Kubernetes being released frequently. While these new versions often bring new features and improvements, they can also introduce changes to Kubernetes APIs, making it essential for us to certify our data services against a specifi\n\nently. While these new versions often bring new features and improvements, they can also introduce changes to Kubernetes APIs, making it essential for us to certify our data services against a specific version of Kubernetes.\n\nOur Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy is drawn to respect the cloud providers’ EOS policies and ensure that our data services remain secure, reliable, and compliant.\n\nAnd on a regular basis we will assess any updates to the cloud provider Kubernetes EOS policy to ensure as much alignment as possible.\n\nWhat is the recommended upgrade cadence?\n\nensure that our data services remain secure, reliable, and compliant. And on a regular basis we will assess any updates to the cloud provider Kubernetes EOS policy to ensure as much alignment as possible. What is the recommended upgrade cadence?\n\nWe recommend upgrading to every release, but at a minimum twice a year, to ensure that you have access to the latest features, security and bug fixes, and performance optimizations. Regular upgrades help to keep your software up-to-date with the latest developments, which can improve the functionality and reliability of our Services. Upgrades also ensure that any security vulnerabilities are addressed in a timely manner, reducing the risk of data breaches or other security incidents. Additionally, regular upgrades enable you to take advantage of performance optimizations and other improvements that can help to streamline workflows and boost productivity. We encourage all users to upgrade regularly to maintain a secure, efficient, and effective\n\nDocument [1]:\nrely on our services to support their business operations, and we are committed to providing the support and resources necessary to ensure their success. When does the Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy go into effect?\n\nThe policy goes into effect immediately and applies to all upcoming Cloudera on cloud (formerly, Public Cloud Data Services) releases. Please refer to the Current End of Support (EoS) Dates table for each Cloudera on cloud (formerly, Public Cloud Data Services) to understand EOS dates for already released versions.\n\nWhy is the Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy different from the Cloudera on cloud policy?\n\nDates table for each Cloudera on cloud (formerly, Public Cloud Data Services) to understand EOS dates for already released versions. Why is the Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy different from the Cloudera on cloud policy?\n\nOur Cloudera on cloud (formerly, Public Cloud Data Services) are built on Kubernetes, a popular open-source container orchestration platform. Cloudera relies on Kubernetes services provided by our cloud providers (like AWS EKS, Azure AKS, and GCP GKE). By leveraging Kubernetes, our data services can automatically scale to meet the changing demands of our customers, ensuring that resources are allocated efficiently and effectively.  Containerization technology is moving at a fast pace, with new versions of Kubernetes being released frequently. While these new versions often bring new features and improvements, they can also introduce changes to Kubernetes APIs, making it essential for us to certify our data services against a specifi\n\nently. While these new versions often bring new features and improvements, they can also introduce changes to Kubernetes APIs, making it essential for us to certify our data services against a specific version of Kubernetes.\n\nOur Cloudera on cloud (formerly, Public Cloud Data Services) EOS policy is drawn to respect the cloud providers’ EOS policies and ensure that our data services remain secure, reliable, and compliant.\n\nAnd on a regular basis we will assess any updates to the cloud provider Kubernetes EOS policy to ensure as much alignment as possible.\n\nWhat is the recommended upgrade cadence?\n\nDocument References:\n[1] faq.txt\n\n\nQuestion: what does cloudera policy say\n\nProvide a detailed answer to the question based only on the context provided. Use markdown formatting for better readability and numbered citations [1], [2], etc. when referencing specific information.'}]
2025-08-10 23:49:13,972 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:13] "GET /api/knowledge/query/stream?query=what%20does%20cloudera%20policy%20say&t=1754840945275 HTTP/1.1" 200 -
2025-08-10 23:49:14,659 - INFO - [llm_engine.py:223] - [Knowledge QA] Model streaming completed in 1.38s
2025-08-10 23:49:14,660 - INFO - [llm_engine.py:225] - [Knowledge QA] Raw model response: 'The Cloudera on cloud (formerly, Public Cloud Data Services) End of Support (EOS) policy provides customers with a clear understanding of the lifecycle of data services and the associated support policies [1]. These guidelines help customers plan their cloud strategies and investments by providing transparency around the availability, support, and end-of-life dates for each service [1]. The policy goes into effect immediately and applies to all upcoming Cloudera on cloud releases [1]. The Cloude...' (truncated)
2025-08-10 23:49:14,661 - INFO - [llm_engine.py:230] - [Knowledge QA] Completion generation completed in 1.38s
2025-08-10 23:49:14,661 - INFO - [llm_engine.py:231] - **************************
2025-08-10 23:49:18,469 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:18] "GET /knowledge HTTP/1.1" 200 -
2025-08-10 23:49:18,884 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-10 23:49:18,938 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:18] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-10 23:49:18,944 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:18] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-10 23:49:19,144 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:19] "GET /agent HTTP/1.1" 200 -
2025-08-10 23:49:19,337 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:19] "GET /static/js/tool-confirmation.js HTTP/1.1" 200 -
2025-08-10 23:49:19,591 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:19] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-10 23:49:19,618 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-10 23:49:19,684 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:19] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-10 23:49:19,931 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:19] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-10 23:49:21,847 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:21] "GET /data-mapping/ HTTP/1.1" 200 -
2025-08-10 23:49:21,956 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:21] "GET /static/js/data-mapping.js HTTP/1.1" 200 -
2025-08-10 23:49:22,220 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-10 23:49:22,261 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:22] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-10 23:49:22,268 - INFO - [data_mapping_routes.py:93] - Available MCP servers: ['Data Mapping Analyst', 'Engineer', 'Skills', 'Weather', 'dataengineer']
2025-08-10 23:49:22,277 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-10 23:49:22,278 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-10 23:49:22,279 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-10 23:49:22,377 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-10 23:49:22,377 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-10 23:49:22,378 - WARNING - [data_mapping_routes.py:106] - Could not connect to data mapping server: Data Mapping Analyst
2025-08-10 23:49:22,378 - INFO - [data_mapping_routes.py:111] - Data mapping server not found in registry, attempting manual registration
2025-08-10 23:49:22,380 - WARNING - [data_mapping_routes.py:119] - Could not connect to manual data mapping server: HTTPConnectionPool(host='localhost', port=8003): Max retries exceeded with url: /sse (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x70da09051d10>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-10 23:49:22,380 - WARNING - [data_mapping_routes.py:122] - Data mapping MCP server not found. Agent will work without MCP features.
2025-08-10 23:49:22,444 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:22] "GET /data-mapping/server-status HTTP/1.1" 200 -
2025-08-10 23:49:22,610 - INFO - [app.py:317] - Schema requested for workspace: 
2025-08-10 23:49:22,610 - DEBUG - [app.py:344] - Schema retrieval completed in 0.000s
2025-08-10 23:49:22,611 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:22] "GET /api/schema?workspace= HTTP/1.1" 200 -
2025-08-10 23:49:30,902 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:30] "GET /admin/ HTTP/1.1" 200 -
2025-08-10 23:49:31,107 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:31] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-10 23:49:31,347 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-10 23:49:31,426 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:31] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-10 23:49:31,483 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:31] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-10 23:49:31,486 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:31] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-10 23:49:35,365 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:35] "GET /admin/audit-logs HTTP/1.1" 200 -
2025-08-10 23:49:35,702 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:35] "GET /static/js/admin/audit-logs.js HTTP/1.1" 200 -
2025-08-10 23:49:35,942 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-10 23:49:36,005 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:36] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-10 23:49:41,777 - DEBUG - [app.py:163] - Main page requested
2025-08-10 23:49:41,783 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:41] "GET / HTTP/1.1" 200 -
2025-08-10 23:49:42,182 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-10 23:49:42,194 - INFO - [_internal.py:97] - 127.0.0.1 - - [10/Aug/2025 23:49:42] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-10 23:49:48,622 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-10 23:49:48,623 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-10 23:49:48,623 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-10 23:49:48,624 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-10 23:49:48,625 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-10 23:49:48,626 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-10 23:49:48,626 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-10 23:49:48,627 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-10 23:49:48,628 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-10 23:49:48,628 - INFO - [database.py:294] - Closing database connection
2025-08-10 23:49:48,629 - INFO - [database.py:297] - Database engine disposed
2025-08-10 23:49:48,630 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-10 23:49:48,630 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-10 23:49:48,633 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-10 23:49:48,634 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-10 23:49:48,634 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-10 23:49:48,635 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-10 23:49:48,636 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-10 23:49:48,636 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-10 23:49:48,637 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-10 23:49:48,637 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-10 23:49:48,638 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-10 23:49:48,639 - INFO - [database.py:294] - Closing database connection
2025-08-10 23:49:48,641 - INFO - [database.py:297] - Database engine disposed
2025-08-10 23:49:48,642 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-10 23:49:48,642 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 10:15:59,747 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:15:59,748 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:15:59,748 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:15:59,748 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:15:59,750 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:16:07,717 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 10:16:07,729 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:16:07,729 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:16:07,804 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:16:07,805 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:16:07,806 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:16:07,806 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:16:07,806 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:16:07,806 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:16:07,806 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:16:07,874 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:16:07,874 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:16:07,875 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:16:07,875 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:16:07,875 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:16:07,876 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:16:07,876 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:16:07,940 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:16:07,941 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:16:07,942 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:16:07,942 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:16:07,942 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:16:07,943 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 10:16:07,943 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:16:07,944 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:16:08,005 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:16:08,006 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 10:16:08,006 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:16:08,006 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:16:08,007 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:16:08,008 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:16:08,008 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:16:08,008 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:16:08,026 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 10:16:08,061 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 10:16:08,065 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 10:16:08,066 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 10:16:08,125 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:16:08,126 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:16:08,188 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:16:08,188 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:16:08,189 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:16:08,189 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:16:08,190 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:16:08,190 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:16:08,190 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:16:08,257 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:16:08,257 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:16:08,258 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:16:08,258 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:16:08,258 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:16:08,259 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:16:08,259 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:16:08,330 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:16:08,331 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:16:08,331 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:16:08,332 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:16:08,332 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:16:08,332 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 10:16:08,332 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:16:08,333 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:16:08,400 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:16:08,400 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 10:16:08,401 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:16:08,401 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:16:08,401 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:16:08,402 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:16:08,402 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:16:08,402 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:16:08,438 - INFO - [app.py:727] - Initializing application-wide components
2025-08-11 10:16:08,443 - INFO - [app.py:61] - Successfully started MCP server: dataengineer
2025-08-11 10:16:08,443 - INFO - [app.py:729] - Application-wide components initialization complete
2025-08-11 10:16:08,446 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 10:16:08,447 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 10:16:23,759 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:23] "[32mGET / HTTP/1.1[0m" 302 -
2025-08-11 10:16:24,000 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /login HTTP/1.1" 200 -
2025-08-11 10:16:24,055 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 10:16:24,343 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 10:16:24,354 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 10:16:24,357 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 10:16:24,360 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /static/css/glassmorphism1.css HTTP/1.1" 200 -
2025-08-11 10:16:24,364 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /static/css/auth.css HTTP/1.1" 200 -
2025-08-11 10:16:24,369 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 10:16:24,637 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 10:16:24,953 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:24] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 10:16:28,050 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 10:16:28,286 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:28] "[32mPOST /login HTTP/1.1[0m" 302 -
2025-08-11 10:16:28,598 - DEBUG - [app.py:163] - Main page requested
2025-08-11 10:16:28,618 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:28] "GET / HTTP/1.1" 200 -
2025-08-11 10:16:28,834 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:28] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 10:16:28,956 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:28] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 10:16:28,962 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:28] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 10:16:28,969 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:28] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 10:16:28,973 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:28] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 10:16:28,974 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:28] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 10:16:29,139 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "[33mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 404 -
2025-08-11 10:16:29,265 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 10:16:29,267 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "[33mGET /static/vendor/webfonts/fa-solid-900.ttf HTTP/1.1[0m" 404 -
2025-08-11 10:16:29,278 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 10:16:29,279 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 10:16:29,280 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 10:16:29,442 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 10:16:29,580 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 10:16:29,585 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 10:16:29,588 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 10:16:29,595 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 10:16:29,599 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 10:16:29,746 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 10:16:29,880 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 10:16:29,886 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 10:16:29,890 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 10:16:29,895 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 10:16:29,899 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:29] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 10:16:30,041 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:30] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 10:16:30,191 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:30] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 10:16:30,551 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 10:16:30,569 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:30] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 10:16:30,579 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:30] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 10:16:30,782 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:30] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 10:16:30,955 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:30] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 10:16:31,090 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:31] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-11 10:16:31,428 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:16:31] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-11 10:17:15,425 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:15] "GET /query-editor HTTP/1.1" 200 -
2025-08-11 10:17:15,788 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:15] "GET /static/js/query-editor.js HTTP/1.1" 200 -
2025-08-11 10:17:15,793 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:15] "[33mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 404 -
2025-08-11 10:17:16,016 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:16] "[33mGET /static/vendor/webfonts/fa-solid-900.ttf HTTP/1.1[0m" 404 -
2025-08-11 10:17:16,161 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 10:17:16,178 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:16] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 10:17:16,208 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:16] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-11 10:17:16,228 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:16] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-11 10:17:17,968 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:17] "GET /knowledge HTTP/1.1" 200 -
2025-08-11 10:17:18,301 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:18] "GET /static/js/knowledge-base.js HTTP/1.1" 200 -
2025-08-11 10:17:18,306 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:18] "[33mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 404 -
2025-08-11 10:17:18,519 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:18] "[33mGET /static/vendor/webfonts/fa-solid-900.ttf HTTP/1.1[0m" 404 -
2025-08-11 10:17:18,607 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-11 10:17:18,614 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:18] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 10:17:18,615 - INFO - [knowledge_manager.py:33] - Initializing Knowledge Manager
2025-08-11 10:17:18,721 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-11 10:17:18,723 - ERROR - [vector_store_client.py:50] - ChromaDB service connection error: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79d511cc9450>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1289, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1048, in _send_output
    self.send(msg)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 986, in send
    self.connect()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x79d511cc9450>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79d511cc9450>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/vector_store_client.py", line 39, in connect
    response = self.session.get(f"{self.service_url}/health", timeout=10)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79d511cc9450>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-11 10:17:18,730 - ERROR - [vector_store_client.py:137] - Error initializing collection knowledge_chunks: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/knowledge_chunks (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79d511b5d490>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1289, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1048, in _send_output
    self.send(msg)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 986, in send
    self.connect()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x79d511b5d490>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/knowledge_chunks (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79d511b5d490>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/vector_store_client.py", line 119, in init_collection
    response = self.session.get(f"{self.service_url}/collections/{collection_name}")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/knowledge_chunks (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79d511b5d490>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-11 10:17:18,732 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:17:18,732 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:17:18,757 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:17:18,759 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:17:18] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-11 10:18:16,603 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 10:18:16,603 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 10:18:16,603 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 10:18:16,603 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 10:18:16,604 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 10:18:16,604 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 10:18:16,604 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 10:18:16,604 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 10:18:16,604 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 10:18:16,604 - INFO - [database.py:294] - Closing database connection
2025-08-11 10:18:16,604 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 10:18:16,605 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 10:18:16,605 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 10:18:16,605 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 10:18:16,606 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 10:18:16,606 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 10:18:16,606 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 10:18:16,606 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 10:18:16,606 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 10:18:16,606 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 10:18:16,606 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 10:18:16,607 - INFO - [database.py:294] - Closing database connection
2025-08-11 10:18:16,607 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 10:18:16,607 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 10:20:12,853 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:12,853 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:12,853 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:12,854 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:12,855 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:20:16,926 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 10:20:16,929 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:16,929 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:16,961 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:16,961 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:16,961 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:16,962 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:16,962 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:16,962 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:16,962 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:16,992 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:16,993 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:16,993 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:16,993 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:16,993 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:16,993 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:16,993 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:17,029 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:17,029 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:17,029 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:17,029 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:17,029 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:17,030 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 10:20:17,030 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:17,030 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:17,063 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:17,063 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 10:20:17,063 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:20:17,063 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:17,064 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:17,064 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:17,064 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:17,064 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:20:17,070 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 10:20:17,087 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 10:20:17,089 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 10:20:17,091 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 10:20:17,124 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:17,125 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:17,159 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:17,159 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:17,160 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:17,160 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:17,160 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:17,160 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:17,160 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:17,197 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:17,197 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:17,198 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:17,198 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:17,198 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:17,198 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:17,199 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:17,242 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:17,242 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:17,242 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:17,242 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:17,243 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:17,243 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 10:20:17,243 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:17,243 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:17,280 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:17,280 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 10:20:17,280 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:20:17,280 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 10:20:17,281 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 10:20:17,281 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 10:20:17,281 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 10:20:17,281 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:20:17,301 - INFO - [app.py:727] - Initializing application-wide components
2025-08-11 10:20:17,303 - INFO - [app.py:61] - Successfully started MCP server: dataengineer
2025-08-11 10:20:17,303 - INFO - [app.py:729] - Application-wide components initialization complete
2025-08-11 10:20:17,305 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 10:20:17,305 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 10:20:49,028 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 10:20:49,058 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /knowledge HTTP/1.1" 200 -
2025-08-11 10:20:49,254 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 10:20:49,386 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 10:20:49,400 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 10:20:49,402 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 10:20:49,404 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 10:20:49,410 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 10:20:49,552 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 10:20:49,710 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 10:20:49,718 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 10:20:49,724 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 10:20:49,727 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 10:20:49,732 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 10:20:49,854 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:49] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 10:20:50,017 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 10:20:50,042 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 10:20:50,047 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 10:20:50,053 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 10:20:50,053 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 10:20:50,164 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 10:20:50,330 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 10:20:50,343 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 10:20:50,348 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 10:20:50,360 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 10:20:50,362 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 10:20:50,471 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 10:20:50,634 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 10:20:50,648 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 10:20:50,657 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 10:20:50,663 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 10:20:50,664 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 10:20:50,768 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 10:20:50,947 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:50] "GET /static/js/knowledge-base.js HTTP/1.1" 200 -
2025-08-11 10:20:51,260 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-11 10:20:51,272 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:51] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 10:20:51,287 - INFO - [knowledge_manager.py:33] - Initializing Knowledge Manager
2025-08-11 10:20:51,288 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:51] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 10:20:51,357 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-11 10:20:51,360 - ERROR - [vector_store_client.py:50] - ChromaDB service connection error: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4b61510>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1289, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1048, in _send_output
    self.send(msg)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 986, in send
    self.connect()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7d25d4b61510>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4b61510>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/vector_store_client.py", line 39, in connect
    response = self.session.get(f"{self.service_url}/health", timeout=10)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4b61510>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-11 10:20:51,368 - ERROR - [vector_store_client.py:137] - Error initializing collection knowledge_chunks: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/knowledge_chunks (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4bf1410>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1289, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1048, in _send_output
    self.send(msg)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 986, in send
    self.connect()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7d25d4bf1410>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/knowledge_chunks (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4bf1410>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/vector_store_client.py", line 119, in init_collection
    response = self.session.get(f"{self.service_url}/collections/{collection_name}")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /collections/knowledge_chunks (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4bf1410>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-11 10:20:51,370 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:20:51,370 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:20:51,397 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:20:51,398 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:51] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-11 10:20:51,517 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:51] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 10:20:51,664 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:51] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 10:20:51,791 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:51] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 10:20:53,698 - DEBUG - [app.py:163] - Main page requested
2025-08-11 10:20:53,700 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:53] "GET / HTTP/1.1" 200 -
2025-08-11 10:20:53,931 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 10:20:53,936 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:53] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 10:20:54,075 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:54] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-11 10:20:54,164 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:54] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-11 10:20:58,640 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:58] "GET /query-editor HTTP/1.1" 200 -
2025-08-11 10:20:58,970 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:58] "[36mGET /static/js/query-editor.js HTTP/1.1[0m" 304 -
2025-08-11 10:20:59,207 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 10:20:59,214 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:59] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 10:20:59,365 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:59] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-11 10:20:59,370 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:59] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-11 10:20:59,799 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:20:59] "GET /knowledge HTTP/1.1" 200 -
2025-08-11 10:21:00,142 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-11 10:21:00,155 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:00] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-11 10:21:00,156 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:00] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 10:21:00,738 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:00] "GET /agent HTTP/1.1" 200 -
2025-08-11 10:21:01,065 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:01] "GET /static/js/tool-confirmation.js HTTP/1.1" 200 -
2025-08-11 10:21:01,082 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:01] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-11 10:21:01,314 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-11 10:21:01,321 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:01] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 10:21:01,395 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:01] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-11 10:21:02,200 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:02] "GET /data-mapping/ HTTP/1.1" 200 -
2025-08-11 10:21:02,527 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:02] "GET /static/js/data-mapping.js HTTP/1.1" 200 -
2025-08-11 10:21:02,761 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-11 10:21:02,767 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:02] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 10:21:02,850 - INFO - [data_mapping_routes.py:93] - Available MCP servers: ['Data Mapping Analyst', 'Engineer', 'Skills', 'Weather', 'dataengineer']
2025-08-11 10:21:02,857 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 10:21:02,857 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:21:02,858 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:21:02,902 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:21:02,902 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 10:21:02,902 - WARNING - [data_mapping_routes.py:106] - Could not connect to data mapping server: Data Mapping Analyst
2025-08-11 10:21:02,902 - INFO - [data_mapping_routes.py:111] - Data mapping server not found in registry, attempting manual registration
2025-08-11 10:21:02,903 - WARNING - [data_mapping_routes.py:119] - Could not connect to manual data mapping server: HTTPConnectionPool(host='localhost', port=8003): Max retries exceeded with url: /sse (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4b3da10>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-11 10:21:02,904 - WARNING - [data_mapping_routes.py:122] - Data mapping MCP server not found. Agent will work without MCP features.
2025-08-11 10:21:02,910 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:02] "GET /data-mapping/server-status HTTP/1.1" 200 -
2025-08-11 10:21:03,203 - INFO - [app.py:317] - Schema requested for workspace: 
2025-08-11 10:21:03,203 - DEBUG - [app.py:344] - Schema retrieval completed in 0.000s
2025-08-11 10:21:03,205 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:03] "GET /api/schema?workspace= HTTP/1.1" 200 -
2025-08-11 10:21:09,868 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:09] "GET /admin/ HTTP/1.1" 200 -
2025-08-11 10:21:10,090 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:10] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-11 10:21:10,214 - DEBUG - [app.py:231] - Table suggestions requested for workspace: , query: ''
2025-08-11 10:21:10,223 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:10] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 10:21:10,430 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:10] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 10:21:10,434 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:10] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 10:21:20,563 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:20] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 10:21:21,187 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:21] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 10:21:21,296 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:21] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 10:21:36,353 - DEBUG - [app.py:615] - Samples management page requested
2025-08-11 10:21:36,360 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:36] "GET /samples HTTP/1.1" 200 -
2025-08-11 10:21:36,697 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:36] "GET /static/js/samples.js HTTP/1.1" 200 -
2025-08-11 10:21:36,930 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 10:21:36,935 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:36] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 10:21:37,002 - DEBUG - [app.py:623] - Workspaces list requested
2025-08-11 10:21:37,004 - DEBUG - [app.py:654] - Tables list requested for workspace: 
2025-08-11 10:21:37,016 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:37] "GET /api/workspaces HTTP/1.1" 200 -
2025-08-11 10:21:37,016 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 10:21:37,017 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:37] "GET /api/tables?workspace= HTTP/1.1" 200 -
2025-08-11 10:21:37,018 - INFO - [feedback_manager.py:49] - Attempting database connection
2025-08-11 10:21:37,019 - INFO - [feedback_manager.py:53] - Database connection established in 0.00s
2025-08-11 10:21:37,019 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-11 10:21:37,021 - ERROR - [vector_store_client.py:50] - ChromaDB service connection error: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4235e90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1289, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 1048, in _send_output
    self.send(msg)
  File "/home/vijay/anaconda3/lib/python3.11/http/client.py", line 986, in send
    self.connect()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7d25d4235e90>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4235e90>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/vector_store_client.py", line 39, in connect
    response = self.session.get(f"{self.service_url}/health", timeout=10)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8001): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d25d4235e90>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-11 10:21:37,022 - INFO - [feedback_manager.py:58] - Failed to connect to vector store, vector similarity search will be unavailable
2025-08-11 10:21:37,024 - INFO - [feedback_manager.py:534] - Retrieved 5 samples (page 1, limit 10)
2025-08-11 10:21:37,024 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:37] "GET /api/samples?page=1&limit=10 HTTP/1.1" 200 -
2025-08-11 10:21:54,610 - DEBUG - [app.py:163] - Main page requested
2025-08-11 10:21:54,613 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:54] "GET / HTTP/1.1" 200 -
2025-08-11 10:21:54,964 - DEBUG - [app.py:231] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 10:21:54,980 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:54] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 10:21:55,058 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:55] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-11 10:21:55,090 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:21:55] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-11 10:24:42,866 - INFO - [sql_generator.py:37] - Processing query: 'get me all customers'
2025-08-11 10:24:42,867 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:42] "POST /api/query HTTP/1.1" 200 -
2025-08-11 10:24:42,867 - INFO - [intent_agent.py:27] - Intent detection started for query: 'get me all customers'
2025-08-11 10:24:42,868 - INFO - [intent_agent.py:38] - Using default intent 'data_retrieval' without calling LLM
2025-08-11 10:24:42,869 - INFO - [intent_agent.py:41] - Intent detection completed in 0.00s
2025-08-11 10:24:42,869 - INFO - [sql_generator.py:45] - Detected intent: data_retrieval
2025-08-11 10:24:42,869 - INFO - [sql_generator.py:141] - Starting SQL generation process
2025-08-11 10:24:42,870 - INFO - [database.py:80] - Attempting database connection
2025-08-11 10:24:42,871 - INFO - [database.py:84] - Database connection established in 0.00s
2025-08-11 10:24:42,871 - INFO - [table_agent.py:28] - Table selection started for query: 'get me all customers'
2025-08-11 10:24:42,871 - INFO - [table_agent.py:34] - Available tables (5): customers, products, orders, order_items, sales_metrics
2025-08-11 10:24:42,872 - INFO - [table_agent.py:64] - Sending request to AI model for table selection
2025-08-11 10:24:42,873 - INFO - [llm_engine.py:128] - [TABLE] Completion generation started (format: openai)
2025-08-11 10:24:42,873 - INFO - [llm_engine.py:193] - [TABLE] Prompt: [{'role': 'system', 'content': "You are a table selection agent for a Text-to-SQL system.\nYour job is to identify which database tables are most relevant to a user query.\nYou will be provided with table names and their descriptions.\nReturn ONLY the names of relevant tables, separated by commas. Be selective and choose\nonly the tables that are directly needed to answer the query. If you're unsure,\ninclude tables that might be related. Return only table names in your response."}, {'role': 'us... (truncated)
2025-08-11 10:24:42,873 - INFO - [llm_engine.py:197] - [TABLE] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-11 10:24:42,874 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are a table selection agent for a Text-to-SQL system.\nYour job is to identify which database tables are most relevant to a user query.\nYou will be provided with table names and their descriptions.\nReturn ONLY the names of relevant tables, separated by commas. Be selective and choose\nonly the tables that are directly needed to answer the query. If you're unsure,\ninclude tables that might be related. Return only table names in your response."}, {'role': 'user', 'content': 'Available tables:\ncustomers: Customer information and profiles\nproducts: Product catalog and inventory\norders: Customer orders and transactions\norder_items: Individual items within each order\nsales_metrics: Aggregated sales data by channel\n\nUser query: get me all customers'}]
2025-08-11 10:24:43,362 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:43] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:43,433 - INFO - [llm_engine.py:245] - [TABLE] Model response received in 0.56s
2025-08-11 10:24:43,433 - INFO - [llm_engine.py:254] - [TABLE] Raw model response: 'customers
'
2025-08-11 10:24:43,433 - INFO - [llm_engine.py:257] - [TABLE] Completion generation completed in 0.56s
2025-08-11 10:24:43,434 - INFO - [llm_engine.py:258] - **************************
2025-08-11 10:24:43,434 - INFO - [table_agent.py:69] - Raw model response: 'customers'
2025-08-11 10:24:43,434 - INFO - [table_agent.py:90] - Table selection completed in 0.56s. Selected: customers
2025-08-11 10:24:43,434 - INFO - [column_agent.py:29] - Column pruning started for query: 'get me all customers'
2025-08-11 10:24:43,434 - INFO - [column_agent.py:30] - Processing tables: customers
2025-08-11 10:24:43,435 - INFO - [column_agent.py:38] - Only one table involved (customers). Skipping LLM call and including all columns.
2025-08-11 10:24:43,435 - INFO - [feedback_manager.py:250] - Stage 1: Vector search for 'get me all customers...'
2025-08-11 10:24:43,435 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:24:43,435 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:24:43,475 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:24:43,475 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-11 10:24:44,134 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:44] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:44,391 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:44] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:44,785 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:44] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:45,623 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:45] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:45,791 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:45] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:46,071 - INFO - [llm_engine.py:59] - Embedding model loaded in 2.60s
2025-08-11 10:24:46,162 - INFO - [llm_engine.py:85] - Generated embedding in 0.09s with shape (384,)
2025-08-11 10:24:46,179 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:46] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:46,204 - INFO - [feedback_manager.py:278] - Found 1 initial candidates from vector search
2025-08-11 10:24:46,204 - INFO - [feedback_manager.py:346] - Less than 2 candidates, skipping reranking
2025-08-11 10:24:46,204 - INFO - [sql_generator.py:280] - Found 1 similar queries with reranking
2025-08-11 10:24:46,204 - INFO - [sql_generator.py:302] - Added similar query #1 from manual (score: 0.5478): @customers count...
2025-08-11 10:24:46,204 - INFO - [azure_client.py:35] - SQL generation started for query: 'get me all customers'
2025-08-11 10:24:46,205 - INFO - [azure_client.py:69] - Including schema information (587 chars)
2025-08-11 10:24:46,205 - INFO - [azure_client.py:97] - Including 1 SQL examples from manual similarity search
2025-08-11 10:24:46,205 - INFO - [azure_client.py:114] - PROMPT: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: @customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: get me all customers'}]
2025-08-11 10:24:46,205 - INFO - [llm_engine.py:128] - [SQL_GEN] Completion generation started (format: openai)
2025-08-11 10:24:46,205 - INFO - [llm_engine.py:193] - [SQL_GEN] Prompt: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief ... (truncated)
2025-08-11 10:24:46,205 - INFO - [llm_engine.py:197] - [SQL_GEN] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-11 10:24:46,206 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: @customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: get me all customers'}]
2025-08-11 10:24:46,939 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:46] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:46,949 - INFO - [llm_engine.py:245] - [SQL_GEN] Model response received in 0.74s
2025-08-11 10:24:46,951 - INFO - [llm_engine.py:254] - [SQL_GEN] Raw model response: 'Here's a query that will retrieve all columns for all customers.

```sql
SELECT 
    *
FROM customers;
```'
2025-08-11 10:24:46,951 - INFO - [llm_engine.py:257] - [SQL_GEN] Completion generation completed in 0.75s
2025-08-11 10:24:46,951 - INFO - [llm_engine.py:258] - **************************
2025-08-11 10:24:46,952 - INFO - [azure_client.py:150] - Parsing SQL from model response
2025-08-11 10:24:46,952 - INFO - [azure_client.py:157] - Found SQL code block in response
2025-08-11 10:24:46,952 - INFO - [azure_client.py:171] - Extracted SQL query (29 chars) and explanation (64 chars)
2025-08-11 10:24:46,953 - INFO - [azure_client.py:124] - Generated SQL: SELECT 
    *
FROM customers;
2025-08-11 10:24:46,953 - INFO - [azure_client.py:132] - SQL generation completed in 0.75s
2025-08-11 10:24:46,953 - INFO - [database.py:101] - Executing SQL query: SELECT 
    *
FROM customers;
2025-08-11 10:24:46,954 - INFO - [database.py:112] - Query execution started
2025-08-11 10:24:46,956 - INFO - [database.py:117] - Query execution completed in 0.00s
2025-08-11 10:24:46,960 - INFO - [database.py:122] - Query returned 4 rows with 11 columns
2025-08-11 10:24:46,960 - INFO - [database.py:131] - Query processing completed in 0.01s
2025-08-11 10:24:46,965 - INFO - [sql_generator.py:348] - Analyzing query results for dashboard potential
2025-08-11 10:24:46,965 - INFO - [azure_client.py:197] - Dashboard analysis started for query: 'get me all customers'
2025-08-11 10:24:46,965 - INFO - [llm_engine.py:128] - [DASHBOARD_ANALYSIS] Completion generation started (format: openai)
2025-08-11 10:24:46,966 - INFO - [llm_engine.py:193] - [DASHBOARD_ANALYSIS] Prompt: [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axi... (truncated)
2025-08-11 10:24:46,966 - INFO - [llm_engine.py:197] - [DASHBOARD_ANALYSIS] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-11 10:24:46,966 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axis\n5. Suggest meaningful labels and title\n\nReturn your analysis in JSON format exactly like this:\n{\n  "is_suitable": true_or_false,\n  "reason": "brief explanation of why it is or isn\'t suitable",\n  "chart_type": "recommended chart type if suitable",\n  "x_axis": {\n    "column": "column_name for x-axis",\n    "label": "suggested x-axis label"\n  },\n  "y_axis": {\n    "column": "column_name for y-axis",\n    "label": "suggested y-axis label"\n  },\n  "title": "suggested chart title"\n}\n\nMake decisions based on these criteria:\n- Bar charts are good for comparing categories\n- Line charts are good for time series \n- Pie charts are good for part-to-whole relationships (under 7 categories)\n- Scatter plots are good for showing relationships between numeric values\n- Data needs at least one numeric column for most visualizations'}, {'role': 'user', 'content': 'Query: get me all customers\nSQL: SELECT \n    *\nFROM customers;\nColumns: customer_id, first_name, last_name, email, phone, address, city, state, country, postal_code, registration_date\nData Sample:\nRow 1: {"customer_id": 1, "first_name": "John", "last_name": "Doe", "email": "john.doe@example.com", "phone": "123-456-7890", "address": "123 Main St", "city": "New York", "state": "NY", "country": "USA", "postal_code": "10001", "registration_date": "2023-01-15"}\nRow 2: {"customer_id": 2, "first_name": "Jane", "last_name": "Smith", "email": "jane.smith@example.com", "phone": "987-654-3210", "address": "456 Oak Ave", "city": "Los Angeles", "state": "CA", "country": "USA", "postal_code": "90001", "registration_date": "2023-02-20"}\nRow 3: {"customer_id": 3, "first_name": "Alice", "last_name": "Johnson", "email": "alice@example.com", "phone": "555-123-4567", "address": "789 Pine St", "city": "Chicago", "state": "IL", "country": "USA", "postal_code": "60007", "registration_date": "2023-03-10"}\nRow 4: {"customer_id": 4, "first_name": "Bob", "last_name": "Williams", "email": "bob@example.com", "phone": "555-987-6543", "address": "101 Maple Dr", "city": "Houston", "state": "TX", "country": "USA", "postal_code": "77002", "registration_date": "2023-01-05"}\n\n\nAnalyze if this data is suitable for a dashboard visualization. If so, provide recommendations in the required JSON format.'}]
2025-08-11 10:24:47,180 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:47] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:47,552 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:47] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:48,298 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:48] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:48,364 - INFO - [llm_engine.py:245] - [DASHBOARD_ANALYSIS] Model response received in 1.40s
2025-08-11 10:24:48,365 - INFO - [llm_engine.py:254] - [DASHBOARD_ANALYSIS] Raw model response: '```json
{
  "is_suitable": true,
  "reason": "The data contains categorical information like city, state, and country, suitable for a bar chart to show customer distribution by these categories. The registration_date can be used for a time series.",
  "chart_type": "bar",
  "x_axis": {
    "column": "city",
    "label": "City"
  },
  "y_axis": {
    "column": "customer_id",
    "label": "Number of Customers"
  },
  "title": "Customer Distribution by City"
}
```'
2025-08-11 10:24:48,365 - INFO - [llm_engine.py:257] - [DASHBOARD_ANALYSIS] Completion generation completed in 1.40s
2025-08-11 10:24:48,365 - INFO - [llm_engine.py:258] - **************************
2025-08-11 10:24:48,365 - INFO - [azure_client.py:255] - Dashboard analysis results: suitable=True
2025-08-11 10:24:48,365 - INFO - [azure_client.py:264] - Dashboard analysis completed in 1.40s
2025-08-11 10:24:48,365 - INFO - [sql_generator.py:366] - Dashboard analysis completed: suitable=True
2025-08-11 10:24:48,366 - INFO - [sql_generator.py:444] - SQL generation completed in 5.50s
2025-08-11 10:24:48,366 - INFO - [sql_generator.py:125] - Query processing completed in 5.50s
2025-08-11 10:24:48,532 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:48] "GET /api/query/progress/de7725d2-5135-400d-afef-bb9f170a0fb4 HTTP/1.1" 200 -
2025-08-11 10:24:48,788 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:24:48] "GET /static/vendor/monaco-editor/0.36.1/min/vs/base/browser/ui/codicons/codicon/codicon.ttf HTTP/1.1" 200 -
2025-08-11 10:27:34,688 - INFO - [sql_generator.py:37] - Processing query: 'get me all customers who lives in state NY'
2025-08-11 10:27:34,688 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:34] "POST /api/query HTTP/1.1" 200 -
2025-08-11 10:27:34,689 - INFO - [intent_agent.py:27] - Intent detection started for query: 'get me all customers who lives in state NY'
2025-08-11 10:27:34,689 - INFO - [intent_agent.py:38] - Using default intent 'data_retrieval' without calling LLM
2025-08-11 10:27:34,690 - INFO - [intent_agent.py:41] - Intent detection completed in 0.00s
2025-08-11 10:27:34,690 - INFO - [sql_generator.py:45] - Detected intent: data_retrieval
2025-08-11 10:27:34,690 - INFO - [sql_generator.py:141] - Starting SQL generation process
2025-08-11 10:27:34,690 - INFO - [database.py:80] - Attempting database connection
2025-08-11 10:27:34,691 - INFO - [database.py:84] - Database connection established in 0.00s
2025-08-11 10:27:34,692 - INFO - [table_agent.py:28] - Table selection started for query: 'get me all customers who lives in state NY'
2025-08-11 10:27:34,692 - INFO - [table_agent.py:34] - Available tables (5): customers, products, orders, order_items, sales_metrics
2025-08-11 10:27:34,693 - INFO - [table_agent.py:64] - Sending request to AI model for table selection
2025-08-11 10:27:34,693 - INFO - [llm_engine.py:128] - [TABLE] Completion generation started (format: openai)
2025-08-11 10:27:34,693 - INFO - [llm_engine.py:193] - [TABLE] Prompt: [{'role': 'system', 'content': "You are a table selection agent for a Text-to-SQL system.\nYour job is to identify which database tables are most relevant to a user query.\nYou will be provided with table names and their descriptions.\nReturn ONLY the names of relevant tables, separated by commas. Be selective and choose\nonly the tables that are directly needed to answer the query. If you're unsure,\ninclude tables that might be related. Return only table names in your response."}, {'role': 'us... (truncated)
2025-08-11 10:27:34,693 - INFO - [llm_engine.py:197] - [TABLE] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-11 10:27:34,694 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are a table selection agent for a Text-to-SQL system.\nYour job is to identify which database tables are most relevant to a user query.\nYou will be provided with table names and their descriptions.\nReturn ONLY the names of relevant tables, separated by commas. Be selective and choose\nonly the tables that are directly needed to answer the query. If you're unsure,\ninclude tables that might be related. Return only table names in your response."}, {'role': 'user', 'content': 'Available tables:\ncustomers: Customer information and profiles\nproducts: Product catalog and inventory\norders: Customer orders and transactions\norder_items: Individual items within each order\nsales_metrics: Aggregated sales data by channel\n\nUser query: get me all customers who lives in state NY'}]
2025-08-11 10:27:35,176 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:35] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:35,466 - INFO - [llm_engine.py:245] - [TABLE] Model response received in 0.77s
2025-08-11 10:27:35,467 - INFO - [llm_engine.py:254] - [TABLE] Raw model response: 'customers
'
2025-08-11 10:27:35,467 - INFO - [llm_engine.py:257] - [TABLE] Completion generation completed in 0.77s
2025-08-11 10:27:35,467 - INFO - [llm_engine.py:258] - **************************
2025-08-11 10:27:35,467 - INFO - [table_agent.py:69] - Raw model response: 'customers'
2025-08-11 10:27:35,467 - INFO - [table_agent.py:90] - Table selection completed in 0.78s. Selected: customers
2025-08-11 10:27:35,468 - INFO - [column_agent.py:29] - Column pruning started for query: 'get me all customers who lives in state NY'
2025-08-11 10:27:35,468 - INFO - [column_agent.py:30] - Processing tables: customers
2025-08-11 10:27:35,468 - INFO - [column_agent.py:38] - Only one table involved (customers). Skipping LLM call and including all columns.
2025-08-11 10:27:35,468 - INFO - [feedback_manager.py:250] - Stage 1: Vector search for 'get me all customers who lives in state NY...'
2025-08-11 10:27:35,468 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 10:27:35,469 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 10:27:35,497 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 10:27:35,498 - INFO - [llm_engine.py:55] - Loading embedding model 'sentence-transformers/all-MiniLM-L12-v2'
2025-08-11 10:27:35,952 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:35] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:36,194 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:36] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:36,585 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:36] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:37,346 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:37] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:37,576 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:37] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:37,989 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:37] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:38,316 - INFO - [llm_engine.py:59] - Embedding model loaded in 2.82s
2025-08-11 10:27:38,352 - INFO - [llm_engine.py:85] - Generated embedding in 0.04s with shape (384,)
2025-08-11 10:27:38,359 - INFO - [feedback_manager.py:278] - Found 1 initial candidates from vector search
2025-08-11 10:27:38,359 - INFO - [feedback_manager.py:346] - Less than 2 candidates, skipping reranking
2025-08-11 10:27:38,359 - INFO - [sql_generator.py:280] - Found 1 similar queries with reranking
2025-08-11 10:27:38,359 - INFO - [sql_generator.py:302] - Added similar query #1 from manual (score: 0.4415): @customers count...
2025-08-11 10:27:38,359 - INFO - [azure_client.py:35] - SQL generation started for query: 'get me all customers who lives in state NY'
2025-08-11 10:27:38,359 - INFO - [azure_client.py:69] - Including schema information (587 chars)
2025-08-11 10:27:38,360 - INFO - [azure_client.py:97] - Including 1 SQL examples from manual similarity search
2025-08-11 10:27:38,360 - INFO - [azure_client.py:114] - PROMPT: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: @customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: get me all customers who lives in state NY'}]
2025-08-11 10:27:38,360 - INFO - [llm_engine.py:128] - [SQL_GEN] Completion generation started (format: openai)
2025-08-11 10:27:38,360 - INFO - [llm_engine.py:193] - [SQL_GEN] Prompt: [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief ... (truncated)
2025-08-11 10:27:38,361 - INFO - [llm_engine.py:197] - [SQL_GEN] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-11 10:27:38,361 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': "You are an expert SQL assistant. Convert natural language questions into precise, executable SQL queries.\nYour task is to:\n1. Analyze the provided schema carefully, noting table relationships and column types\n2. Generate a SQL query that accurately answers the user's question\n3. Consider performance by selecting only necessary columns\n4. Use appropriate JOIN conditions based on primary/foreign key relationships or provided join conditions\n5. Include a brief explanation of your query\n\nRules:\n- Include table names and column references exactly as provided in the schema\n- Use appropriate SQL functions based on column data types\n- Consider NULL values in your conditions\n- Use table aliases for better readability when joining multiple tables\n- Add column aliases for computed values\n- Format the SQL query with proper indentation\n- If similar queries are provided, strictly use that as format or syntax\n- Return the SQL inside a code block tagged with ```sql\n\nExample output format:\nHere's a query that will [explanation]...\n\n```sql\nSELECT ...\nFROM ...\nWHERE ...\n```"}, {'role': 'user', 'content': "Here's the database schema:\nTable: customers\nDescription: Customer information and profiles\nColumns: customer_id (INTEGER) - Unique customer identifier, first_name (TEXT) - Customer's first name, last_name (TEXT) - Customer's last name, email (TEXT) - Customer's email address (unique), phone (TEXT) - Customer's phone number, address (TEXT) - Customer's street address, city (TEXT) - Customer's city, state (TEXT) - Customer's state/province, country (TEXT) - Customer's country, postal_code (TEXT) - Customer's postal/zip code, registration_date (TEXT) - Date when customer registered\nPrimary Key(s): customer_id\n"}, {'role': 'user', 'content': 'Here are some similar queries that were previously successful:\nQuestion: @customers count\nSQL: SELECT \n    COUNT(customer_id) AS total_customers\nFROM customers;\n\n'}, {'role': 'user', 'content': 'Convert this question to SQL: get me all customers who lives in state NY'}]
2025-08-11 10:27:38,760 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:38] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:38,990 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:38] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:39,143 - INFO - [llm_engine.py:245] - [SQL_GEN] Model response received in 0.78s
2025-08-11 10:27:39,144 - INFO - [llm_engine.py:254] - [SQL_GEN] Raw model response: 'Here's a query that will retrieve all customer information for customers who live in the state of NY.

```sql
SELECT 
    *
FROM customers
WHERE state = 'NY';
```'
2025-08-11 10:27:39,145 - INFO - [llm_engine.py:257] - [SQL_GEN] Completion generation completed in 0.78s
2025-08-11 10:27:39,145 - INFO - [llm_engine.py:258] - **************************
2025-08-11 10:27:39,146 - INFO - [azure_client.py:150] - Parsing SQL from model response
2025-08-11 10:27:39,147 - INFO - [azure_client.py:157] - Found SQL code block in response
2025-08-11 10:27:39,147 - INFO - [azure_client.py:171] - Extracted SQL query (48 chars) and explanation (101 chars)
2025-08-11 10:27:39,148 - INFO - [azure_client.py:124] - Generated SQL: SELECT 
    *
FROM customers
WHERE state = 'NY';
2025-08-11 10:27:39,149 - INFO - [azure_client.py:132] - SQL generation completed in 0.79s
2025-08-11 10:27:39,150 - INFO - [database.py:101] - Executing SQL query: SELECT 
    *
FROM customers
WHERE state = 'NY';
2025-08-11 10:27:39,152 - INFO - [database.py:112] - Query execution started
2025-08-11 10:27:39,154 - INFO - [database.py:117] - Query execution completed in 0.00s
2025-08-11 10:27:39,156 - INFO - [database.py:122] - Query returned 1 rows with 11 columns
2025-08-11 10:27:39,156 - INFO - [database.py:131] - Query processing completed in 0.01s
2025-08-11 10:27:39,159 - INFO - [sql_generator.py:348] - Analyzing query results for dashboard potential
2025-08-11 10:27:39,159 - INFO - [azure_client.py:197] - Dashboard analysis started for query: 'get me all customers who lives in state NY'
2025-08-11 10:27:39,160 - INFO - [llm_engine.py:128] - [DASHBOARD_ANALYSIS] Completion generation started (format: openai)
2025-08-11 10:27:39,160 - INFO - [llm_engine.py:193] - [DASHBOARD_ANALYSIS] Prompt: [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axi... (truncated)
2025-08-11 10:27:39,160 - INFO - [llm_engine.py:197] - [DASHBOARD_ANALYSIS] Sending request to gemini-2.0-flash-lite with max_tokens=2000, temperature=0.7, stream=False
2025-08-11 10:27:39,161 - INFO - [llm_engine.py:201] - message [{'role': 'system', 'content': 'You are a data visualization expert. Analyze the given query results and determine if they\'re suitable for a dashboard visualization.\n\nYour task is to:\n1. Analyze the columns and data\n2. Determine if the data is suitable for visualization (has numeric values and categorical data)\n3. If suitable, recommend the best chart type (bar, line, pie, etc.)\n4. Identify the best columns for X and Y axes (or equivalent based on chart type). Only one column for each axis\n5. Suggest meaningful labels and title\n\nReturn your analysis in JSON format exactly like this:\n{\n  "is_suitable": true_or_false,\n  "reason": "brief explanation of why it is or isn\'t suitable",\n  "chart_type": "recommended chart type if suitable",\n  "x_axis": {\n    "column": "column_name for x-axis",\n    "label": "suggested x-axis label"\n  },\n  "y_axis": {\n    "column": "column_name for y-axis",\n    "label": "suggested y-axis label"\n  },\n  "title": "suggested chart title"\n}\n\nMake decisions based on these criteria:\n- Bar charts are good for comparing categories\n- Line charts are good for time series \n- Pie charts are good for part-to-whole relationships (under 7 categories)\n- Scatter plots are good for showing relationships between numeric values\n- Data needs at least one numeric column for most visualizations'}, {'role': 'user', 'content': 'Query: get me all customers who lives in state NY\nSQL: SELECT \n    *\nFROM customers\nWHERE state = \'NY\';\nColumns: customer_id, first_name, last_name, email, phone, address, city, state, country, postal_code, registration_date\nData Sample:\nRow 1: {"customer_id": 1, "first_name": "John", "last_name": "Doe", "email": "john.doe@example.com", "phone": "123-456-7890", "address": "123 Main St", "city": "New York", "state": "NY", "country": "USA", "postal_code": "10001", "registration_date": "2023-01-15"}\n\n\nAnalyze if this data is suitable for a dashboard visualization. If so, provide recommendations in the required JSON format.'}]
2025-08-11 10:27:39,389 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:39] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:40,163 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:40] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:40,401 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:40] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 10:27:40,463 - INFO - [llm_engine.py:245] - [DASHBOARD_ANALYSIS] Model response received in 1.30s
2025-08-11 10:27:40,463 - INFO - [llm_engine.py:254] - [DASHBOARD_ANALYSIS] Raw model response: '```json
{
  "is_suitable": false,
  "reason": "The query returns customer data for a single state (NY). There's no aggregation or numerical comparison possible with the current data.  It's a list of individual customer details, not suitable for a dashboard visualization.",
  "chart_type": null,
  "x_axis": null,
  "y_axis": null,
  "title": null
}
```'
2025-08-11 10:27:40,464 - INFO - [llm_engine.py:257] - [DASHBOARD_ANALYSIS] Completion generation completed in 1.30s
2025-08-11 10:27:40,464 - INFO - [llm_engine.py:258] - **************************
2025-08-11 10:27:40,464 - INFO - [azure_client.py:255] - Dashboard analysis results: suitable=False
2025-08-11 10:27:40,464 - INFO - [azure_client.py:264] - Dashboard analysis completed in 1.30s
2025-08-11 10:27:40,464 - INFO - [sql_generator.py:366] - Dashboard analysis completed: suitable=False
2025-08-11 10:27:40,464 - INFO - [sql_generator.py:444] - SQL generation completed in 5.77s
2025-08-11 10:27:40,465 - INFO - [sql_generator.py:125] - Query processing completed in 5.78s
2025-08-11 10:27:40,812 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 10:27:40] "GET /api/query/progress/a307dd9f-899c-4b88-a392-892d999f759e HTTP/1.1" 200 -
2025-08-11 13:44:41,299 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:41,299 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:41,300 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:41,300 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:41,302 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 13:44:44,364 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 13:44:46,467 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 13:44:46,467 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 13:44:46,497 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 13:44:46,497 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:46,497 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:46,498 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:46,498 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:46,498 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 13:44:46,498 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 13:44:46,529 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 13:44:46,529 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:46,529 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:46,529 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:46,529 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:46,530 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 13:44:46,530 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 13:44:46,561 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 13:44:46,561 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:46,562 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:46,562 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:46,562 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:46,562 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 13:44:46,562 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 13:44:46,562 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 13:44:46,595 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 13:44:46,595 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 13:44:46,596 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 13:44:46,596 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:46,596 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:46,596 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:46,597 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:46,597 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 13:44:46,603 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 13:44:46,619 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 13:44:46,622 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 13:44:46,623 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 13:44:46,663 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 13:44:46,663 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 13:44:46,697 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 13:44:46,697 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:46,697 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:46,698 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:46,698 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:46,698 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 13:44:46,698 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 13:44:46,733 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 13:44:46,734 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:46,734 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:46,734 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:46,734 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:46,734 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 13:44:46,734 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 13:44:46,771 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 13:44:46,771 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:46,771 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:46,771 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:46,771 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:46,771 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 13:44:46,772 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 13:44:46,772 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 13:44:46,807 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 13:44:46,808 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 13:44:46,808 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 13:44:46,808 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 13:44:46,808 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 13:44:46,808 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 13:44:46,808 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 13:44:46,808 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 13:44:46,827 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 13:44:46,830 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 13:44:46,843 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 13:44:46,843 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 13:44:46,845 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 13:44:46,845 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 13:44:57,227 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:44:57] "[32mGET /agent HTTP/1.1[0m" 302 -
2025-08-11 13:44:57,484 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:44:57] "GET /login HTTP/1.1" 200 -
2025-08-11 13:44:57,536 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:44:57] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 13:44:57,835 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:44:57] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 13:44:57,840 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:44:57] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 13:45:06,273 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 13:45:06,503 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:06] "[32mPOST /login HTTP/1.1[0m" 302 -
2025-08-11 13:45:06,795 - DEBUG - [app.py:172] - Main page requested
2025-08-11 13:45:06,817 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:06] "GET / HTTP/1.1" 200 -
2025-08-11 13:45:07,029 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 13:45:07,131 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 13:45:07,134 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 13:45:07,136 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,140 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,142 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,320 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 13:45:07,419 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,422 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,429 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,432 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,433 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,626 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,701 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 13:45:07,706 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:07] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 13:45:08,020 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 13:45:08,027 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:08] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 13:45:36,178 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:36] "GET /agent HTTP/1.1" 200 -
2025-08-11 13:45:36,509 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:36] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 13:45:36,521 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:36] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-11 13:45:36,739 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 13:45:36,746 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:36] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 13:45:36,815 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:36] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-11 13:45:36,816 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:36] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 13:45:36,818 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:45:36] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 13:46:23,711 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:46:23] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 13:46:23,933 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:46:23] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-11 13:46:24,043 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:46:24] "GET /static/js/admin/agent-teams.js HTTP/1.1" 200 -
2025-08-11 13:46:24,057 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 13:46:24,074 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:46:24] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 13:46:24,389 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:46:24] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 13:46:24,389 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:46:24] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 13:46:24,390 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:46:24] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 13:46:24,398 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:46:24] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 13:47:20,892 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:47:20] "POST /api/agent/teams HTTP/1.1" 200 -
2025-08-11 13:47:21,112 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:47:21] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 13:47:21,181 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:47:21] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 13:47:25,283 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:47:25] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 13:47:37,103 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:47:37] "POST /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 13:47:37,333 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:47:37] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 13:47:37,412 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 13:47:37] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:00:24,407 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:00:24,408 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:00:24,408 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:00:24,408 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:00:24,409 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:00:24,409 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:00:24,409 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:00:24,410 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:00:24,410 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:00:24,410 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:00:24,410 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:00:24,410 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:00:24,411 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:00:24,412 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:00:24,412 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:00:24,412 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:00:24,412 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:00:24,412 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:00:24,413 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:00:24,413 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:00:24,413 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:00:24,413 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:00:24,413 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:00:24,414 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:00:28,600 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:28,600 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:28,600 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:28,600 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:28,601 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:00:31,927 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:00:33,950 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:00:33,950 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:00:33,979 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:00:33,979 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:33,979 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:33,979 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:33,979 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:33,979 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:00:33,979 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:00:34,008 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:00:34,009 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:34,009 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:34,009 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:34,009 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:34,009 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:00:34,010 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:00:34,035 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:00:34,036 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:34,036 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:34,036 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:34,036 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:34,036 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:00:34,036 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:00:34,036 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:00:34,064 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:00:34,064 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:00:34,064 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:00:34,064 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:34,064 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:34,064 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:34,065 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:34,065 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:00:34,071 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 14:00:34,084 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 14:00:34,088 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 14:00:34,089 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 14:00:34,122 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:00:34,122 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:00:34,152 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:00:34,152 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:34,152 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:34,152 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:34,152 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:34,153 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:00:34,153 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:00:34,181 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:00:34,182 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:34,182 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:34,182 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:34,182 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:34,182 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:00:34,183 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:00:34,210 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:00:34,210 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:34,210 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:34,210 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:34,211 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:34,211 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:00:34,211 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:00:34,211 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:00:34,241 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:00:34,241 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:00:34,242 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:00:34,242 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:00:34,242 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:00:34,242 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:00:34,242 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:00:34,242 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:00:34,257 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 14:00:34,259 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 14:00:34,260 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 14:00:34,260 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 14:00:34,262 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 14:00:34,262 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 14:00:55,490 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 14:00:55,520 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:55] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 14:00:55,742 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:55] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 14:00:55,857 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:55] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 14:00:55,869 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:55] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 14:00:55,882 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:55] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 14:00:55,893 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:55] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 14:00:55,895 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:55] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 14:00:56,065 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 14:00:56,203 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 14:00:56,207 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 14:00:56,217 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,219 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,221 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,372 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 14:00:56,518 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,532 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,541 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,549 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,560 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,678 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 14:00:56,820 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 14:00:56,849 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 14:00:56,855 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 14:00:56,867 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 14:00:56,868 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 14:00:56,995 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:56] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 14:00:57,135 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 14:00:57,166 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 14:00:57,175 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 14:00:57,180 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 14:00:57,187 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 14:00:57,303 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 14:00:57,450 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-11 14:00:57,465 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/js/admin/agent-teams.js HTTP/1.1" 200 -
2025-08-11 14:00:57,787 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:00:57,824 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:00:57,825 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 14:00:57,831 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:00:57,841 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:00:57,846 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 14:00:57,857 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:57] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 14:00:58,228 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:58] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 14:00:58,241 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:58] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 14:00:58,472 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:00:58] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 14:01:00,906 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:01:00] "GET /api/agent/teams/1 HTTP/1.1" 200 -
2025-08-11 14:01:01,222 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 14:01:01,223 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:01:01,224 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:01:01,269 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:01:01,269 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 14:01:01,269 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 14:01:01,269 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 14:01:01,270 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 14:01:01,276 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 14:01:01,276 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 14:01:01,277 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 14:01:01,277 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 14:01:02,006 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 14:01:02,012 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 14:01:02,019 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:01:02] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 14:02:11,218 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 24, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 112, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 14:02:11,230 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:11] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 14:02:16,235 - ERROR - [app.py:875] - Exception on /api/agent/teams/1 [PUT]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 52, in team_detail
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 103, in save
    cur.execute(
sqlite3.OperationalError: database is locked
2025-08-11 14:02:16,245 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:16] "[35m[1mPUT /api/agent/teams/1 HTTP/1.1[0m" 500 -
2025-08-11 14:02:16,266 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:16] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:02:16,558 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:16] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:02:28,122 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:28] "GET /api/agent/teams/1 HTTP/1.1" 200 -
2025-08-11 14:02:28,351 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:28] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 14:02:36,289 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:36] "GET /api/agent/workflows/1 HTTP/1.1" 200 -
2025-08-11 14:02:36,614 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:36] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:02:41,017 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:41] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:02:44,669 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:44] "GET /agent HTTP/1.1" 200 -
2025-08-11 14:02:44,905 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:44] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 14:02:44,996 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:44] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-11 14:02:45,005 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:02:45,307 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:45] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:02:45,308 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:45] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:02:58,846 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:02:58] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 14:03:05,055 - ERROR - [user_manager.py:558] - Error logging audit event: (sqlite3.OperationalError) database is locked
[SQL: INSERT INTO audit_logs (user_id, action, details, timestamp, ip_address, query_text, sql_query, response) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (1, 'get_table_suggestions', 'Retrieved 5 table suggestions for workspace: ', '2025-08-11 06:02:45.005752', '127.0.0.1', None, None, None)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
2025-08-11 14:03:05,058 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:03:05] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:06:11,753 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 14:06:11,755 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 14:06:11,755 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 14:06:11,756 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 14:06:11,756 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:06:11,756 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:06:11,757 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:06:11,757 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:06:11,757 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:06:11,757 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:06:11,758 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:06:11,758 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:06:11,758 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:06:11,758 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:06:11,759 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:06:11,759 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:06:11,760 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:06:11,760 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:06:11,760 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:06:11,760 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:06:11,761 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:06:11,761 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:06:11,761 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:06:11,761 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:06:11,761 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:06:11,762 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:06:11,762 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:06:11,762 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:07:26,547 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:07:26,547 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:07:26,547 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:07:26,547 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:07:26,548 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:07:29,608 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:07:29,848 - WARNING - [autogen_orchestrator.py:21] - New AutoGen packages not available: cannot import name 'MaxTurnTermination' from 'autogen_agentchat.conditions' (/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/conditions/__init__.py)
2025-08-11 14:08:27,375 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:08:27,375 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:08:27,375 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:08:27,375 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:08:27,376 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:08:30,227 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:08:30,439 - WARNING - [autogen_orchestrator.py:21] - New AutoGen packages not available: cannot import name 'MaxTurnTermination' from 'autogen_agentchat.conditions' (/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/conditions/__init__.py)
2025-08-11 14:09:19,709 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:19,710 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:19,710 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:19,710 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:19,711 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:09:24,644 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:09:24,861 - WARNING - [autogen_orchestrator.py:21] - New AutoGen packages not available: cannot import name 'MaxTurnTermination' from 'autogen_agentchat.conditions' (/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/conditions/__init__.py)
2025-08-11 14:09:26,839 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:26,839 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:26,867 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:26,868 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:26,868 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:26,868 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:26,868 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:26,868 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:26,869 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:26,895 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:26,895 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:26,895 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:26,895 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:26,895 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:26,895 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:26,895 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:26,923 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:26,923 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:26,923 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:26,923 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:26,923 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:26,924 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:09:26,924 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:26,924 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:26,951 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:26,951 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:09:26,951 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:09:26,951 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:26,952 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:26,952 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:26,952 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:26,952 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:09:26,956 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 14:09:26,970 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 14:09:26,974 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 14:09:26,974 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 14:09:27,003 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:27,003 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:27,030 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:27,030 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:27,031 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:27,031 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:27,031 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:27,031 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:27,031 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:27,061 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:27,062 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:27,062 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:27,062 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:27,062 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:27,062 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:27,063 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:27,089 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:27,089 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:27,089 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:27,089 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:27,089 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:27,090 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:09:27,090 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:27,090 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:27,117 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:27,117 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:09:27,117 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:09:27,117 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:09:27,118 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:09:27,118 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:09:27,118 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:09:27,118 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:09:27,131 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 14:09:27,132 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 14:09:27,133 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 14:09:27,133 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 14:09:27,134 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 14:09:27,135 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 14:09:33,317 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 14:09:33,339 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:33] "GET /agent HTTP/1.1" 200 -
2025-08-11 14:09:33,526 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:09:33,533 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:33] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:09:33,712 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:33] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:09:33,713 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:33] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:09:38,749 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:38] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 14:09:39,072 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:39] "[36mGET /static/js/admin/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 14:09:39,077 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:39] "[36mGET /static/js/admin/agent-teams.js HTTP/1.1[0m" 304 -
2025-08-11 14:09:39,291 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:09:39,310 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:39] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:09:39,395 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:39] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:09:39,399 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:39] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:09:39,401 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:39] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 14:09:39,401 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:39] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 14:09:42,230 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:42] "DELETE /api/agent/teams/1 HTTP/1.1" 200 -
2025-08-11 14:09:42,527 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:42] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:09:42,528 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:42] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:09:45,558 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:45] "DELETE /api/agent/workflows/1 HTTP/1.1" 200 -
2025-08-11 14:09:45,853 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:45] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:09:45,854 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:45] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:09:47,066 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 14:09:47,066 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:09:47,066 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:09:47,111 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:09:47,111 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 14:09:47,111 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 14:09:47,111 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 14:09:47,111 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 14:09:47,116 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 14:09:47,116 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 14:09:47,116 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 14:09:47,116 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 14:09:47,788 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 14:09:47,795 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 14:09:47,810 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:09:47] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 14:11:01,773 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:11:01] "POST /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:11:02,014 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:11:02] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:11:02,074 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:11:02] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:11:16,667 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:11:16] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:11:39,001 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:11:39] "POST /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:11:39,229 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:11:39] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:11:39,307 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:11:39] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:11:55,555 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:11:55] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 14:12:18,529 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:18] "GET /agent HTTP/1.1" 200 -
2025-08-11 14:12:18,770 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:12:18,777 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:18] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:12:18,904 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:18] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:12:18,906 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:18] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:12:23,124 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:23] "[31m[1mPOST /api/agent/autogen/chat HTTP/1.1[0m" 400 -
2025-08-11 14:12:39,629 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:39] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 14:12:39,870 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:39] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 14:12:39,896 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:39] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 14:12:46,693 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:46] "GET /agent HTTP/1.1" 200 -
2025-08-11 14:12:47,016 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:12:47,024 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:47] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:12:47,051 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:47] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:12:47,057 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:47] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:12:47,121 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:47] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 14:12:47,123 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:47] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 14:12:47,128 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:47] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 14:12:54,142 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:12:54] "[31m[1mPOST /api/agent/autogen/chat HTTP/1.1[0m" 400 -
2025-08-11 14:14:24,925 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:24] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 14:14:25,146 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:14:25,153 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:25] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:14:25,273 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:25] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 14:14:25,300 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:25] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 14:14:25,301 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:25] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:14:25,375 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:25] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 14:14:25,378 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:25] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:14:25,446 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:25] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 14:14:25,567 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:25] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 14:14:35,833 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:14:35] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 14:15:25,621 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 14:15:25,623 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 14:15:25,624 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 14:15:25,624 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 14:15:25,624 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:15:25,625 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:15:25,625 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:15:25,625 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:15:25,626 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:15:25,626 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:15:25,626 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:15:25,626 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:15:25,627 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:15:25,627 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:15:25,627 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:15:25,627 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:15:25,629 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:15:25,629 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:15:25,629 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:15:25,629 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:15:25,630 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:15:25,630 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:15:25,630 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:15:25,630 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:15:25,630 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:15:25,631 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:15:25,631 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:15:25,631 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:16:40,999 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:40,999 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:40,999 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:40,999 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:41,001 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:16:44,100 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:16:44,423 - WARNING - [autogen_orchestrator.py:21] - New AutoGen packages not available: cannot import name 'MaxTurnTermination' from 'autogen_agentchat.conditions' (/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/conditions/__init__.py)
2025-08-11 14:16:47,535 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:16:47,535 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:16:47,573 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:16:47,573 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:47,574 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:47,574 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:47,574 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:47,574 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:16:47,574 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:16:47,622 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:16:47,622 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:47,623 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:47,623 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:47,623 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:47,623 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:16:47,624 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:16:47,663 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:16:47,663 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:47,664 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:47,664 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:47,664 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:47,664 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:16:47,664 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:16:47,664 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:16:47,708 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:16:47,708 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:16:47,708 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:16:47,708 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:47,709 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:47,709 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:47,709 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:47,709 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:16:47,718 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 14:16:47,737 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 14:16:47,741 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 14:16:47,742 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 14:16:47,786 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:16:47,786 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:16:47,827 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:16:47,828 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:47,828 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:47,828 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:47,828 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:47,828 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:16:47,828 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:16:47,869 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:16:47,869 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:47,869 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:47,869 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:47,869 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:47,870 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:16:47,870 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:16:49,792 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:16:49,792 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:49,793 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:49,793 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:49,793 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:49,793 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:16:49,793 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:16:49,793 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:16:49,835 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:16:49,835 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:16:49,835 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:16:49,836 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:16:49,836 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:16:49,836 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:16:49,836 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:16:49,836 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:16:49,856 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 14:16:49,858 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 14:16:49,859 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 14:16:49,859 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 14:16:49,861 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 14:16:49,861 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 14:17:43,619 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 14:17:43,656 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:43] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 14:17:43,836 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:17:43,844 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:43] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:17:44,008 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:44] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 14:17:44,021 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:44] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:17:44,022 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:44] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 14:17:44,087 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:44] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 14:17:44,088 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:44] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:17:44,146 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:44] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 14:17:44,304 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:44] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 14:17:53,551 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 14:17:53,551 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:17:53,551 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:17:53,595 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:17:53,595 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 14:17:53,597 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:17:53] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 14:18:55,204 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:18:55] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 14:21:38,911 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:21:38,911 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:21:38,912 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:21:38,912 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:21:38,912 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:21:38,913 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:21:38,913 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:21:38,913 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:21:38,913 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:21:38,914 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:21:38,914 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:21:38,914 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:21:38,915 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:21:38,916 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:21:38,916 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:21:38,916 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:21:38,916 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:21:38,916 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:21:38,917 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:21:38,917 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:21:38,917 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:21:38,917 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:21:38,917 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:21:38,918 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:21:44,029 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:44,029 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:44,029 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:44,029 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:44,030 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:21:46,949 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:21:47,161 - WARNING - [autogen_orchestrator.py:24] - New AutoGen packages not available: cannot import name 'MaxTurnTermination' from 'autogen_agentchat.conditions' (/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/conditions/__init__.py)
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 18, in <module>
    from autogen_agentchat.conditions import MaxTurnTermination
ImportError: cannot import name 'MaxTurnTermination' from 'autogen_agentchat.conditions' (/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/conditions/__init__.py)

2025-08-11 14:21:49,249 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:21:49,249 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:21:49,275 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:21:49,275 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:49,276 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:49,276 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:49,276 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:49,276 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:21:49,276 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:21:49,301 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:21:49,301 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:49,301 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:49,301 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:49,302 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:49,302 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:21:49,302 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:21:49,353 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:21:49,353 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:49,354 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:49,354 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:49,354 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:49,354 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:21:49,354 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:21:49,354 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:21:49,402 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:21:49,402 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:21:49,402 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:21:49,402 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:49,402 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:49,402 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:49,403 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:49,403 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:21:49,409 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 14:21:49,433 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 14:21:49,435 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 14:21:49,436 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 14:21:49,462 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:21:49,462 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:21:49,489 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:21:49,489 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:49,489 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:49,489 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:49,490 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:49,490 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:21:49,490 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:21:49,515 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:21:49,515 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:49,515 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:49,515 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:49,515 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:49,515 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:21:49,515 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:21:49,541 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:21:49,541 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:49,541 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:49,541 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:49,541 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:49,541 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:21:49,541 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:21:49,542 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:21:49,569 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:21:49,569 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:21:49,569 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:21:49,569 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:21:49,570 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:21:49,570 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:21:49,570 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:21:49,570 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:21:49,581 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 14:21:49,583 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 14:21:49,584 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 14:21:49,584 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 14:21:49,585 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 14:21:49,585 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 14:21:57,707 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 14:21:57,744 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:57] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 14:21:57,941 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:21:57,949 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:57] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:21:58,087 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:58] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 14:21:58,101 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:58] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:21:58,113 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:58] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 14:21:58,163 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:58] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 14:21:58,164 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:58] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:21:58,239 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:58] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 14:21:58,382 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:21:58] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 14:22:02,735 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 14:22:02,736 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:22:02,736 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:22:02,793 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:22:02,793 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 14:22:02,794 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:22:02] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 14:35:23,881 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:35:23,882 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:35:23,883 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:35:23,883 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:35:23,884 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:35:23,884 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:35:23,884 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:35:23,885 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:35:23,885 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:35:23,885 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:35:23,886 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:35:23,886 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:35:23,887 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:35:23,888 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:35:23,888 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:35:23,888 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:35:23,889 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:35:23,889 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:35:23,889 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:35:23,890 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:35:23,890 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:35:23,890 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:35:23,891 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:35:23,891 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:35:28,675 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:28,675 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:28,675 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:28,675 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:28,676 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:35:31,858 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:35:34,527 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:34,528 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:34,554 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:34,554 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:34,555 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:34,555 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:34,555 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:34,555 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:34,555 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:34,584 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:34,584 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:34,584 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:34,584 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:34,584 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:34,584 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:34,584 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:34,615 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:34,616 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:34,616 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:34,616 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:34,616 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:34,616 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:35:34,616 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:34,616 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:34,658 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:34,659 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:35:34,659 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:35:34,659 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:34,659 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:34,659 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:34,659 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:34,659 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:35:34,667 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 14:35:34,688 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 14:35:34,690 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 14:35:34,691 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 14:35:34,723 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:34,724 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:34,755 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:34,755 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:34,755 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:34,755 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:34,755 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:34,756 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:34,756 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:34,790 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:34,790 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:34,790 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:34,790 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:34,791 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:34,791 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:34,791 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:34,820 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:34,820 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:34,820 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:34,820 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:34,820 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:34,821 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:35:34,821 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:34,821 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:34,849 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:34,849 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:35:34,850 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:35:34,850 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:35:34,850 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:35:34,850 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:35:34,850 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:35:34,850 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:35:34,863 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 14:35:34,865 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 14:35:34,866 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 14:35:34,866 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 14:35:34,867 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 14:35:34,867 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 14:35:40,643 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 14:35:40,682 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:40] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 14:35:40,890 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:40] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 14:35:41,026 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 14:35:41,042 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 14:35:41,048 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 14:35:41,051 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 14:35:41,058 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 14:35:41,198 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 14:35:41,360 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 14:35:41,371 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 14:35:41,372 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,383 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,383 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,517 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 14:35:41,672 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,701 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,713 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,714 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,726 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,823 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 14:35:41,994 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:41] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 14:35:42,009 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 14:35:42,014 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 14:35:42,029 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 14:35:42,033 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 14:35:42,147 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 14:35:42,304 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 14:35:42,313 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 14:35:42,318 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 14:35:42,325 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 14:35:42,335 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 14:35:42,463 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 14:35:42,635 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-11 14:35:42,644 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/js/admin/agent-teams.js HTTP/1.1" 200 -
2025-08-11 14:35:42,671 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 14:35:42,673 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 14:35:42,678 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 14:35:42,978 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:35:42,995 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 14:35:42,996 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:42] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:35:43,018 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:43] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:35:43,029 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:43] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:35:43,041 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:43] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 14:35:43,061 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:43] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 14:35:43,432 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:43] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 14:35:43,452 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:43] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 14:35:43,675 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:43] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 14:35:49,733 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 14:35:49,733 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:35:49,734 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:35:49,774 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:35:49,774 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 14:35:49,807 - WARNING - [autogen_orchestrator.py:118] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
2025-08-11 14:35:49,835 - WARNING - [autogen_orchestrator.py:118] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
2025-08-11 14:35:49,836 - ERROR - [autogen_orchestrator.py:219] - Team run failed: AutoGen AgentChat or model client missing
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 199, in run_team
    agents_with_wb, team_obj = await self._build_agents_team(team)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 177, in _build_agents_team
    raise RuntimeError("AutoGen AgentChat or model client missing")
RuntimeError: AutoGen AgentChat or model client missing

2025-08-11 14:35:49,842 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:35:49] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 14:38:21,891 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:38:21,891 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:38:21,891 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:38:21,891 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:38:21,891 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:38:21,892 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:38:21,892 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:38:21,892 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:38:21,892 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:38:21,892 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:38:21,892 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:38:21,892 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:38:21,893 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:38:21,893 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:38:21,893 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:38:21,893 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:38:21,893 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:38:21,893 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:38:21,893 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:38:21,893 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:38:21,893 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:38:21,893 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:38:21,893 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:38:21,893 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:38:31,583 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:31,584 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:31,584 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:31,584 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:31,585 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:38:34,863 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:38:38,775 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:38,775 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:38,809 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:38,809 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:38,809 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:38,809 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:38,809 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:38,810 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:38,810 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:38,843 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:38,844 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:38,844 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:38,844 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:38,844 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:38,844 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:38,844 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:38,878 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:38,878 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:38,878 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:38,878 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:38,879 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:38,879 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:38:38,879 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:38,879 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:38,914 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:38,914 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:38:38,914 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:38:38,914 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:38,915 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:38,915 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:38,915 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:38,915 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:38:38,923 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 14:38:38,945 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 14:38:38,951 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 14:38:38,952 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 14:38:38,993 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:38,994 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:39,034 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:39,035 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:39,035 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:39,035 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:39,035 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:39,035 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:39,035 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:39,072 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:39,072 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:39,072 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:39,072 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:39,073 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:39,073 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:39,073 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:39,111 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:39,111 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:39,111 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:39,112 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:39,112 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:39,112 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:38:39,112 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:39,112 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:39,152 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:39,153 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:38:39,153 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:38:39,153 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:38:39,153 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:38:39,153 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:38:39,153 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:38:39,154 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:38:39,172 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 14:38:39,175 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 14:38:39,176 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 14:38:39,176 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 14:38:39,178 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 14:38:39,178 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 14:38:41,368 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 14:38:41,404 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:41] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 14:38:41,605 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:41] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 14:38:41,729 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:41] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 14:38:41,742 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:41] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 14:38:41,765 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:41] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 14:38:41,766 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:41] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 14:38:41,772 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:41] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 14:38:41,918 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:41] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 14:38:42,042 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 14:38:42,071 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 14:38:42,073 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,078 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,079 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,216 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 14:38:42,349 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,379 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,390 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,395 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,398 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,517 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 14:38:42,646 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 14:38:42,674 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 14:38:42,690 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 14:38:42,706 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 14:38:42,708 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 14:38:42,817 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 14:38:42,930 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 14:38:42,979 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:42] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 14:38:43,001 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 14:38:43,016 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 14:38:43,024 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 14:38:43,101 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 14:38:43,216 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-11 14:38:43,279 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /static/js/admin/agent-teams.js HTTP/1.1" 200 -
2025-08-11 14:38:43,296 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:38:43,309 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:38:43,344 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 14:38:43,358 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 14:38:43,584 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 14:38:43,586 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:38:43,588 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:38:43,610 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 14:38:43,640 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 14:38:43,646 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:43] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 14:38:44,032 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:44] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 14:38:44,042 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:44] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 14:38:44,321 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:44] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 14:38:48,305 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 14:38:48,305 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:38:48,305 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:38:48,449 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:38:48,449 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 14:38:48,579 - ERROR - [autogen_orchestrator.py:152] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 139, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 14:38:48,672 - ERROR - [autogen_orchestrator.py:152] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 139, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 14:38:48,673 - ERROR - [autogen_orchestrator.py:255] - Team run failed: Model client init failed. Check OPENROUTER_MODEL, OPENROUTER_API_KEY, OPENROUTER_BASE_URL / OPENAI_* env.
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 235, in run_team
    agents_with_wb, team_obj = await self._build_agents_team(team)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 213, in _build_agents_team
    raise RuntimeError("Model client init failed. Check OPENROUTER_MODEL, OPENROUTER_API_KEY, OPENROUTER_BASE_URL / OPENAI_* env.")
RuntimeError: Model client init failed. Check OPENROUTER_MODEL, OPENROUTER_API_KEY, OPENROUTER_BASE_URL / OPENAI_* env.

2025-08-11 14:38:48,685 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:38:48] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 14:55:36,880 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:55:36,881 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:55:36,881 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:55:36,882 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:55:36,882 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:55:36,882 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:55:36,882 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:55:36,883 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:55:36,883 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:55:36,883 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:55:36,883 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:55:36,884 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:55:36,885 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 14:55:36,885 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 14:55:36,885 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:55:36,885 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 14:55:36,885 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:55:36,886 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 14:55:36,886 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:55:36,886 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 14:55:36,887 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 14:55:36,887 - INFO - [database.py:294] - Closing database connection
2025-08-11 14:55:36,887 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 14:55:36,887 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 14:55:41,186 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:41,186 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:41,186 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:41,186 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:41,187 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:55:44,283 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 14:55:47,116 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:47,117 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:55:47,163 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:55:47,163 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:47,163 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:47,163 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:47,164 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:47,164 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:47,164 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:55:47,209 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:55:47,209 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:47,209 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:47,210 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:47,210 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:47,210 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:47,210 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:55:47,256 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:55:47,257 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:47,257 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:47,257 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:47,257 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:47,257 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:55:47,258 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:47,258 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:55:47,303 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:55:47,303 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:55:47,303 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:55:47,303 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:47,304 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:47,304 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:47,304 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:47,304 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:55:47,315 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 14:55:47,339 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 14:55:47,342 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 14:55:47,344 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 14:55:47,391 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:47,391 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:55:47,437 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:55:47,437 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:47,437 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:47,437 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:47,437 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:47,438 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:47,438 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:55:47,481 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:55:47,482 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:47,482 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:47,482 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:47,482 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:47,482 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:47,482 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:55:47,527 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:55:47,527 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:47,527 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:47,528 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:47,528 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:47,528 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 14:55:47,528 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:47,528 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:55:47,572 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:55:47,572 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 14:55:47,572 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:55:47,573 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 14:55:47,573 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 14:55:47,573 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 14:55:47,573 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 14:55:47,573 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 14:55:47,594 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 14:55:47,596 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 14:55:47,597 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 14:55:47,597 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 14:55:47,599 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 14:55:47,600 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 14:55:52,682 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 14:55:52,711 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:52] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 14:55:52,911 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:52] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 14:55:53,048 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 14:55:53,061 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 14:55:53,067 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 14:55:53,071 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 14:55:53,072 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 14:55:53,216 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 14:55:53,383 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 14:55:53,387 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 14:55:53,398 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 14:55:53,408 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 14:55:53,413 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 14:55:53,521 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 14:55:53,702 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 14:55:53,728 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 14:55:53,731 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 14:55:53,732 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 14:55:53,733 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 14:55:53,829 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:53] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 14:55:54,018 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 14:55:54,037 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 14:55:54,044 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 14:55:54,049 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 14:55:54,059 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 14:55:54,126 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 14:55:54,328 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 14:55:54,337 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 14:55:54,347 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 14:55:54,355 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 14:55:54,362 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 14:55:54,452 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 14:55:54,640 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-11 14:55:54,656 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "GET /static/js/admin/agent-teams.js HTTP/1.1" 200 -
2025-08-11 14:55:54,701 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 14:55:54,706 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 14:55:54,707 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:54] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 14:55:54,980 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 14:55:55,005 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 14:55:55,024 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 14:55:55,026 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:55:55,026 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 14:55:55,029 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 14:55:55,050 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 14:55:55,467 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 14:55:55,475 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 14:55:55,713 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:55:55] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 14:55:59,994 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 14:55:59,994 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 14:55:59,995 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 14:56:00,142 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 14:56:00,143 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 14:56:00,298 - ERROR - [autogen_orchestrator.py:154] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 140, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 14:56:00,432 - INFO - [autogen_orchestrator.py:177] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 14:56:00,558 - ERROR - [autogen_orchestrator.py:154] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 140, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 14:56:00,646 - INFO - [autogen_orchestrator.py:177] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 14:56:02,617 - ERROR - [_single_threaded_agent_runtime.py:611] - Error processing publish message for Agent_87628239-3708-4d3f-961c-5c5d91687059/87628239-3708-4d3f-961c-5c5d91687059
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_single_threaded_agent_runtime.py", line 606, in _on_message
    return await agent.on_message(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_base_agent.py", line 119, in on_message
    return await self.on_message_impl(message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py", line 67, in on_message_impl
    return await super().on_message_impl(message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_routed_agent.py", line 485, in on_message_impl
    return await h(self, message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_routed_agent.py", line 268, in wrapper
    return_value = await func(self, message, ctx)  # type: ignore
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 660, in create
    create_params = self._process_create_args(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 618, in _process_create_args
    converted_tools = convert_tools(tools)
                      ^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 270, in convert_tools
    assert_valid_name(tool_param["function"]["name"])
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_utils.py", line 11, in assert_valid_name
    raise ValueError(f"Invalid name: {name}. Only letters, numbers, '_' and '-' are allowed.")
ValueError: Invalid name: 1:get_mapping_details. Only letters, numbers, '_' and '-' are allowed.
2025-08-11 14:56:03,013 - ERROR - [autogen_orchestrator.py:287] - Team run failed: ValueError: Invalid name: 1:get_mapping_details. Only letters, numbers, '_' and '-' are allowed.
Traceback:
Traceback (most recent call last):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 660, in create
    create_params = self._process_create_args(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 618, in _process_create_args
    converted_tools = convert_tools(tools)
                      ^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 270, in convert_tools
    assert_valid_name(tool_param["function"]["name"])

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_utils.py", line 11, in assert_valid_name
    raise ValueError(f"Invalid name: {name}. Only letters, numbers, '_' and '-' are allowed.")

ValueError: Invalid name: 1:get_mapping_details. Only letters, numbers, '_' and '-' are allowed.

Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 283, in run_team
    result = await with_all_workbenches()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 274, in with_all_workbenches
    result = await team_obj.run(task=task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 340, in run
    async for message in self.run_stream(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 554, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: ValueError: Invalid name: 1:get_mapping_details. Only letters, numbers, '_' and '-' are allowed.
Traceback:
Traceback (most recent call last):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 660, in create
    create_params = self._process_create_args(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 618, in _process_create_args
    converted_tools = convert_tools(tools)
                      ^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 270, in convert_tools
    assert_valid_name(tool_param["function"]["name"])

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_utils.py", line 11, in assert_valid_name
    raise ValueError(f"Invalid name: {name}. Only letters, numbers, '_' and '-' are allowed.")

ValueError: Invalid name: 1:get_mapping_details. Only letters, numbers, '_' and '-' are allowed.


2025-08-11 14:56:03,016 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:56:03] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 14:57:25,704 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:57:25] "GET /api/agent/workflows/2 HTTP/1.1" 200 -
2025-08-11 14:57:25,941 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:57:25] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 14:57:37,613 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 14:57:37] "GET /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 15:00:25,523 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:00:25,523 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:00:25,524 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:00:25,524 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:00:25,525 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:00:25,525 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:00:25,525 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:00:25,525 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:00:25,525 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:00:25,526 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:00:25,526 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:00:25,526 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:00:25,527 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:00:25,527 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:00:25,527 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:00:25,527 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:00:25,528 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:00:25,528 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:00:25,528 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:00:25,528 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:00:25,528 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:00:25,528 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:00:25,528 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:00:25,529 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:00:28,371 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:28,371 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:28,371 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:28,371 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:28,372 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:00:31,472 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 15:00:34,620 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:00:34,621 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:00:34,850 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:00:34,851 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:34,852 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:34,852 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:34,852 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:34,853 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:00:34,853 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:00:34,965 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:00:34,966 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:34,966 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:34,966 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:34,967 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:34,967 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:00:34,967 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:00:35,033 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:00:35,034 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:35,034 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:35,034 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:35,034 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:35,035 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:00:35,035 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:00:35,035 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:00:35,110 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:00:35,111 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:00:35,111 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:00:35,112 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:35,112 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:35,112 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:35,112 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:35,113 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:00:35,130 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 15:00:35,165 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 15:00:35,170 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 15:00:35,171 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 15:00:35,239 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:00:35,239 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:00:35,298 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:00:35,299 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:35,300 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:35,300 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:35,300 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:35,300 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:00:35,301 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:00:35,361 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:00:35,361 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:35,362 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:35,362 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:35,362 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:35,363 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:00:35,363 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:00:35,423 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:00:35,424 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:35,424 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:35,424 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:35,425 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:35,425 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:00:35,425 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:00:35,425 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:00:35,485 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:00:35,485 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:00:35,485 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:00:35,486 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:00:35,486 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:00:35,486 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:00:35,486 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:00:35,487 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:00:35,514 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 15:00:35,517 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 15:00:35,518 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 15:00:35,519 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 15:00:35,521 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 15:00:35,521 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 15:00:37,552 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 15:00:37,583 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:37] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 15:00:37,803 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:37] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 15:00:37,915 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:37] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 15:00:37,929 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:37] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 15:00:37,933 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:37] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 15:00:37,936 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:37] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 15:00:37,938 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:37] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 15:00:38,104 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 15:00:38,234 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 15:00:38,238 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 15:00:38,249 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,253 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,255 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,410 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 15:00:38,540 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,545 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,553 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,556 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,558 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,721 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 15:00:38,838 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 15:00:38,844 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 15:00:38,853 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 15:00:38,856 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 15:00:38,860 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:38] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 15:00:39,033 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 15:00:39,144 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 15:00:39,154 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 15:00:39,163 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 15:00:39,167 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 15:00:39,173 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 15:00:39,345 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 15:00:39,463 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-11 15:00:39,476 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/js/admin/agent-teams.js HTTP/1.1" 200 -
2025-08-11 15:00:39,508 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:00:39,512 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:00:39,513 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:00:39,810 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:00:39,835 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:00:39] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 15:01:01,936 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:01] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:01:01,956 - ERROR - [user_manager.py:558] - Error logging audit event: <built-in method commit of sqlite3.Connection object at 0x7fdf074c24d0> returned NULL without setting an exception
2025-08-11 15:01:01,968 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:01] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:01:01,969 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:01] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 15:01:01,976 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:01] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:01:01,989 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:01] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 15:01:02,255 - DEBUG - [app.py:172] - Main page requested
2025-08-11 15:01:02,258 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:02] "GET / HTTP/1.1" 200 -
2025-08-11 15:01:02,645 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 15:01:02,653 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:02] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 15:01:02,748 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:02] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:01:02,809 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:02] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:01:02,825 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:02] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:01:03,019 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:03] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-11 15:01:03,401 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:03] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 15:01:03,512 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:03] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-11 15:01:11,766 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:11] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 15:01:12,169 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:12] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:01:12,240 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:01:12,256 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:12] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:01:12,288 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:12] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 15:01:12,437 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:12] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 15:01:12,523 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:12] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:01:12,526 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:12] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:01:12,546 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:12] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:01:12,587 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:12] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:01:20,049 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 15:01:20,049 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:01:20,049 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:01:20,149 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:01:20,150 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 15:01:20,307 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:01:20,582 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:01:20,675 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:01:20,775 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:01:27,297 - ERROR - [_single_threaded_agent_runtime.py:611] - Error processing publish message for Agent_90d0d449-55b1-4d23-8285-3219f72d8965/90d0d449-55b1-4d23-8285-3219f72d8965
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_single_threaded_agent_runtime.py", line 606, in _on_message
    return await agent.on_message(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_base_agent.py", line 119, in on_message
    return await self.on_message_impl(message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py", line 67, in on_message_impl
    return await super().on_message_impl(message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_routed_agent.py", line 485, in on_message_impl
    return await h(self, message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_routed_agent.py", line 268, in wrapper
    return_value = await func(self, message, ctx)  # type: ignore
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 660, in create
    create_params = self._process_create_args(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 602, in _process_create_args
    oai_messages_nested = [
                          ^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 603, in <listcomp>
    to_oai_type(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 184, in to_oai_type
    result = transformer(message, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_transformation/registry.py", line 64, in transformer
    kwargs.update(func(message, context))
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 250, in _set_tool_calls
    "tool_calls": [func_call_to_oai(x) for x in message.content],
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 250, in <listcomp>
    "tool_calls": [func_call_to_oai(x) for x in message.content],
                   ^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 176, in func_call_to_oai
    return ChatCompletionMessageToolCallParam(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/typing.py", line 1275, in __call__
    result = self.__origin__(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/typing.py", line 472, in __call__
    raise TypeError(f"Cannot instantiate {self!r}")
TypeError: Cannot instantiate typing.Union
2025-08-11 15:01:27,616 - ERROR - [autogen_orchestrator.py:318] - Team run failed: TypeError: Cannot instantiate typing.Union
Traceback:
Traceback (most recent call last):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 660, in create
    create_params = self._process_create_args(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 602, in _process_create_args
    oai_messages_nested = [
                          ^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 603, in <listcomp>
    to_oai_type(

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 184, in to_oai_type
    result = transformer(message, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_transformation/registry.py", line 64, in transformer
    kwargs.update(func(message, context))
                  ^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 250, in _set_tool_calls
    "tool_calls": [func_call_to_oai(x) for x in message.content],
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 250, in <listcomp>
    "tool_calls": [func_call_to_oai(x) for x in message.content],
                   ^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 176, in func_call_to_oai
    return ChatCompletionMessageToolCallParam(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/typing.py", line 1275, in __call__
    result = self.__origin__(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/typing.py", line 472, in __call__
    raise TypeError(f"Cannot instantiate {self!r}")

TypeError: Cannot instantiate typing.Union

Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 314, in run_team
    result = await with_all_workbenches()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 305, in with_all_workbenches
    result = await team_obj.run(task=task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 340, in run
    async for message in self.run_stream(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 554, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: TypeError: Cannot instantiate typing.Union
Traceback:
Traceback (most recent call last):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 660, in create
    create_params = self._process_create_args(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 602, in _process_create_args
    oai_messages_nested = [
                          ^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 603, in <listcomp>
    to_oai_type(

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 184, in to_oai_type
    result = transformer(message, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_transformation/registry.py", line 64, in transformer
    kwargs.update(func(message, context))
                  ^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 250, in _set_tool_calls
    "tool_calls": [func_call_to_oai(x) for x in message.content],
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 250, in <listcomp>
    "tool_calls": [func_call_to_oai(x) for x in message.content],
                   ^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_message_transform.py", line 176, in func_call_to_oai
    return ChatCompletionMessageToolCallParam(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/typing.py", line 1275, in __call__
    result = self.__origin__(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/typing.py", line 472, in __call__
    raise TypeError(f"Cannot instantiate {self!r}")

TypeError: Cannot instantiate typing.Union


2025-08-11 15:01:27,618 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:01:27] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 15:04:57,076 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:04:57,077 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:04:57,077 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:04:57,077 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:04:57,078 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:04:57,078 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:04:57,079 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:04:57,079 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:04:57,079 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:04:57,080 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:04:57,080 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:04:57,080 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:04:57,082 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:04:57,082 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:04:57,082 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:04:57,083 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:04:57,083 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:04:57,083 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:04:57,083 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:04:57,083 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:04:57,084 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:04:57,084 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:04:57,084 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:04:57,085 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:04:59,962 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:04:59,962 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:04:59,962 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:04:59,962 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:04:59,963 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:05:03,052 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 15:05:05,386 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:05,386 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:05,419 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:05,419 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:05:05,419 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:05:05,419 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:05:05,419 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:05:05,419 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:05,420 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:05,453 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:05,454 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:05:05,454 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:05:05,454 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:05:05,454 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:05:05,454 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:05,454 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:05,490 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:05,490 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:05:05,490 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:05:05,490 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:05:05,490 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:05:05,490 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:05:05,490 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:05,491 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:05,525 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:05,526 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:05:05,526 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:05:05,526 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:05:05,526 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:05:05,526 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:05:05,526 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:05:05,526 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:05:05,536 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 15:05:05,553 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 15:05:05,556 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 15:05:05,557 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 15:05:05,590 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:05,591 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:05,626 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:05,627 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:05:05,627 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:05:05,627 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:05:05,627 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:05:05,627 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:05,628 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:05,665 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:05,665 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:05:05,665 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:05:05,665 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:05:05,665 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:05:05,665 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:05,666 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:05,706 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:05,706 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:05:05,707 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:05:05,707 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:05:05,707 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:05:05,707 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:05:05,707 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:05,707 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:05,750 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:05,751 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:05:05,751 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:05:05,751 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:05:05,751 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:05:05,751 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:05:05,752 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:05:05,752 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:05:05,773 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 15:05:05,776 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 15:05:05,779 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 15:05:05,779 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 15:05:05,782 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 15:05:05,782 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 15:05:09,548 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 15:05:09,577 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:09] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:05:09,781 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:09] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 15:05:09,922 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:09] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-11 15:05:09,956 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:09] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:05:09,960 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:05:09,962 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:09] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:05:09,990 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:09] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:05:09,992 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:09] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:05:10,262 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:10] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:05:10,263 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:10] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:05:28,148 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 15:05:28,149 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:05:28,149 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:05:28,182 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:05:28,182 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 15:05:28,183 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:05:28] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:05:28,216 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:05:28,245 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:05:28,275 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:05:28,305 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:06:08,862 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:06:08] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:06:09,193 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:06:09,200 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:06:09] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:06:09,205 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:06:09] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:06:09,224 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:06:09] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:06:09,326 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:06:09] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:06:09,332 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:06:09] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:06:09,333 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:06:09] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:06:22,648 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:06:22] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:06:22,690 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:06:22,722 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:06:22,754 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:06:22,788 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:07:18,856 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:07:18] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:07:18,898 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:07:18,932 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:07:18,962 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:07:18,990 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:07:21,488 - ERROR - [base_events.py:1771] - Task exception was never retrieved
future: <Task finished name='Task-214' coro=<AsyncClient.aclose() done, defined at /home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py", line 2018, in aclose
    await self._transport.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py", line 385, in aclose
    await self._pool.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 313, in aclose
    await self._close_connections(closing_connections)
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 305, in _close_connections
    await connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py", line 171, in aclose
    await self._connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py", line 265, in aclose
    await self._network_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 55, in aclose
    await self._stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/streams/tls.py", line 216, in aclose
    await self.transport_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 1314, in aclose
    self._transport.close()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/selector_events.py", line 860, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 761, in call_soon
    self._check_closed()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 519, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-08-11 15:07:57,819 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:07:57] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:07:58,058 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:07:58,064 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:07:58] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:07:58,160 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:07:58] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:07:58,193 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:07:58] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:07:58,194 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:07:58] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:07:58,225 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:07:58] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:07:58,227 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:07:58] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:08:10,207 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:08:10] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:08:10,251 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:08:10,282 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:08:10,310 - ERROR - [autogen_orchestrator.py:185] - Failed to init OpenAIChatCompletionClient: model_info is required when model name is not a valid OpenAI model
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 171, in _build_model_client
    client = OpenAIChatCompletionClient(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 1474, in __init__
    super().__init__(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 435, in __init__
    self._model_info = _model_info.get_info(create_args["model"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_model_info.py", line 491, in get_info
    raise ValueError("model_info is required when model name is not a valid OpenAI model")
ValueError: model_info is required when model name is not a valid OpenAI model

2025-08-11 15:08:10,339 - INFO - [autogen_orchestrator.py:208] - OpenAIChatCompletionClient initialized with ModelInfo (model=gemini-2.0-flash-lite, family=gemini)
2025-08-11 15:11:25,421 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:11:25,422 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:11:25,423 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:11:25,423 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:11:25,424 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:11:25,425 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:11:25,425 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:11:25,426 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:11:25,427 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:11:25,427 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:11:25,428 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:11:25,428 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:11:25,429 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:11:25,429 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:11:25,430 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:11:25,430 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:11:25,431 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:11:25,431 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:11:25,431 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:11:25,431 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:11:25,432 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:11:25,432 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:11:25,432 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:11:25,432 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:11:30,306 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:30,306 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:30,306 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:30,307 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:30,308 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:11:35,427 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 15:11:37,604 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:37,604 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:37,631 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:37,632 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:37,632 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:37,632 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:37,632 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:37,632 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:37,632 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:37,661 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:37,661 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:37,662 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:37,662 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:37,662 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:37,662 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:37,662 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:37,688 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:37,688 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:37,688 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:37,688 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:37,689 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:37,689 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:11:37,689 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:37,689 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:37,716 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:37,717 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:11:37,717 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:11:37,717 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:37,717 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:37,717 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:37,717 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:37,717 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:11:37,724 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 15:11:37,738 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 15:11:37,741 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 15:11:37,742 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 15:11:37,768 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:37,768 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:37,794 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:37,794 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:37,794 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:37,794 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:37,794 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:37,795 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:37,795 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:37,820 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:37,820 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:37,820 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:37,820 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:37,820 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:37,821 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:37,821 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:37,846 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:37,846 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:37,846 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:37,847 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:37,847 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:37,847 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:11:37,847 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:37,847 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:37,878 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:37,878 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:11:37,878 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:11:37,878 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:11:37,879 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:11:37,879 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:11:37,879 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:11:37,879 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:11:37,890 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 15:11:37,892 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 15:11:37,893 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 15:11:37,893 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 15:11:37,894 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 15:11:37,894 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 15:11:42,339 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 15:11:42,363 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:11:42] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:11:42,568 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:11:42,578 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:11:42] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:11:42,691 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:11:42] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:11:42,698 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:11:42] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:11:42,724 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:11:42] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:11:42,752 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:11:42] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:11:42,755 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:11:42] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:11:55,973 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 15:11:55,973 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:11:55,973 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:11:56,013 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:11:56,013 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 15:11:56,014 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:11:56] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:11:56,044 - INFO - [autogen_orchestrator.py:194] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:11:56,072 - INFO - [autogen_orchestrator.py:194] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:28:16,325 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:28:16,326 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:28:16,326 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:28:16,326 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:28:16,327 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:28:16,327 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:28:16,327 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:28:16,327 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:28:16,328 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:28:16,328 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:28:16,328 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:28:16,329 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:28:16,330 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:28:16,330 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:28:16,330 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:28:16,331 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:28:16,331 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:28:16,331 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:28:16,331 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:28:16,332 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:28:16,332 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:28:16,332 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:28:16,332 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:28:16,333 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:28:20,360 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:20,361 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:20,361 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:20,361 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:20,365 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:28:23,546 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 15:28:25,890 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:25,890 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:25,918 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:25,918 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:25,918 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:25,918 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:25,918 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:25,918 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:25,918 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:25,947 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:25,947 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:25,947 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:25,948 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:25,948 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:25,948 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:25,948 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:25,978 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:25,978 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:25,978 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:25,979 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:25,979 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:25,979 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:28:25,979 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:25,979 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:26,015 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:26,015 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:28:26,015 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:28:26,015 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:26,015 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:26,015 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:26,016 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:26,016 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:28:26,024 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 15:28:26,043 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 15:28:26,047 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 15:28:26,052 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 15:28:26,095 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:26,095 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:26,128 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:26,129 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:26,129 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:26,129 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:26,129 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:26,130 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:26,130 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:26,164 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:26,164 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:26,164 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:26,165 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:26,165 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:26,165 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:26,165 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:26,196 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:26,197 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:26,197 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:26,197 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:26,197 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:26,197 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:28:26,197 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:26,197 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:26,230 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:26,230 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:28:26,231 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:28:26,231 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:28:26,231 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:28:26,231 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:28:26,231 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:28:26,231 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:28:26,247 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 15:28:26,249 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 15:28:26,250 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 15:28:26,250 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 15:28:26,251 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 15:28:26,252 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 15:28:29,699 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 15:28:29,719 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:29] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:28:29,938 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:29] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 15:28:30,059 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:30] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:28:30,061 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:30] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:28:30,273 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:28:30,281 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:30] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:28:30,286 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:30] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:28:30,364 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:30] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:28:30,371 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:30] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 15:28:30,376 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:30] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:28:30,410 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:30] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 15:28:43,654 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 15:28:43,654 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:28:43,655 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:28:43,694 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:28:43,695 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 15:28:43,695 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:28:43] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:28:43,751 - INFO - [autogen_orchestrator.py:244] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:28:43,781 - INFO - [autogen_orchestrator.py:244] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:29:28,195 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 15:29:28,532 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "[36mGET /static/js/admin/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 15:29:28,536 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "[36mGET /static/js/admin/agent-teams.js HTTP/1.1[0m" 304 -
2025-08-11 15:29:28,550 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:29:28,556 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:29:28,561 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:29:28,777 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:29:28,785 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:29:28,880 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 15:29:28,882 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:29:28,883 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:29:28,895 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:28] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 15:29:33,022 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:33] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 15:29:33,263 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:33] "GET /static/js/admin/agent-runs.js HTTP/1.1" 200 -
2025-08-11 15:29:33,357 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:29:33,376 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:33] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:29:33,379 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:33] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 15:29:33,380 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:33] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:29:33,389 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:33] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 15:29:33,563 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:33] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 15:29:40,266 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:40] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:29:42,738 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:29:42] "GET /api/agent/runs/1 HTTP/1.1" 200 -
2025-08-11 15:30:38,533 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:30:38] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:33:06,402 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:33:06] "GET /api/agent/runs/1 HTTP/1.1" 200 -
2025-08-11 15:35:41,884 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:35:41,885 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:35:41,885 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:35:41,885 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:35:41,886 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:35:41,886 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:35:41,886 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:35:41,887 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:35:41,887 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:35:41,887 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:35:41,887 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:35:41,887 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:35:41,888 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:35:41,889 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:35:41,889 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:35:41,889 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:35:41,889 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:35:41,889 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:35:41,889 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:35:41,890 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:35:41,890 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:35:41,890 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:35:41,890 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:35:41,890 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:35:45,896 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:45,896 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:45,896 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:45,897 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:45,898 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:35:49,113 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 15:35:51,277 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:35:51,277 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:35:51,304 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:35:51,304 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:51,304 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:51,304 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:51,304 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:51,304 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:35:51,305 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:35:51,330 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:35:51,330 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:51,330 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:51,330 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:51,331 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:51,331 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:35:51,331 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:35:51,356 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:35:51,356 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:51,356 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:51,356 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:51,356 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:51,356 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:35:51,356 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:35:51,356 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:35:51,405 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:35:51,405 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:35:51,405 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:35:51,406 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:51,406 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:51,406 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:51,406 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:51,406 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:35:51,419 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 15:35:51,453 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 15:35:51,457 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 15:35:51,458 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 15:35:51,505 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:35:51,505 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:35:51,566 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:35:51,567 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:51,567 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:51,567 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:51,567 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:51,567 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:35:51,567 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:35:51,595 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:35:51,595 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:51,595 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:51,595 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:51,595 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:51,595 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:35:51,596 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:35:51,625 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:35:51,625 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:51,626 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:51,626 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:51,626 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:51,626 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:35:51,626 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:35:51,626 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:35:51,655 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:35:51,656 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:35:51,656 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:35:51,656 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:35:51,656 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:35:51,656 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:35:51,656 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:35:51,656 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:35:51,670 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 15:35:51,671 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 15:35:51,672 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 15:35:51,672 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 15:35:51,674 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 15:35:51,674 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 15:35:55,711 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 15:35:55,742 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:35:55] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 15:35:55,951 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:35:55,962 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:35:55] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:35:56,109 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:35:56] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:35:58,657 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:35:58] "GET /api/agent/runs/1 HTTP/1.1" 200 -
2025-08-11 15:36:29,836 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:36:29] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:36:30,068 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:36:30] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 15:36:30,156 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:36:30] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-11 15:36:30,166 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:36:30,182 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:36:30] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:36:30,471 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:36:30] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:36:30,473 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:36:30] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:36:49,731 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 15:36:49,731 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:36:49,731 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:36:49,773 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:36:49,773 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 15:36:49,774 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:36:49] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:36:49,818 - INFO - [autogen_orchestrator.py:244] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:36:49,846 - INFO - [autogen_orchestrator.py:244] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:37:21,907 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:21] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:37:22,223 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,229 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,230 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,469 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,530 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,534 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,539 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,768 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,837 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,840 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:22,840 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:22] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,077 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,152 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,159 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,166 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,395 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,457 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,463 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,470 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,700 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,759 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,764 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,773 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,910 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,916 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:23,987 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:23] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,067 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,074 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,079 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,220 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,231 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,283 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,375 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,681 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:37:24,687 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:24,699 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:37:24,706 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:37:24,708 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:37:24,924 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:24] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 15:37:25,018 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:25] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 15:37:28,191 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:28] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 15:37:28,524 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:28] "GET /static/js/admin/agent-runs.js HTTP/1.1" 200 -
2025-08-11 15:37:28,762 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:37:28,776 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:28] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:37:28,822 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:28] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:37:31,230 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:37:31] "GET /api/agent/runs/2 HTTP/1.1" 200 -
2025-08-11 15:38:47,293 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:38:47] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:38:47,528 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:38:47,538 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:38:47] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:38:47,653 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:38:47] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:38:47,656 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:38:47] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:39:09,399 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:39:09] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:39:09,450 - INFO - [autogen_orchestrator.py:244] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:39:09,480 - INFO - [autogen_orchestrator.py:244] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:39:12,474 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:39:12] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:39:17,065 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:39:17] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:39:18,704 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:39:18] "GET /api/agent/runs/3 HTTP/1.1" 200 -
2025-08-11 15:45:57,495 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:45:57,496 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:45:57,497 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:45:57,498 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:45:57,498 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:45:57,499 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:45:57,499 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:45:57,500 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:45:57,500 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:45:57,500 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:45:57,501 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:45:57,501 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:45:57,503 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:45:57,503 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:45:57,503 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:45:57,504 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:45:57,504 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:45:57,504 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:45:57,504 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:45:57,504 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:45:57,505 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:45:57,505 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:45:57,505 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:45:57,505 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:46:02,308 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:02,309 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:02,309 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:02,309 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:02,310 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:46:06,568 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 15:46:10,911 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:10,911 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:10,954 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:10,954 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:10,954 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:10,955 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:10,955 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:10,955 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:10,955 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:11,000 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:11,001 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:11,001 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:11,001 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:11,001 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:11,002 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:11,002 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:11,047 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:11,048 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:11,048 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:11,048 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:11,048 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:11,048 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:46:11,048 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:11,049 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:11,099 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:11,100 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:46:11,100 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:46:11,100 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:11,101 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:11,101 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:11,101 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:11,101 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:46:11,115 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 15:46:11,147 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 15:46:11,150 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 15:46:11,151 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 15:46:11,198 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:11,198 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:11,248 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:11,248 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:11,249 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:11,249 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:11,249 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:11,249 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:11,250 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:11,296 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:11,296 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:11,296 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:11,296 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:11,297 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:11,297 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:11,297 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:11,347 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:11,348 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:11,348 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:11,348 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:11,349 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:11,349 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:46:11,349 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:11,349 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:11,399 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:11,400 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:46:11,400 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:46:11,400 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:46:11,401 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:46:11,401 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:46:11,401 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:46:11,401 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:46:11,426 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 15:46:11,428 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 15:46:11,430 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 15:46:11,430 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 15:46:11,432 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 15:46:11,433 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 15:46:13,271 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 15:46:13,292 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:46:13] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:46:13,493 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:46:13,503 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:46:13] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:46:13,673 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:46:13] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:46:13,677 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:46:13] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:46:40,237 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 15:46:40,237 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:46:40,238 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:46:40,275 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:46:40,275 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 15:46:40,275 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:46:40] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:46:40,323 - INFO - [autogen_orchestrator.py:251] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:46:40,354 - INFO - [autogen_orchestrator.py:251] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:46:44,858 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:46:44] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:46:47,221 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:46:47] "GET /api/agent/runs/4 HTTP/1.1" 200 -
2025-08-11 15:47:02,370 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:47:02] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:47:07,058 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:47:07] "GET /api/agent/runs/4 HTTP/1.1" 200 -
2025-08-11 15:49:38,158 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:49:38] "GET /api/agent/runs/4 HTTP/1.1" 200 -
2025-08-11 15:55:29,228 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:55:29,228 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:55:29,229 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:55:29,229 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:55:29,229 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:55:29,229 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:55:29,229 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:55:29,230 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:55:29,230 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:55:29,230 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:55:29,230 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:55:29,230 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:55:29,231 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 15:55:29,231 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 15:55:29,231 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:55:29,231 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 15:55:29,232 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:55:29,232 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 15:55:29,232 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:55:29,232 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 15:55:29,232 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 15:55:29,232 - INFO - [database.py:294] - Closing database connection
2025-08-11 15:55:29,232 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 15:55:29,233 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 15:55:35,080 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:35,080 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:35,081 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:35,081 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:35,082 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:55:38,128 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 15:55:40,375 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:55:40,376 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:55:40,402 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:55:40,402 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:40,402 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:40,402 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:40,403 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:40,403 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:55:40,403 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:55:40,433 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:55:40,434 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:40,434 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:40,434 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:40,434 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:40,434 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:55:40,434 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:55:40,462 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:55:40,462 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:40,462 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:40,462 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:40,462 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:40,463 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:55:40,463 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:55:40,463 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:55:40,490 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:55:40,491 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:55:40,491 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:55:40,491 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:40,491 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:40,491 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:40,491 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:40,491 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:55:40,497 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 15:55:40,514 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 15:55:40,517 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 15:55:40,518 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 15:55:40,550 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:55:40,550 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:55:40,583 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:55:40,583 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:40,584 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:40,584 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:40,584 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:40,585 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:55:40,585 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:55:40,616 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:55:40,617 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:40,617 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:40,617 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:40,617 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:40,617 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:55:40,617 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:55:40,643 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:55:40,644 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:40,644 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:40,644 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:40,644 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:40,644 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 15:55:40,644 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:55:40,644 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:55:40,671 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:55:40,672 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 15:55:40,672 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:55:40,672 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 15:55:40,672 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 15:55:40,672 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 15:55:40,672 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 15:55:40,672 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 15:55:40,685 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 15:55:40,687 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 15:55:40,687 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 15:55:40,688 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 15:55:40,689 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 15:55:40,689 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 15:56:18,467 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 15:56:18,490 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:56:18] "GET /agent HTTP/1.1" 200 -
2025-08-11 15:56:18,706 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 15:56:18,716 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:56:18] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 15:56:18,883 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:56:18] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 15:56:18,891 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:56:18] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 15:56:26,966 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 15:56:26,967 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 15:56:26,967 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 15:56:27,041 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 15:56:27,042 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 15:56:27,043 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:56:27] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 15:56:27,130 - INFO - [autogen_orchestrator.py:251] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:56:27,170 - INFO - [autogen_orchestrator.py:251] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 15:56:58,297 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:56:58] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 15:56:59,904 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 15:56:59] "GET /api/agent/runs/5 HTTP/1.1" 200 -
2025-08-11 16:09:25,552 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 16:09:25,553 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 16:09:25,553 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:09:25,553 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 16:09:25,553 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:09:25,554 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 16:09:25,554 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:09:25,554 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 16:09:25,554 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:09:25,554 - INFO - [database.py:294] - Closing database connection
2025-08-11 16:09:25,555 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 16:09:25,555 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 16:09:25,556 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 16:09:25,556 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 16:09:25,556 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:09:25,557 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 16:09:25,557 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:09:25,557 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 16:09:25,557 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:09:25,557 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 16:09:25,557 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:09:25,558 - INFO - [database.py:294] - Closing database connection
2025-08-11 16:09:25,558 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 16:09:25,558 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 16:09:29,383 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:29,383 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:29,383 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:29,384 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:29,384 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:09:32,743 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 16:09:35,045 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:09:35,045 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:09:35,073 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:09:35,074 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:35,074 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:35,074 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:35,074 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:35,074 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:09:35,074 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:09:35,106 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:09:35,106 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:35,106 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:35,106 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:35,106 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:35,106 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:09:35,107 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:09:35,135 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:09:35,136 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:35,136 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:35,136 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:35,136 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:35,136 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 16:09:35,136 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:09:35,136 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:09:35,164 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:09:35,164 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 16:09:35,164 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:09:35,164 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:35,165 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:35,165 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:35,165 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:35,165 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:09:35,172 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 16:09:35,189 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 16:09:35,192 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 16:09:35,192 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 16:09:35,226 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:09:35,226 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:09:35,256 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:09:35,257 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:35,257 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:35,257 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:35,257 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:35,257 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:09:35,257 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:09:35,286 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:09:35,286 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:35,286 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:35,286 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:35,286 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:35,286 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:09:35,286 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:09:35,320 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:09:35,320 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:35,320 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:35,320 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:35,321 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:35,321 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 16:09:35,321 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:09:35,321 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:09:35,350 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:09:35,351 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 16:09:35,351 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:09:35,351 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:09:35,351 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:09:35,351 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:09:35,351 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:09:35,351 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:09:35,365 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 16:09:35,367 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 16:09:35,368 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 16:09:35,368 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 16:09:35,370 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 16:09:35,370 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 16:10:22,873 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 16:10:22,899 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:10:22] "GET /agent HTTP/1.1" 200 -
2025-08-11 16:10:23,098 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 16:10:23,108 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:10:23] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 16:10:23,312 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:10:23] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 16:10:23,314 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:10:23] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 16:10:31,973 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 16:10:31,973 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:10:31,973 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:10:32,015 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:10:32,015 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 16:10:32,016 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:10:32] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 16:10:32,057 - INFO - [autogen_orchestrator.py:251] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:10:32,086 - INFO - [autogen_orchestrator.py:251] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:10:43,132 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:10:43] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 16:10:44,733 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:10:44] "GET /api/agent/runs/6 HTTP/1.1" 200 -
2025-08-11 16:21:58,108 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 16:21:58,108 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 16:21:58,109 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:21:58,109 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 16:21:58,110 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:21:58,110 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 16:21:58,110 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:21:58,110 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 16:21:58,110 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:21:58,111 - INFO - [database.py:294] - Closing database connection
2025-08-11 16:21:58,111 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 16:21:58,111 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 16:21:58,112 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 16:21:58,112 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 16:21:58,112 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:21:58,112 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 16:21:58,113 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:21:58,113 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 16:21:58,113 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:21:58,113 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 16:21:58,113 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:21:58,114 - INFO - [database.py:294] - Closing database connection
2025-08-11 16:21:58,114 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 16:21:58,114 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 16:22:02,796 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:02,797 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:02,797 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:02,797 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:02,798 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:22:05,924 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 16:22:08,143 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:08,144 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:08,170 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:08,171 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:08,171 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:08,171 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:08,171 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:08,171 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:08,171 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:08,199 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:08,200 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:08,200 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:08,200 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:08,200 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:08,200 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:08,200 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:08,228 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:08,228 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:08,228 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:08,228 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:08,228 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:08,228 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 16:22:08,228 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:08,228 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:08,255 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:08,255 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 16:22:08,255 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:22:08,255 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:08,255 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:08,256 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:08,256 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:08,256 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:22:08,261 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 16:22:08,276 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 16:22:08,278 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 16:22:08,279 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 16:22:08,308 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:08,308 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:08,338 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:08,338 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:08,339 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:08,339 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:08,339 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:08,339 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:08,339 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:08,367 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:08,367 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:08,368 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:08,368 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:08,368 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:08,368 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:08,368 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:08,397 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:08,397 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:08,397 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:08,397 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:08,397 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:08,398 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 16:22:08,398 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:08,398 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:08,423 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:08,423 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 16:22:08,423 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:22:08,424 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:22:08,424 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:22:08,424 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:22:08,425 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:22:08,425 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:22:08,437 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 16:22:08,439 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 16:22:08,440 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 16:22:08,440 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 16:22:08,442 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 16:22:08,442 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 16:22:22,013 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 16:22:22,038 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:22:22] "GET /agent HTTP/1.1" 200 -
2025-08-11 16:22:22,231 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 16:22:22,240 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:22:22] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 16:22:22,437 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:22:22] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 16:22:22,438 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:22:22] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 16:22:33,744 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 16:22:33,744 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:22:33,744 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:22:33,786 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:22:33,787 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 16:22:33,787 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:22:33] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 16:22:33,837 - INFO - [autogen_orchestrator.py:251] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:22:33,869 - INFO - [autogen_orchestrator.py:251] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:23:03,204 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:23:03] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 16:23:04,745 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:23:04] "GET /api/agent/runs/7 HTTP/1.1" 200 -
2025-08-11 16:42:32,237 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 16:42:32,238 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 16:42:32,239 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:42:32,239 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 16:42:32,239 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:42:32,240 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 16:42:32,240 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:42:32,240 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 16:42:32,241 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:42:32,241 - INFO - [database.py:294] - Closing database connection
2025-08-11 16:42:32,241 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 16:42:32,241 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 16:42:32,243 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 16:42:32,243 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 16:42:32,243 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:42:32,243 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 16:42:32,244 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:42:32,244 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 16:42:32,244 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:42:32,245 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 16:42:32,245 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 16:42:32,245 - INFO - [database.py:294] - Closing database connection
2025-08-11 16:42:32,245 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 16:42:32,245 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 16:42:36,559 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:36,559 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:36,559 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:36,559 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:36,560 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:42:39,650 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 16:42:41,857 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:42:41,858 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:42:41,886 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:42:41,886 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:41,886 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:41,886 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:41,886 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:41,886 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:42:41,886 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:42:41,917 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:42:41,917 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:41,917 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:41,917 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:41,918 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:41,918 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:42:41,918 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:42:41,947 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:42:41,947 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:41,947 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:41,947 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:41,947 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:41,948 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 16:42:41,948 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:42:41,948 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:42:41,975 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:42:41,975 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 16:42:41,975 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:42:41,975 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:41,975 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:41,975 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:41,975 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:41,975 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:42:41,982 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 16:42:41,996 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 16:42:41,998 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 16:42:41,999 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 16:42:42,027 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:42:42,027 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:42:42,054 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:42:42,054 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:42,054 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:42,054 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:42,054 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:42,054 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:42:42,054 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:42:42,081 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:42:42,081 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:42,082 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:42,082 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:42,082 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:42,083 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:42:42,083 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:42:42,119 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:42:42,119 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:42,119 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:42,119 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:42,119 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:42,119 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 16:42:42,119 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:42:42,119 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:42:42,147 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:42:42,147 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 16:42:42,147 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:42:42,147 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 16:42:42,147 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 16:42:42,147 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 16:42:42,147 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 16:42:42,147 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 16:42:42,158 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 16:42:42,160 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 16:42:42,161 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 16:42:42,161 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 16:42:42,162 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 16:42:42,162 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 16:43:08,702 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 16:43:08,723 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:08] "GET /agent HTTP/1.1" 200 -
2025-08-11 16:43:08,952 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:08] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,063 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,069 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,074 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,079 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,084 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,244 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,370 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,371 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,375 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,378 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,380 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,539 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,675 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,677 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,682 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,685 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,690 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,836 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,976 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,994 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,996 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:09,999 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:09] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,006 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,141 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,278 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,296 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,296 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,300 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,303 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,434 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,573 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,588 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,895 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 16:43:10,908 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:10,921 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 16:43:10,925 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 16:43:10,927 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:10] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 16:43:11,124 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:11] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 16:43:11,299 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:11] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 16:43:17,683 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 16:43:17,683 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 16:43:17,683 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 16:43:17,722 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 16:43:17,722 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 16:43:17,723 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:17] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 16:43:17,771 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:43:17,801 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:43:47,016 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:47] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 16:43:48,494 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:43:48] "GET /api/agent/runs/8 HTTP/1.1" 200 -
2025-08-11 16:45:33,922 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:45:33] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 16:45:33,965 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:45:33,997 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:45:43,823 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:45:43] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 16:45:45,793 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:45:45] "GET /api/agent/runs/9 HTTP/1.1" 200 -
2025-08-11 16:55:20,300 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:55:20] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 16:55:20,640 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:55:20,670 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 16:55:30,208 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:55:30] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 16:55:31,937 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 16:55:31] "GET /api/agent/runs/10 HTTP/1.1" 200 -
2025-08-11 17:01:43,731 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:01:43,732 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:01:43,732 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:01:43,772 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:01:43,772 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:01:43,814 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:02:55,619 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:02:55,620 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:02:55,620 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:02:55,654 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:02:55,655 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:02:55,764 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:03:19,003 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:03:19,003 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:03:19,003 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:03:19,030 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:03:19,031 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:03:19,074 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:03:19,105 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:03:19,131 - ERROR - [autogen_orchestrator.py:582] - Team run failed: 'list' object has no attribute 'terminated'
Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 576, in run_team
    result = await with_all_workbenches()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 503, in with_all_workbenches
    result = await team_obj.run(task=task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 340, in run
    async for message in self.run_stream(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 534, in run_stream
    await self._runtime.send_message(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_single_threaded_agent_runtime.py", line 385, in send_message
    return await future
           ^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_single_threaded_agent_runtime.py", line 508, in _process_send
    response = await recipient_agent.on_message(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_base_agent.py", line 119, in on_message
    return await self.on_message_impl(message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py", line 67, in on_message_impl
    return await super().on_message_impl(message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_routed_agent.py", line 485, in on_message_impl
    return await h(self, message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_routed_agent.py", line 389, in wrapper
    return_value = await func(self, message, ctx)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat_manager.py", line 91, in handle_start
    if self._termination_condition is not None and self._termination_condition.terminated:
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'terminated'

2025-08-11 17:04:00,606 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:04:00,606 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:04:00,606 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:04:00,636 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:04:00,636 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:04:00,679 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:04:00,710 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:05:46,386 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:05:46,387 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:05:46,387 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:05:46,387 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:05:46,387 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:05:46,387 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:05:46,387 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:05:46,387 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:05:46,388 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:05:46,388 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:05:46,388 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:05:46,388 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:05:46,389 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:05:46,389 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:05:46,389 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:05:46,389 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:05:46,389 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:05:46,389 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:05:46,389 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:05:46,390 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:05:46,390 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:05:46,390 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:05:46,390 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:05:46,390 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:05:52,917 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:52,917 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:52,917 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:52,917 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:52,918 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:05:56,112 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 17:05:58,363 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:05:58,363 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:05:58,389 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:05:58,389 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:58,389 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:58,390 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:58,390 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:58,390 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:05:58,390 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:05:58,417 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:05:58,417 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:58,418 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:58,418 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:58,418 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:58,418 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:05:58,418 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:05:58,445 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:05:58,445 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:58,445 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:58,445 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:58,445 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:58,445 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:05:58,445 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:05:58,446 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:05:58,473 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:05:58,473 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:05:58,473 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:05:58,473 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:58,473 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:58,473 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:58,473 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:58,474 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:05:58,480 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 17:05:58,495 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 17:05:58,497 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 17:05:58,498 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 17:05:58,528 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:05:58,528 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:05:58,558 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:05:58,558 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:58,558 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:58,558 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:58,558 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:58,559 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:05:58,559 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:05:58,588 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:05:58,588 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:58,588 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:58,588 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:58,588 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:58,588 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:05:58,588 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:05:58,621 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:05:58,621 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:58,622 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:58,622 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:58,622 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:58,622 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:05:58,622 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:05:58,622 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:05:58,649 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:05:58,650 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:05:58,650 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:05:58,650 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:05:58,650 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:05:58,650 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:05:58,650 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:05:58,650 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:05:58,663 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 17:05:58,664 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 17:05:58,665 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 17:05:58,665 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 17:05:58,666 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 17:05:58,666 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 17:06:16,541 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 17:06:16,569 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:16] "GET /agent HTTP/1.1" 200 -
2025-08-11 17:06:16,789 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:16] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:16,922 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:16] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:16,951 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:16] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:16,953 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:16] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:16,959 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:16] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:16,965 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:16] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:17,102 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:17] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:17,247 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:17] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:17,662 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:06:17,670 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:17] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 17:06:17,678 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:17] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:06:17,681 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:17] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:06:17,681 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:17] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:06:17,909 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:17] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 17:06:17,991 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:17] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 17:06:43,636 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:06:43,637 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:06:43,637 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:06:43,674 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:06:43,674 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:06:43,675 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:43] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:06:43,722 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:06:43,754 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:06:54,692 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:54] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:06:56,431 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:06:56] "GET /api/agent/runs/15 HTTP/1.1" 200 -
2025-08-11 17:07:34,384 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:07:34] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:07:34,440 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:07:34,468 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:07:54,817 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:07:54] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:07:54,871 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:07:54,904 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:07:56,521 - ERROR - [base_events.py:1771] - Task exception was never retrieved
future: <Task finished name='Task-35' coro=<AsyncClient.aclose() done, defined at /home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py", line 2018, in aclose
    await self._transport.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py", line 385, in aclose
    await self._pool.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 313, in aclose
    await self._close_connections(closing_connections)
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 305, in _close_connections
    await connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py", line 171, in aclose
    await self._connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py", line 265, in aclose
    await self._network_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 55, in aclose
    await self._stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/streams/tls.py", line 216, in aclose
    await self.transport_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 1314, in aclose
    self._transport.close()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/selector_events.py", line 860, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 761, in call_soon
    self._check_closed()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 519, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-08-11 17:08:03,148 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:08:03] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:08:04,656 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:08:04] "GET /api/agent/runs/17 HTTP/1.1" 200 -
2025-08-11 17:11:09,330 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:11:09,330 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:11:09,330 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:11:09,360 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:11:09,360 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:11:09,405 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:11:09,434 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:11:41,520 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:11:41,521 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:11:41,521 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:11:41,548 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:11:41,549 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:11:41,592 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:11:41,624 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:12:19,601 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:12:19,602 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:12:19,602 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:12:19,638 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:12:19,639 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:12:19,692 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:12:19,732 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:14:44,408 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:14:44] "GET /agent HTTP/1.1" 200 -
2025-08-11 17:14:44,652 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:14:44,666 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:14:44] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:14:44,800 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:14:44] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:14:44,805 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:14:44] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:15:06,012 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:15:06] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:15:06,063 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:15:06,094 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:15:16,111 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:15:16] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:15:17,453 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:15:17] "GET /api/agent/runs/21 HTTP/1.1" 200 -
2025-08-11 17:16:18,441 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:16:18,442 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:16:18,442 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:16:18,473 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:16:18,473 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:16:18,507 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:16:18,537 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:16:36,220 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 17:16:36,419 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:16:36,419 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:16:36,419 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:16:36,444 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:16:36,444 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:16:36,444 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 17:16:36,445 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 17:16:36,445 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 17:16:36,451 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 17:16:36,451 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 17:16:36,451 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 17:16:36,451 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 17:16:37,242 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 17:16:37,250 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 17:16:37,420 - ERROR - [base_events.py:1771] - an error occurred during closing of asynchronous generator <async_generator object stdio_client at 0x7605675baf80>
asyncgen: <async_generator object stdio_client at 0x7605675baf80>
  + Exception Group Traceback (most recent call last):
  |   File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | BaseExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "/home/vijay/anaconda3/lib/python3.11/site-packages/mcp/client/stdio/__init__.py", line 187, in stdio_client
    |     yield read_stream, write_stream
    | GeneratorExit
    +------------------------------------

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/mcp/client/stdio/__init__.py", line 180, in stdio_client
    async with (
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 778, in __aexit__
    if self.cancel_scope.__exit__(type(exc), exc, exc.__traceback__):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 457, in __exit__
    raise RuntimeError(
RuntimeError: Attempted to exit cancel scope in a different task than it was entered in
2025-08-11 17:17:00,125 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:17:00,125 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:17:00,125 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:17:00,155 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:17:00,155 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:17:00,197 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:17:00,224 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:17:55,636 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:17:55,636 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:17:55,636 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:17:55,665 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:17:55,665 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:17:55,710 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:17:55,739 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:18:29,133 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:18:29] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:18:30,777 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:18:30] "GET /api/agent/runs/24 HTTP/1.1" 200 -
2025-08-11 17:19:02,580 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:19:02,580 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:19:02,581 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:19:02,612 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:19:02,612 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:19:02,643 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:19:02,672 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:19:52,299 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:19:52,299 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:19:52,299 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:19:52,369 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:19:52,370 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:19:52,453 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:19:52,518 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:20:41,814 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:20:41,815 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:20:41,815 - INFO - [llm_engine.py:31] - Using model: gemini-2.0-flash-lite
2025-08-11 17:20:41,847 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:20:41,847 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:20:41,893 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:20:41,922 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:21:49,462 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:49] "GET /agent HTTP/1.1" 200 -
2025-08-11 17:21:49,704 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:49] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:49,804 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:49] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:49,810 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:49] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:49,819 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:49] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:49,820 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:49] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:49,823 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:49] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:50,020 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:50] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:50,111 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:50] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:50,521 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:21:50,526 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:50] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 17:21:50,538 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:50] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:21:50,544 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:50] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:21:50,546 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:50] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:21:50,766 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:50] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 17:21:50,929 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:50] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 17:21:56,162 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:21:56] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:21:56,209 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:21:56,237 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:22:12,845 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:22:12] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:22:12,897 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:22:12,927 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:23:56,535 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:23:56,535 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:23:56,535 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:23:56,583 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:23:56,583 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:23:56,640 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:23:56,690 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:25:14,616 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:25:14,616 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:25:14,616 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:25:14,647 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:25:14,648 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:25:14,693 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:25:14,722 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:25:38,335 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:25:38] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:25:39,766 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:25:39] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:25:40,213 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:25:40] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:25:40,447 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:25:40] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:25:41,323 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:25:41] "GET /api/agent/runs/31 HTTP/1.1" 200 -
2025-08-11 17:27:25,568 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:27:25] "GET /agent HTTP/1.1" 200 -
2025-08-11 17:27:25,795 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:27:25,811 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:27:25] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:27:25,960 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:27:25] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:27:25,963 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:27:25] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:27:33,471 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:27:33] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:27:33,524 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:27:33,557 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.0-flash-lite, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:27:44,307 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:27:44] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:27:47,807 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:27:47] "GET /api/agent/runs/32 HTTP/1.1" 200 -
2025-08-11 17:28:11,404 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:28:11,404 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:11,405 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:11,444 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:11,444 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:28:11,507 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:28:11,547 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:28:46,527 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:28:46,528 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:28:46,528 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:28:46,529 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:28:46,529 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:28:46,529 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:28:46,530 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:28:46,530 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:28:46,530 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:28:46,530 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:28:46,531 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:28:46,531 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:28:46,532 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:28:46,532 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:28:46,532 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:28:46,533 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:28:46,533 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:28:46,533 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:28:46,533 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:28:46,533 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:28:46,534 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:28:46,534 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:28:46,534 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:28:46,534 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:28:50,046 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:50,046 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:50,046 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:50,047 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:50,048 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:28:53,922 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 17:28:57,123 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:57,123 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:57,163 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:57,163 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:57,163 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:57,163 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:57,163 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:57,164 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:57,164 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:57,208 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:57,208 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:57,208 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:57,208 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:57,208 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:57,208 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:57,209 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:57,248 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:57,248 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:57,249 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:57,249 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:57,249 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:57,249 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:28:57,249 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:57,249 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:57,290 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:57,290 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:28:57,290 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:28:57,290 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:57,290 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:57,290 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:57,291 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:57,291 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:28:57,300 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 17:28:57,321 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 17:28:57,323 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 17:28:57,325 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 17:28:57,365 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:57,366 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:57,405 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:57,405 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:57,405 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:57,406 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:57,406 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:57,406 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:57,406 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:57,445 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:57,446 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:57,446 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:57,446 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:57,446 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:57,446 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:57,446 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:57,488 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:57,488 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:57,489 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:57,489 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:57,489 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:57,489 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:28:57,489 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:28:57,489 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:28:57,532 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:28:57,532 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:28:57,532 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:28:57,532 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:28:57,532 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:28:57,533 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:28:57,533 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:28:57,533 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:28:57,553 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 17:28:57,556 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 17:28:57,558 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 17:28:57,558 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 17:28:57,560 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 17:28:57,560 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 17:29:17,365 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 17:29:17,406 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:17] "GET /agent HTTP/1.1" 200 -
2025-08-11 17:29:17,605 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:17] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 17:29:17,764 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:17] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 17:29:17,784 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:17] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 17:29:17,792 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:17] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 17:29:17,795 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:17] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 17:29:17,800 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:17] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 17:29:17,898 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:17] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 17:29:18,094 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 17:29:18,110 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,111 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,114 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 17:29:18,115 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,196 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 17:29:18,402 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,423 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,427 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,427 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,429 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,498 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 17:29:18,714 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 17:29:18,729 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 17:29:18,734 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 17:29:18,740 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 17:29:18,744 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 17:29:18,796 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:18] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 17:29:19,013 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 17:29:19,029 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 17:29:19,033 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 17:29:19,037 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 17:29:19,039 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 17:29:19,095 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 17:29:19,306 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/js/tool-confirmation.js HTTP/1.1" 200 -
2025-08-11 17:29:19,327 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-11 17:29:19,625 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:29:19,633 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 17:29:19,643 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:29:19,644 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:29:19,646 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:29:19,878 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:19] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 17:29:20,009 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:20] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 17:29:20,111 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:20] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 17:29:20,786 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:20] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 17:29:21,039 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 17:29:21,116 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 17:29:21,120 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 17:29:21,125 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 17:29:21,132 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 17:29:21,142 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 17:29:21,346 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 17:29:21,428 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 17:29:21,431 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 17:29:21,440 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 17:29:21,442 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 17:29:21,445 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 17:29:21,649 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 17:29:21,728 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 17:29:21,730 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 17:29:21,741 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 17:29:21,743 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 17:29:21,748 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 17:29:21,944 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:21] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 17:29:22,047 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 17:29:22,052 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 17:29:22,053 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 17:29:22,055 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 17:29:22,056 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 17:29:22,253 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 17:29:22,354 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 17:29:22,361 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 17:29:22,362 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 17:29:22,363 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 17:29:22,365 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 17:29:22,548 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 17:29:22,645 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/js/admin/agent-runs.js HTTP/1.1" 200 -
2025-08-11 17:29:22,948 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:29:22,952 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 17:29:22,965 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:29:22,970 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:22] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:29:23,182 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:23] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 17:29:23,340 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:23] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 17:29:23,501 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:23] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 17:29:33,933 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:29:33,934 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:29:33,934 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:29:33,977 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:29:33,977 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:29:33,977 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:33] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:29:34,017 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:29:34,051 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:29:53,552 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:53] "GET /api/agent/runs/33 HTTP/1.1" 200 -
2025-08-11 17:29:59,306 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:29:59] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:30:00,309 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:30:00] "GET /api/agent/runs/34 HTTP/1.1" 200 -
2025-08-11 17:30:49,227 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:30:49,227 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:30:49,227 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:30:49,255 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:30:49,255 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:30:49,289 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:30:49,317 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:40:45,636 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:40:45,636 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:40:45,636 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:40:45,667 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:40:45,667 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:40:45,714 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:40:45,746 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:42:02,003 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:42:02,004 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:42:02,004 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:42:02,004 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:42:02,005 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:42:02,005 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:42:02,005 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:42:02,005 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:42:02,006 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:42:02,006 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:42:02,006 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:42:02,006 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:42:02,008 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:42:02,008 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:42:02,008 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:42:02,008 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:42:02,009 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:42:02,009 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:42:02,009 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:42:02,009 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:42:02,009 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:42:02,010 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:42:02,010 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:42:02,010 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:42:05,615 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:05,615 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:05,615 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:05,615 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:05,616 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:42:08,580 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 17:42:11,447 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:11,447 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:11,502 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:11,502 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:11,503 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:11,503 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:11,503 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:11,503 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:11,503 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:11,553 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:11,553 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:11,554 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:11,554 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:11,554 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:11,554 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:11,554 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:11,607 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:11,607 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:11,608 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:11,608 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:11,608 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:11,608 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:42:11,608 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:11,608 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:11,658 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:11,658 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:42:11,659 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:42:11,659 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:11,659 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:11,659 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:11,659 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:11,660 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:42:11,672 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 17:42:11,699 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 17:42:11,702 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 17:42:11,703 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 17:42:11,752 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:11,752 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:11,803 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:11,804 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:11,804 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:11,804 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:11,804 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:11,805 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:11,805 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:11,872 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:11,872 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:11,873 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:11,873 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:11,873 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:11,873 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:11,874 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:11,941 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:11,941 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:11,941 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:11,942 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:11,942 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:11,942 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:42:11,942 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:11,942 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:12,011 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:12,011 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:42:12,011 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:42:12,012 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:42:12,012 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:42:12,013 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:42:12,013 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:42:12,013 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:42:12,047 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 17:42:12,051 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 17:42:12,053 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 17:42:12,054 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 17:42:12,057 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 17:42:12,057 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 17:42:24,972 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 17:42:24,997 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:42:24] "GET /agent HTTP/1.1" 200 -
2025-08-11 17:42:25,202 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:42:25,212 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:42:25] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:42:25,402 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:42:25] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:42:25,406 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:42:25] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:42:32,102 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:42:32,103 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:42:32,103 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:42:32,141 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:42:32,141 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:42:32,142 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:42:32] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:42:32,191 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:42:32,219 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:42:45,795 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:42:45] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:42:47,323 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:42:47] "GET /api/agent/runs/37 HTTP/1.1" 200 -
2025-08-11 17:45:23,147 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:45:23,147 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:45:23,147 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:45:23,178 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:45:23,178 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:45:23,208 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:45:23,236 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:45:43,882 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:45:43,882 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:45:43,882 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:45:43,910 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:45:43,910 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:45:43,938 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:45:43,967 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:46:27,896 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:46:27,896 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:46:27,896 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:46:27,926 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:46:27,926 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:46:27,970 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:46:28,000 - INFO - [autogen_orchestrator.py:254] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:48:16,118 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:48:16,119 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:48:16,119 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:48:16,146 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:48:16,147 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:48:16,191 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:48:16,219 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:48:52,246 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:48:52,247 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:48:52,247 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:48:52,248 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:48:52,248 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:48:52,248 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:48:52,249 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:48:52,249 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:48:52,249 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:48:52,250 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:48:52,250 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:48:52,250 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:48:52,251 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:48:52,252 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:48:52,252 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:48:52,252 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:48:52,252 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:48:52,252 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:48:52,253 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:48:52,253 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:48:52,253 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:48:52,253 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:48:52,254 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:48:52,254 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:48:56,166 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:48:56,166 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:48:56,166 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:48:56,166 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:48:56,167 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:48:59,249 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 17:49:02,047 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:02,047 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:02,091 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:02,091 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:49:02,091 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:49:02,092 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:49:02,092 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:49:02,092 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:02,092 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:02,135 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:02,136 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:49:02,136 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:49:02,136 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:49:02,136 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:49:02,136 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:02,137 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:02,180 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:02,181 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:49:02,181 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:49:02,181 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:49:02,181 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:49:02,181 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:49:02,182 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:02,182 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:02,224 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:02,224 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:49:02,224 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:49:02,225 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:49:02,225 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:49:02,225 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:49:02,225 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:49:02,225 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:49:02,235 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 17:49:02,259 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 17:49:02,266 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 17:49:02,267 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 17:49:02,319 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:02,320 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:02,363 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:02,363 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:49:02,363 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:49:02,363 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:49:02,363 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:49:02,364 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:02,364 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:02,407 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:02,407 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:49:02,407 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:49:02,407 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:49:02,407 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:49:02,408 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:02,408 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:02,450 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:02,451 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:49:02,451 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:49:02,451 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:49:02,451 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:49:02,451 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:49:02,451 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:02,451 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:02,494 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:02,494 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:49:02,495 - INFO - [database.py:74] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:49:02,495 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:49:02,495 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:49:02,495 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:49:02,495 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:49:02,495 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:49:02,516 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 17:49:02,519 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 17:49:02,520 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 17:49:02,520 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 17:49:02,523 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 17:49:02,523 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 17:49:18,523 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:49:18,523 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:49:18,523 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:49:18,564 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:49:18,564 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:49:18,565 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:49:18] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:49:18,604 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:49:18,634 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:49:42,335 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:49:42] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:49:42,384 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:49:42,417 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:49:58,799 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:49:58] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:50:00,851 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:50:00] "GET /api/agent/runs/41 HTTP/1.1" 200 -
2025-08-11 17:50:36,410 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:50:36] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:50:36,500 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:50:36,569 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:50:37,369 - ERROR - [base_events.py:1771] - Task exception was never retrieved
future: <Task finished name='Task-88' coro=<AsyncClient.aclose() done, defined at /home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py", line 2018, in aclose
    await self._transport.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py", line 385, in aclose
    await self._pool.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 313, in aclose
    await self._close_connections(closing_connections)
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 305, in _close_connections
    await connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py", line 171, in aclose
    await self._connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py", line 265, in aclose
    await self._network_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 55, in aclose
    await self._stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/streams/tls.py", line 216, in aclose
    await self.transport_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 1314, in aclose
    self._transport.close()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/selector_events.py", line 860, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 761, in call_soon
    self._check_closed()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 519, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-08-11 17:50:47,042 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:50:47] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:50:48,715 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:50:48] "GET /api/agent/runs/42 HTTP/1.1" 200 -
2025-08-11 17:51:14,127 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:51:14] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:51:14,165 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:51:14,197 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:51:20,442 - ERROR - [_single_threaded_agent_runtime.py:611] - Error processing publish message for Agent_0c530378-44f5-4210-8ee4-54e854bb64ca/0c530378-44f5-4210-8ee4-54e854bb64ca
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_single_threaded_agent_runtime.py", line 606, in _on_message
    return await agent.on_message(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_base_agent.py", line 119, in on_message
    return await self.on_message_impl(message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py", line 67, in on_message_impl
    return await super().on_message_impl(message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_routed_agent.py", line 485, in on_message_impl
    return await h(self, message, ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_core/_routed_agent.py", line 268, in wrapper
    return_value = await func(self, message, ctx)  # type: ignore
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 723, in create
    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]
                                                                        ~~~~~~~~~~~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-11 17:51:20,637 - ERROR - [autogen_orchestrator.py:673] - Team run failed: TypeError: 'NoneType' object is not subscriptable
Traceback:
Traceback (most recent call last):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 723, in create
    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]
                                                                        ~~~~~~~~~~~~~~^^^

TypeError: 'NoneType' object is not subscriptable

Traceback (most recent call last):
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 667, in run_team
    result = await with_all_workbenches()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/services/autogen_orchestrator.py", line 594, in with_all_workbenches
    result = await team_obj.run(task=task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 340, in run
    async for message in self.run_stream(
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 554, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: TypeError: 'NoneType' object is not subscriptable
Traceback:
Traceback (most recent call last):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 133, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 953, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 1107, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/vijay/anaconda3/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py", line 723, in create
    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]
                                                                        ~~~~~~~~~~~~~~^^^

TypeError: 'NoneType' object is not subscriptable


2025-08-11 17:51:34,875 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:51:34] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:51:36,475 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:51:36] "GET /api/agent/runs/43 HTTP/1.1" 200 -
2025-08-11 17:52:34,809 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 17:52:34,900 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:34] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 17:52:35,068 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,286 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,289 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,294 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,381 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,588 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,593 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,594 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,682 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,884 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,889 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,891 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:35,977 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:35] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,215 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,237 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,243 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,246 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,250 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,267 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,524 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,545 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,556 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,568 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,571 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,576 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,834 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,847 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,853 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,865 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,872 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:36,876 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:36] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:37,141 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:37] "[36mGET /static/js/admin/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:37,150 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:37] "[36mGET /static/js/admin/agent-teams.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:37,474 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:52:37,520 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:37] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:37,525 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:37] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:52:37,533 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:37] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:52:37,535 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:37] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:52:37,536 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:37] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 17:52:37,551 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:37] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 17:52:39,861 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:39] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 17:52:39,870 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:39] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 17:52:42,463 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:42] "GET /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 17:52:42,761 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 17:52:42,761 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 17:52:42,761 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 17:52:42,764 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 17:52:42,764 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 17:52:42,764 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 17:52:42,764 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 17:52:43,493 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 17:52:43,499 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 17:52:43,513 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:52:43] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 17:53:03,252 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 112, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 17:53:03,266 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:03] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 17:53:08,567 - ERROR - [app.py:875] - Exception on /api/agent/teams/2 [PUT]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 54, in team_detail
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 103, in save
    cur.execute(
sqlite3.OperationalError: database is locked
2025-08-11 17:53:08,572 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:08] "[35m[1mPUT /api/agent/teams/2 HTTP/1.1[0m" 500 -
2025-08-11 17:53:08,663 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 112, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 17:53:08,670 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:08] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 17:53:08,887 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:08] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:53:08,889 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:08] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:53:14,681 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:14] "GET /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 17:53:14,998 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:14] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 17:53:15,678 - ERROR - [app.py:875] - Exception on /api/agent/teams/2 [PUT]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 54, in team_detail
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 103, in save
    cur.execute(
sqlite3.OperationalError: database is locked
2025-08-11 17:53:15,689 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:15] "[35m[1mPUT /api/agent/teams/2 HTTP/1.1[0m" 500 -
2025-08-11 17:53:16,007 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:16] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:53:16,009 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:16] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:53:17,499 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:17] "GET /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 17:53:17,807 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:17] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 17:53:36,783 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 112, in save
    cur.execute(
sqlite3.OperationalError: database is locked
2025-08-11 17:53:36,802 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:36] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 17:53:36,825 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:36] "PUT /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 17:53:37,136 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:37] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:53:37,137 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:53:37] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:56:34,936 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 17:56:34,937 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 17:56:34,938 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 17:56:34,938 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 17:56:34,938 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:56:34,938 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:56:34,939 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:56:34,939 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:56:34,939 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:56:34,939 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:56:34,939 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:56:34,939 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:56:34,940 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:56:34,940 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:56:34,940 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:56:34,940 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:56:34,941 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 17:56:34,941 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 17:56:34,941 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:56:34,941 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 17:56:34,941 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:56:34,942 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 17:56:34,942 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:56:34,942 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 17:56:34,942 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 17:56:34,942 - INFO - [database.py:294] - Closing database connection
2025-08-11 17:56:34,942 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 17:56:34,942 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 17:56:41,129 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:41,129 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:41,129 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:41,129 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:41,130 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:56:44,522 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 17:56:47,543 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:47,544 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:47,621 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:47,622 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:47,622 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:47,623 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:47,623 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:47,624 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:47,624 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:47,705 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:47,705 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:47,705 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:47,706 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:47,706 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:47,706 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:47,706 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:47,778 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:47,779 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:47,779 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:47,780 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:47,780 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:47,780 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:56:47,780 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:47,780 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:47,846 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:47,847 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:56:47,847 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:56:47,847 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:47,848 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:47,848 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:47,848 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:47,848 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:56:47,866 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 17:56:47,896 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 17:56:47,901 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 17:56:47,903 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 17:56:47,978 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:47,978 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:48,047 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:48,047 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:48,047 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:48,048 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:48,048 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:48,048 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:48,048 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:48,111 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:48,111 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:48,111 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:48,111 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:48,112 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:48,112 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:48,112 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:48,173 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:48,173 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:48,174 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:48,174 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:48,174 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:48,174 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 17:56:48,175 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:48,175 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:48,234 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:48,234 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 17:56:48,234 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:56:48,235 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 17:56:48,235 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 17:56:48,235 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 17:56:48,235 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 17:56:48,236 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 17:56:48,267 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 17:56:48,271 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 17:56:48,272 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 17:56:48,272 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 17:56:48,275 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 17:56:48,275 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 17:56:55,274 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:56:55] "GET /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 17:56:55,512 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 17:56:55,512 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 17:56:55,512 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 17:56:55,571 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 17:56:55,571 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 17:56:55,571 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 17:56:55,572 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 17:56:55,572 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 17:56:55,580 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 17:56:55,580 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 17:56:55,580 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 17:56:55,581 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 17:56:56,730 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 17:56:56,739 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 17:56:56,744 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:56:56] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 17:57:05,204 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 17:57:05,215 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 17:57:05,229 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:05] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 17:57:05,495 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:05] "PUT /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 17:57:05,802 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:05] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:57:05,804 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:05] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:57:14,663 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:14] "GET /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 17:57:14,965 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:14] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 17:57:29,537 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:29] "GET /agent HTTP/1.1" 200 -
2025-08-11 17:57:29,879 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:29] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:29,880 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:29] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:29,882 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:29] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:29,886 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:29] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:29,890 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:29] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:29,892 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:29] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:30,180 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:30] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:30,196 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:30] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:30,594 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 17:57:30,600 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:30] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 17:57:30,602 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:30] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 17:57:30,604 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:30] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 17:57:30,613 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:30] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 17:57:30,839 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:30] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 17:57:30,991 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:30] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 17:57:39,167 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:57:39] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:57:39,212 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:57:39,244 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:58:13,096 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:58:13] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 17:58:13,141 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:58:13,174 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 17:58:15,855 - ERROR - [base_events.py:1771] - Task exception was never retrieved
future: <Task finished name='Task-62' coro=<AsyncClient.aclose() done, defined at /home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py", line 2018, in aclose
    await self._transport.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py", line 385, in aclose
    await self._pool.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 313, in aclose
    await self._close_connections(closing_connections)
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 305, in _close_connections
    await connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py", line 171, in aclose
    await self._connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py", line 265, in aclose
    await self._network_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 55, in aclose
    await self._stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/streams/tls.py", line 216, in aclose
    await self.transport_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 1314, in aclose
    self._transport.close()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/selector_events.py", line 860, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 761, in call_soon
    self._check_closed()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 519, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-08-11 17:58:39,747 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:58:39] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 17:58:41,840 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 17:58:41] "GET /api/agent/runs/45 HTTP/1.1" 200 -
2025-08-11 18:06:48,257 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:06:48] "GET /agent HTTP/1.1" 200 -
2025-08-11 18:06:48,504 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:06:48,510 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:06:48] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:06:48,677 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:06:48] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:06:48,684 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:06:48] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:07:00,785 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:00] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 18:07:01,105 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,112 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,117 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,120 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,126 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,128 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,403 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,412 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,419 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/js/admin/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,422 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/js/admin/agent-teams.js HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,601 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:07:01,606 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:07:01,825 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 18:07:01,830 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 18:07:01,836 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:07:01,847 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:07:01,849 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:01] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 18:07:02,240 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:02] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 18:07:02,252 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:02] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 18:07:04,122 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:04] "GET /api/agent/workflows/2 HTTP/1.1" 200 -
2025-08-11 18:07:04,423 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:04] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:07:27,338 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:07:27,420 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:07:33,314 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:07:33] "POST /api/agent/run/workflow/2 HTTP/1.1" 200 -
2025-08-11 18:08:11,372 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:08:11] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 18:08:11,410 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:08:11,441 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:08:53,898 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 18:08:53,900 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 18:08:53,901 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 18:08:53,901 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 18:08:53,903 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 18:08:53,904 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 18:08:53,904 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:08:53,905 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 18:08:53,905 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:08:53,906 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 18:08:53,906 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:08:53,907 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 18:08:53,907 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:08:53,908 - INFO - [database.py:328] - Closing database connection
2025-08-11 18:08:53,908 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 18:08:53,909 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 18:08:53,910 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 18:08:53,910 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 18:08:53,911 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:08:53,911 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 18:08:53,911 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:08:53,912 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 18:08:53,912 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:08:53,912 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 18:08:53,913 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:08:53,913 - INFO - [database.py:328] - Closing database connection
2025-08-11 18:08:53,913 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 18:08:53,913 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 18:08:58,056 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:08:58,056 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:08:58,056 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:08:58,056 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:08:58,057 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:09:01,153 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 18:09:03,373 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:09:03,373 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:09:03,400 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:09:03,400 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:09:03,400 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:09:03,401 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:09:03,401 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:09:03,401 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:09:03,401 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:09:03,428 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:09:03,428 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:09:03,428 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:09:03,428 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:09:03,428 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:09:03,428 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:09:03,428 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:09:03,456 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:09:03,456 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:09:03,457 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:09:03,457 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:09:03,457 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:09:03,457 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 18:09:03,457 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:09:03,457 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:09:03,485 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:09:03,485 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 18:09:03,485 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:09:03,485 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:09:03,485 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:09:03,486 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:09:03,486 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:09:03,486 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:09:03,492 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 18:09:03,507 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 18:09:03,510 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 18:09:03,510 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 18:09:03,538 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:09:03,538 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:09:03,567 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:09:03,568 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:09:03,568 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:09:03,568 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:09:03,568 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:09:03,568 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:09:03,568 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:09:03,598 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:09:03,599 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:09:03,599 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:09:03,599 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:09:03,599 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:09:03,599 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:09:03,599 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:09:03,627 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:09:03,628 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:09:03,628 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:09:03,628 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:09:03,628 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:09:03,628 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 18:09:03,628 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:09:03,628 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:09:03,655 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:09:03,655 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 18:09:03,655 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:09:03,655 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:09:03,656 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:09:03,656 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:09:03,657 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:09:03,657 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:09:03,669 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 18:09:03,671 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 18:09:03,672 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 18:09:03,672 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 18:09:03,674 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 18:09:03,674 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 18:11:25,301 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 18:11:25,380 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:25] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 18:11:25,560 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:25] "[36mGET /static/js/admin/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 18:11:25,743 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:25] "[36mGET /static/js/admin/agent-teams.js HTTP/1.1[0m" 304 -
2025-08-11 18:11:25,769 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:11:25,785 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:25] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:11:26,111 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:26] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 18:11:26,114 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:26] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:11:26,115 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:26] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:11:26,128 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:26] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 18:11:33,461 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:33] "DELETE /api/agent/workflows/2 HTTP/1.1" 200 -
2025-08-11 18:11:33,703 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:33] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:11:33,785 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:33] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:11:35,877 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:35] "DELETE /api/agent/teams/2 HTTP/1.1" 200 -
2025-08-11 18:11:36,175 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:36] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:11:36,176 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:36] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:11:37,291 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 18:11:37,292 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:11:37,292 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:11:37,336 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:11:37,336 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 18:11:37,336 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 18:11:37,336 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 18:11:37,336 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 18:11:37,341 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 18:11:37,341 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 18:11:37,342 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 18:11:37,342 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 18:11:38,024 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 18:11:38,030 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 18:11:38,032 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:11:38] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 18:12:58,876 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:12:58] "POST /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:12:59,136 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:12:59] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:12:59,209 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:12:59] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:13:07,667 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:13:07] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:13:16,882 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:13:16] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:13:17,119 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:13:17] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 18:14:28,292 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 18:14:28,299 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:14:28] "PUT /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:14:28,301 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:14:28] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 18:14:28,534 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:14:28] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:14:28,602 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:14:28] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:14:30,765 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:14:30] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:15:02,079 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:15:02] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:15:21,732 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:15:21] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:15:22,064 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:15:22] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 18:15:46,991 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 18:15:46,998 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:15:46] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 18:15:47,292 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:15:47] "PUT /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:15:47,606 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:15:47] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:15:47,608 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:15:47] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:15:53,343 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:15:53] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:16:15,484 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:16:15] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:16:38,842 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:16:38] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:16:47,862 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:16:47] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:17:02,908 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:17:02] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:17:24,316 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:17:24] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:17:30,041 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:17:30] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:17:34,282 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:17:34] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:17:48,986 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:17:48] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:18:09,271 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:18:09] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:18:34,864 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:18:34] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:18:46,988 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:18:46] "POST /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:18:47,221 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:18:47] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:18:47,305 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:18:47] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:19:08,319 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:19:08,353 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:19:08,391 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:19:08,424 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:19:08,457 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:19:08,487 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:19:12,313 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:12] "POST /api/agent/run/workflow/3 HTTP/1.1" 200 -
2025-08-11 18:19:36,480 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:36] "[33mGET /admin/agent-rus HTTP/1.1[0m" 404 -
2025-08-11 18:19:36,707 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:36] "GET /static/vendor/bootstrap/bootstrap-5.2.3.min.css HTTP/1.1" 200 -
2025-08-11 18:19:36,817 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:36] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:36,829 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:36] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:41,636 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:41] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 18:19:41,954 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:41] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:41,961 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:41] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:41,969 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:41] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:41,970 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:41] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:41,972 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:41] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:41,973 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:41] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:42,261 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:42] "[36mGET /static/js/admin/agent-runs.js HTTP/1.1[0m" 304 -
2025-08-11 18:19:42,435 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:19:42,440 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:42] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:19:42,585 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:42] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 18:19:42,589 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:42] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:19:42,640 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:42] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 18:19:42,938 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:42] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 18:19:44,662 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:19:44] "GET /api/agent/runs/48 HTTP/1.1" 200 -
2025-08-11 18:20:28,391 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:20:28] "GET /api/agent/workflows/3 HTTP/1.1" 200 -
2025-08-11 18:20:28,644 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:20:28] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:32:18,866 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:18,866 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:18,866 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:18,866 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:18,868 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:22,470 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 18:32:25,745 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:25,745 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:25,787 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:25,787 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:25,787 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:25,787 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:25,788 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:25,788 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:25,788 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:25,831 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:25,832 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:25,832 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:25,832 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:25,832 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:25,832 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:25,832 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:25,886 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:25,887 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:25,887 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:25,887 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:25,888 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:25,888 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 18:32:25,888 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:25,888 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:25,937 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:25,937 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 18:32:25,937 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:25,938 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:25,938 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:25,938 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:25,938 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:25,938 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:25,948 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 18:32:25,972 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 18:32:25,976 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 18:32:25,977 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 18:32:26,022 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:26,022 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:26,075 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:26,075 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:26,075 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:26,076 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:26,076 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:26,076 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:26,076 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:26,125 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:26,126 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:26,126 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:26,126 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:26,126 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:26,127 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:26,127 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:26,175 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:26,175 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:26,175 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:26,175 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:26,176 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:26,176 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 18:32:26,176 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:26,176 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:26,224 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:26,225 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 18:32:26,225 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:26,225 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:26,225 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:26,226 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:26,226 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:26,226 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:26,248 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 18:32:26,251 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 18:32:26,253 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 18:32:26,253 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 18:32:26,255 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 18:32:26,255 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 18:32:26,255 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:26,255 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 18:32:26,255 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:26,255 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 18:32:26,255 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:26,256 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 18:32:26,256 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:26,256 - INFO - [database.py:328] - Closing database connection
2025-08-11 18:32:26,256 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 18:32:26,256 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 18:32:37,614 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 18:32:37,614 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 18:32:37,615 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 18:32:37,615 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 18:32:37,615 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 18:32:37,615 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 18:32:37,616 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:37,616 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 18:32:37,616 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:37,616 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 18:32:37,616 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:37,617 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 18:32:37,617 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:37,617 - INFO - [database.py:328] - Closing database connection
2025-08-11 18:32:37,617 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 18:32:37,617 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 18:32:37,618 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 18:32:37,618 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 18:32:37,618 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:37,618 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 18:32:37,619 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:37,619 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 18:32:37,619 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:37,619 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 18:32:37,619 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:32:37,619 - INFO - [database.py:328] - Closing database connection
2025-08-11 18:32:37,619 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 18:32:37,620 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 18:32:42,308 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:42,309 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:42,309 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:42,309 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:42,310 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:46,241 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 18:32:48,888 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:48,889 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:48,932 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:48,933 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:48,933 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:48,933 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:48,933 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:48,933 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:48,933 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:48,972 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:48,972 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:48,972 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:48,972 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:48,972 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:48,973 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:48,973 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:49,012 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:49,012 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:49,013 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:49,013 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:49,013 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:49,013 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 18:32:49,013 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:49,013 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:49,053 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:49,053 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 18:32:49,053 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:49,053 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:49,053 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:49,053 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:49,054 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:49,054 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:49,063 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 18:32:49,088 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 18:32:49,092 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 18:32:49,093 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 18:32:49,137 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:49,137 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:49,177 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:49,177 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:49,177 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:49,178 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:49,178 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:49,178 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:49,178 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:49,217 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:49,217 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:49,217 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:49,218 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:49,218 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:49,218 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:49,218 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:49,258 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:49,258 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:49,259 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:49,259 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:49,259 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:49,259 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 18:32:49,259 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:32:49,259 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:32:49,298 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:32:49,299 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 18:32:49,299 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:49,299 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:32:49,299 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:32:49,299 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:32:49,299 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:32:49,300 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:32:49,317 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 18:32:49,319 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 18:32:49,320 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 18:32:49,320 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 18:32:49,323 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 18:32:49,323 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 18:33:16,830 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 18:33:16,878 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:16] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 18:33:17,075 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-11 18:33:17,216 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-11 18:33:17,237 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 18:33:17,254 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-11 18:33:17,259 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-11 18:33:17,260 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-11 18:33:17,386 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-11 18:33:17,541 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-11 18:33:17,547 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-11 18:33:17,560 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-11 18:33:17,564 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-11 18:33:17,568 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-11 18:33:17,688 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-11 18:33:17,860 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 18:33:17,870 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-11 18:33:17,877 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-11 18:33:17,886 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-11 18:33:17,890 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-11 18:33:17,982 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:17] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-11 18:33:18,178 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-11 18:33:18,180 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-11 18:33:18,182 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-11 18:33:18,187 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-11 18:33:18,189 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-11 18:33:18,290 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-11 18:33:18,474 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-11 18:33:18,479 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-11 18:33:18,481 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-11 18:33:18,485 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-11 18:33:18,489 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-11 18:33:18,578 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-11 18:33:18,761 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-11 18:33:18,764 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:18] "GET /static/js/admin/agent-teams.js HTTP/1.1" 200 -
2025-08-11 18:33:19,067 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:33:19,113 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-11 18:33:19,114 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 18:33:19,117 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:33:19,125 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:33:19,131 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:33:19,139 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 18:33:19,509 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-11 18:33:19,516 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-11 18:33:19,739 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:19] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 18:33:39,186 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:39] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:33:39,509 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 18:33:39,509 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:33:39,509 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:33:39,606 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:33:39,606 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 18:33:39,606 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 18:33:39,606 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 18:33:39,606 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 18:33:39,621 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 18:33:39,621 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 18:33:39,622 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 18:33:39,622 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 18:33:40,352 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 18:33:40,359 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 18:33:40,360 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:40] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 18:33:46,916 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:46] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 18:33:47,264 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:33:47] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 18:34:08,841 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:34:08] "GET /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:34:09,186 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:34:09] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 18:34:15,877 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:34:15] "DELETE /api/agent/teams/4 HTTP/1.1" 200 -
2025-08-11 18:34:16,185 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:34:16] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:34:16,189 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:34:16] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:34:16,975 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:34:16] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 18:34:17,317 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:34:17] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 18:35:00,122 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 18:35:00,127 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:00] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 18:35:00,430 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:00] "PUT /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 18:35:00,740 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:00] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:35:00,742 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:00] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:35:06,983 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:06] "DELETE /api/agent/workflows/3 HTTP/1.1" 200 -
2025-08-11 18:35:07,278 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:07] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:35:07,279 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:07] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:35:08,774 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:08] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 18:35:09,077 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:09] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:35:44,360 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:35:44,390 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:35:44,421 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:35:44,450 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:35:44,480 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:35:44,508 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:35:55,119 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:55] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:35:57,523 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:35:57] "GET /api/agent/runs/49 HTTP/1.1" 200 -
2025-08-11 18:36:06,538 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:36:06] "POST /api/agent/run/workflow/4 HTTP/1.1" 200 -
2025-08-11 18:36:17,429 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:36:17] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:36:24,766 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:36:24] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:36:43,351 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:36:43] "GET /api/agent/runs/49 HTTP/1.1" 200 -
2025-08-11 18:44:45,163 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 18:44:45,166 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 18:44:45,167 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 18:44:45,167 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 18:44:45,168 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 18:44:45,168 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 18:44:45,169 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:44:45,169 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 18:44:45,169 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:44:45,169 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 18:44:45,170 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:44:45,170 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 18:44:45,170 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:44:45,170 - INFO - [database.py:328] - Closing database connection
2025-08-11 18:44:45,170 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 18:44:45,171 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 18:44:45,172 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 18:44:45,172 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 18:44:45,173 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:44:45,173 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 18:44:45,173 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:44:45,173 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 18:44:45,173 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:44:45,174 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 18:44:45,174 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 18:44:45,174 - INFO - [database.py:328] - Closing database connection
2025-08-11 18:44:45,174 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 18:44:45,174 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 18:44:48,782 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:48,782 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:48,782 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:48,782 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:48,783 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:44:51,871 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 18:44:54,415 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:44:54,416 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:44:54,456 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:44:54,456 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:54,456 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:54,457 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:54,457 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:54,457 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:44:54,457 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:44:54,501 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:44:54,502 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:54,502 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:54,502 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:54,502 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:54,502 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:44:54,502 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:44:54,546 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:44:54,546 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:54,547 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:54,547 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:54,547 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:54,547 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 18:44:54,547 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:44:54,547 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:44:54,599 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:44:54,599 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 18:44:54,599 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:44:54,599 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:54,600 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:54,600 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:54,600 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:54,600 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:44:54,613 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 18:44:54,641 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 18:44:54,644 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 18:44:54,645 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 18:44:54,692 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:44:54,693 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:44:54,745 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:44:54,745 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:54,746 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:54,746 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:54,746 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:54,746 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:44:54,746 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:44:54,791 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:44:54,791 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:54,791 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:54,791 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:54,792 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:54,792 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:44:54,792 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:44:54,839 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:44:54,839 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:54,839 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:54,839 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:54,839 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:54,840 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 18:44:54,840 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:44:54,840 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:44:54,884 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:44:54,885 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 18:44:54,885 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:44:54,885 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 18:44:54,885 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 18:44:54,885 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 18:44:54,886 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 18:44:54,886 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 18:44:54,907 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 18:44:54,910 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 18:44:54,911 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 18:44:54,912 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 18:44:54,915 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 18:44:54,915 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 18:44:58,431 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 18:44:58,457 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:44:58] "GET /agent HTTP/1.1" 200 -
2025-08-11 18:44:58,655 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:44:58] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 18:44:58,787 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:44:58] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-11 18:44:58,808 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:44:58,818 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:44:58] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:44:59,105 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:44:59] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:44:59,107 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:44:59] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:45:28,622 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 18:45:28,622 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 18:45:28,622 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 18:45:28,658 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 18:45:28,658 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 18:45:28,659 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:28] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 18:45:28,691 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:45:28,720 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:45:28,750 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:45:28,780 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:45:28,811 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:45:28,839 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:45:34,724 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:34] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:45:36,466 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:36] "GET /api/agent/runs/50 HTTP/1.1" 200 -
2025-08-11 18:45:49,792 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:49] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:45:51,192 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:51] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:45:51,846 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:51] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:45:52,144 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:52] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:45:57,619 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:57] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:45:58,342 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:45:58] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:46:00,538 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:46:00] "GET /api/agent/runs/50 HTTP/1.1" 200 -
2025-08-11 18:47:25,495 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:47:25] "GET /agent HTTP/1.1" 200 -
2025-08-11 18:47:25,736 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:47:25,740 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:47:25] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:47:25,864 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:47:25] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:47:25,866 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:47:25] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:47:51,190 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:47:51] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 18:47:51,225 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:47:51,257 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:47:51,285 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:47:51,314 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:47:51,343 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:47:51,377 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 18:47:55,893 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:47:55] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:47:57,397 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:47:57] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:48:03,682 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:03] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:48:04,444 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:04] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:48:05,075 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:05] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:48:06,805 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:06] "GET /api/agent/runs/51 HTTP/1.1" 200 -
2025-08-11 18:48:14,459 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:14] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:48:19,116 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:19] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:48:21,129 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 18:48:21,454 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:48:21,456 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:48:21,459 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:48:21,464 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 18:48:21,466 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:48:21,468 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 18:48:21,851 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:48:21,861 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 18:48:21,865 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 18:48:21,876 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:21] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:48:22,087 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:22] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 18:48:22,203 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:22] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 18:48:26,531 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:48:26] "GET /api/agent/runs/51 HTTP/1.1" 200 -
2025-08-11 18:50:40,448 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:40] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 18:50:40,668 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:40] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:40,750 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:40] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:40,759 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:40] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:40,765 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:40] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:40,975 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:40] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,059 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,064 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,067 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,294 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,411 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,418 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,423 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,590 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,759 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,781 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,786 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,875 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,879 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:41,887 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:41] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,057 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,079 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,081 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,172 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,177 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,183 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,355 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,367 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,371 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,467 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,470 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,472 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,658 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/js/admin/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:42,668 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "GET /static/js/admin/agent-teams.js HTTP/1.1" 200 -
2025-08-11 18:50:42,972 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 18:50:42,981 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 18:50:42,986 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:42] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:43,015 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:43] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 18:50:43,019 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:43] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:50:43,021 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:43] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 18:50:43,031 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:43] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 18:50:43,322 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:43] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 18:50:43,325 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:43] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 18:50:44,791 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:44] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 18:50:45,034 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:45] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 18:50:49,479 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:49] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 18:50:49,792 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 18:50:49,792 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 18:50:49,792 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 18:50:49,794 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 18:50:49,794 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 18:50:49,794 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 18:50:49,795 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 18:50:50,556 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 18:50:50,563 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 18:50:50,565 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:50:50] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 18:51:31,211 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:51:31] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 18:51:31,537 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 18:51:31] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 22:33:17,404 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:17] "[32mGET /admin/agent-teams HTTP/1.1[0m" 302 -
2025-08-11 22:33:17,652 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:17] "GET /login HTTP/1.1" 200 -
2025-08-11 22:33:17,736 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:17] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:18,013 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:18] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:18,016 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:18] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:18,020 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:18] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:18,023 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:18] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:18,024 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:18] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:22,500 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:22] "[32mPOST /login HTTP/1.1[0m" 302 -
2025-08-11 22:33:22,509 - DEBUG - [app.py:172] - Main page requested
2025-08-11 22:33:22,511 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:22] "GET / HTTP/1.1" 200 -
2025-08-11 22:33:22,880 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:22] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:22,883 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:22] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:22,886 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:22] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:22,889 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:22] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:22,892 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:22] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:22,897 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:22] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,202 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,203 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,208 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,209 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,212 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,218 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,510 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,512 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,518 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,526 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,527 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,530 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,826 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,832 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,837 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,843 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,850 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:23,852 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:23] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:24,136 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:24] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:24,470 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 22:33:24,474 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:24] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:24,486 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:24] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 22:33:24,729 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:24] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:24,818 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:24] "GET /agent HTTP/1.1" 200 -
2025-08-11 22:33:24,821 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:24] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:24,933 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:24] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-11 22:33:25,244 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:25] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:25,286 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:25] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:25,296 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 22:33:25,310 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:25] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 22:33:25,602 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:25] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:33:25,607 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:25] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:33:33,391 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:33] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 22:33:33,441 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:33:33,475 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:33:33,510 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:33:33,545 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:33:33,582 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:33:33,617 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:33:37,306 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:37] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 22:33:37,661 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:37] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:37,665 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:37] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:37,674 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:37] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:37,675 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:37] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:37,680 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:37] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:37,995 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:37] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,004 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,011 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,022 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,028 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,317 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,324 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,331 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,341 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,346 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,638 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,643 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,646 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,657 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,658 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,973 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,979 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,981 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,986 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:38,993 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:38] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,288 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,292 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,297 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,301 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,304 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,598 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "[36mGET /static/js/admin/agent-runs.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,600 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,916 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 22:33:39,921 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 22:33:39,924 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 22:33:39,928 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:39] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:33:40,288 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:40] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 22:33:40,303 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:33:40] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 22:34:02,708 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:34:02] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:34:03,740 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:34:03] "GET /api/agent/runs/52 HTTP/1.1" 200 -
2025-08-11 22:39:44,418 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:39:44,419 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:39:44,420 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:39:44,421 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:39:44,431 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:40:01,851 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 22:40:11,375 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:40:11,376 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:40:11,560 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:40:11,562 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:40:11,563 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:40:11,564 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:40:11,565 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:40:11,566 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:40:11,566 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:40:11,722 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:40:11,723 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:40:11,724 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:40:11,724 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:40:11,725 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:40:11,725 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:40:11,726 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:40:11,872 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:40:11,873 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:40:11,874 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:40:11,875 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:40:11,876 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:40:11,876 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 22:40:11,877 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:40:11,877 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:40:12,044 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:40:12,044 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 22:40:12,045 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:40:12,046 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:40:12,047 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:40:12,047 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:40:12,048 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:40:12,048 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:40:12,083 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 22:40:12,152 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 22:40:12,164 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 22:40:12,167 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 22:40:12,353 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:40:12,353 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:40:12,645 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:40:12,646 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:40:12,647 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:40:12,647 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:40:12,648 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:40:12,648 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:40:12,648 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:40:12,778 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:40:12,779 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:40:12,781 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:40:12,781 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:40:12,782 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:40:12,789 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:40:12,790 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:40:12,935 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:40:12,936 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:40:12,937 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:40:12,937 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:40:12,938 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:40:12,938 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 22:40:12,939 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:40:12,939 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:40:13,060 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:40:13,060 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 22:40:13,061 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:40:13,061 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:40:13,062 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:40:13,063 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:40:13,063 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:40:13,064 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:40:13,129 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 22:40:13,144 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 22:40:13,147 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 22:40:13,147 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 22:40:13,152 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 22:40:13,153 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 22:40:14,050 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 22:40:14,126 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "GET /agent HTTP/1.1" 200 -
2025-08-11 22:40:14,283 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,614 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,646 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,661 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,680 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,682 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,694 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,928 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,960 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:14,978 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:14] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,021 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,031 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,039 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,248 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,289 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,321 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,373 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,394 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,423 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,582 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,615 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,651 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,719 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,723 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,751 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,906 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,943 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:15,985 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:15] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:16,048 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:16,054 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:16,073 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:16,223 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:16,267 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-11 22:40:16,420 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 22:40:16,453 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 22:40:16,634 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:40:16,640 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:40:16,651 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:16,749 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:16] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:17,080 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:17] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:20,089 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:20] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 22:40:20,509 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:20] "[36mGET /static/js/admin/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:20,510 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:20] "[36mGET /static/js/admin/agent-teams.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:20,771 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 22:40:20,787 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:20] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 22:40:20,941 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:20] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:40:20,948 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:20] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 22:40:20,960 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:20] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:40:20,993 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:20] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 22:40:23,029 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:23] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 22:40:23,362 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:23] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:40:51,826 - DEBUG - [app.py:172] - Main page requested
2025-08-11 22:40:51,829 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:51] "GET / HTTP/1.1" 200 -
2025-08-11 22:40:52,192 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,196 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,202 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,208 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,211 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,212 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,511 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,513 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,883 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-11 22:40:52,886 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:52,888 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:52] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-11 22:40:53,153 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:53] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 22:40:53,219 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:53] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:53,426 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:53] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-11 22:40:53,806 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:53] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-11 22:40:55,407 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:55] "GET /agent HTTP/1.1" 200 -
2025-08-11 22:40:55,772 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:55] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:55,779 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:55] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-11 22:40:56,020 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 22:40:56,024 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:56] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 22:40:56,108 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:56] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:40:56,121 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:40:56] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:41:02,866 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 22:41:02,866 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:41:02,866 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:41:02,904 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:41:02,904 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 22:41:02,905 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:02] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 22:41:02,942 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:41:02,975 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:41:03,009 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:41:03,043 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:41:03,074 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:41:03,105 - INFO - [autogen_orchestrator.py:271] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:41:12,223 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 22:41:12,601 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,607 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,616 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,617 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,622 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,924 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,928 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,933 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,939 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:12,942 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:12] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,234 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,243 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,246 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,254 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,258 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,547 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,553 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,560 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,567 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,570 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,873 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,878 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,887 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,890 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:13,894 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:13] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,185 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,204 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,206 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,210 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,213 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,492 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,517 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "[36mGET /static/js/admin/agent-runs.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,839 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 22:41:14,843 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:14,845 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:41:14,855 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:14] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 22:41:15,220 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:15] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 22:41:15,222 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:15] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 22:41:16,715 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:41:16] "GET /api/agent/runs/53 HTTP/1.1" 200 -
2025-08-11 22:43:52,224 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 22:43:52,224 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 22:43:52,224 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 22:43:52,225 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 22:43:52,225 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 22:43:52,225 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 22:43:52,225 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 22:43:52,225 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 22:43:52,225 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 22:43:52,225 - INFO - [database.py:328] - Closing database connection
2025-08-11 22:43:52,226 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 22:43:52,226 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 22:43:52,226 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 22:43:52,227 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 22:43:52,227 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 22:43:52,227 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 22:43:52,227 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 22:43:52,227 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 22:43:52,227 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 22:43:52,227 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 22:43:52,228 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 22:43:52,228 - INFO - [database.py:328] - Closing database connection
2025-08-11 22:43:52,228 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 22:43:52,228 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 22:43:56,839 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:43:56,839 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:43:56,840 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:43:56,840 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:43:56,843 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:44:02,405 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 22:44:06,187 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:44:06,187 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:44:06,225 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:44:06,226 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:44:06,226 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:44:06,226 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:44:06,226 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:44:06,227 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:44:06,227 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:44:06,266 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:44:06,267 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:44:06,267 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:44:06,267 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:44:06,268 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:44:06,268 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:44:06,268 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:44:06,307 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:44:06,307 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:44:06,308 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:44:06,308 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:44:06,308 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:44:06,308 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 22:44:06,308 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:44:06,308 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:44:06,347 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:44:06,348 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 22:44:06,348 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:44:06,348 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:44:06,348 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:44:06,348 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:44:06,349 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:44:06,349 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:44:06,358 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 22:44:06,383 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 22:44:06,386 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 22:44:06,387 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 22:44:06,430 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:44:06,430 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:44:06,472 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:44:06,473 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:44:06,473 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:44:06,473 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:44:06,474 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:44:06,474 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:44:06,474 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:44:06,515 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:44:06,516 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:44:06,516 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:44:06,516 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:44:06,516 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:44:06,517 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:44:06,517 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:44:06,562 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:44:06,562 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:44:06,562 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:44:06,563 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:44:06,563 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:44:06,563 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 22:44:06,563 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:44:06,563 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:44:06,619 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:44:06,619 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 22:44:06,620 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:44:06,620 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 22:44:06,620 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 22:44:06,620 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 22:44:06,620 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 22:44:06,621 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 22:44:06,641 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 22:44:06,644 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 22:44:06,646 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 22:44:06,646 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 22:44:06,648 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 22:44:06,649 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 22:44:44,055 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 22:44:44,081 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:44:44] "GET /agent HTTP/1.1" 200 -
2025-08-11 22:44:44,276 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 22:44:44,284 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:44:44] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 22:44:44,500 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:44:44] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:44:44,502 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:44:44] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:45:00,772 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:00] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:45:10,752 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 22:45:10,752 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 22:45:10,752 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 22:45:10,788 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 22:45:10,788 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 22:45:10,789 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:10] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 22:45:10,824 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:45:10,856 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:45:10,889 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:45:10,925 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:45:10,960 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:45:10,995 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:45:12,007 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:12] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:45:13,382 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:13] "GET /api/agent/runs/54 HTTP/1.1" 200 -
2025-08-11 22:45:16,531 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:16] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:45:19,447 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:19] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:45:21,499 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:21] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:45:21,959 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:21] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:45:22,696 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:22] "GET /api/agent/runs/54 HTTP/1.1" 200 -
2025-08-11 22:45:45,261 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:45] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:45:46,552 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:45:46] "GET /api/agent/runs/54 HTTP/1.1" 200 -
2025-08-11 22:46:21,844 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:46:21] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:46:23,020 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:46:23] "GET /api/agent/runs/54 HTTP/1.1" 200 -
2025-08-11 22:46:50,786 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:46:50] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:46:51,048 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 22:46:51,049 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 22:46:51,049 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 22:46:51,053 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 22:46:51,054 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 22:46:51,054 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 22:46:51,055 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 22:46:51,935 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 22:46:51,942 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 22:46:51,944 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:46:51] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 22:48:16,162 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 22:48:16,176 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:48:16] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 22:48:16,178 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:48:16] "PUT /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:48:16,426 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:48:16] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:48:16,504 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:48:16] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:48:18,358 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:48:18] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:48:18,689 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:48:18] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 22:50:27,666 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 22:50:27,669 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:27] "PUT /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:50:27,673 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:27] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 22:50:27,930 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:27] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:50:27,986 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:27] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:50:29,073 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:29] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:50:29,391 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:29] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 22:50:33,233 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:33] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 22:50:33,563 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:33] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:50:47,353 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:47] "GET /agent HTTP/1.1" 200 -
2025-08-11 22:50:47,769 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 22:50:47,780 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:47] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:50:47,783 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:47] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:50:47,788 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:47] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 22:50:52,695 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:52] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 22:50:52,740 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:50:52,774 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:50:52,813 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:50:52,842 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:50:52,873 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:50:52,905 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 22:50:54,469 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:54] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:50:56,782 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:50:56] "GET /api/agent/runs/55 HTTP/1.1" 200 -
2025-08-11 22:51:05,831 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:51:05] "GET /api/agent/runs/55 HTTP/1.1" 200 -
2025-08-11 22:51:16,210 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:51:16] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 22:51:17,387 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:51:17] "GET /api/agent/runs/55 HTTP/1.1" 200 -
2025-08-11 22:52:46,877 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:52:46] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 22:52:47,128 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:52:47] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:52:55,487 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:52:55] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:53:05,861 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:53:05] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:53:07,592 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:53:07] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:53:12,450 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:53:12] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:53:12,700 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:53:12] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 22:53:19,656 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:53:19] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 22:53:19,973 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:53:19] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:53:25,072 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:53:25] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:53:58,421 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:53:58] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:54:26,506 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:54:26] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:54:41,989 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:54:41] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:54:45,356 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:54:45] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:55:02,042 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:55:02] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:55:22,379 - ERROR - [app.py:875] - Exception on /api/agent/workflows [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 66, in workflows
    wf.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_workflow.py", line 92, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_workflows.name
2025-08-11 22:55:22,382 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:55:22] "[35m[1mPOST /api/agent/workflows HTTP/1.1[0m" 500 -
2025-08-11 22:55:52,801 - ERROR - [app.py:875] - Exception on /api/agent/workflows/4 [PUT]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 90, in workflow_detail
    wf.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_workflow.py", line 83, in save
    cur.execute(
sqlite3.OperationalError: database is locked
2025-08-11 22:55:52,806 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:55:52] "[35m[1mPUT /api/agent/workflows/4 HTTP/1.1[0m" 500 -
2025-08-11 22:55:53,143 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:55:53] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:55:53,144 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:55:53] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 22:55:54,447 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:55:54] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 22:55:54,790 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:55:54] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:55:57,213 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:55:57] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:13,514 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:13] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:13,780 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:13] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 22:56:16,379 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:16] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 22:56:16,692 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:16] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:56:39,927 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:39] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:40,860 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:40] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:41,660 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:41] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:43,312 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:43] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:43,567 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:43] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:46,423 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:46] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 22:56:46,750 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:46] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:56:53,384 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:53] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:54,900 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:54] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:55,932 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:55] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:56:56,997 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:56:56] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:57:06,579 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:57:06] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 22:57:14,020 - ERROR - [app.py:875] - Exception on /api/agent/workflows [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 66, in workflows
    wf.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_workflow.py", line 92, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_workflows.name
2025-08-11 22:57:14,022 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:57:14] "[35m[1mPOST /api/agent/workflows HTTP/1.1[0m" 500 -
2025-08-11 22:57:44,126 - ERROR - [app.py:875] - Exception on /api/agent/workflows/4 [PUT]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 90, in workflow_detail
    wf.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_workflow.py", line 83, in save
    cur.execute(
sqlite3.OperationalError: database is locked
2025-08-11 22:57:44,131 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:57:44] "[35m[1mPUT /api/agent/workflows/4 HTTP/1.1[0m" 500 -
2025-08-11 22:57:44,143 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:57:44] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 22:57:44,458 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 22:57:44] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:00:21,979 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:00:21] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 23:00:22,235 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:00:22] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:00:27,172 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:00:27] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:06:27,622 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:27] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 23:06:27,857 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:27] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:06:27,968 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:06:27,976 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:27] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:06:28,299 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:28] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 23:06:28,308 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:28] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 23:06:28,314 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:28] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:06:28,317 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:28] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:06:28,326 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:28] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 23:06:28,741 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:28] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 23:06:30,205 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:30] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 23:06:30,525 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:06:30] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:08:35,257 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 23:08:35,260 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 23:08:35,261 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 23:08:35,261 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 23:08:35,262 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:08:35,263 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:08:35,263 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:08:35,264 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:08:35,264 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:08:35,264 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:08:35,265 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:08:35,265 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:08:35,266 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:08:35,266 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:08:35,266 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:08:35,267 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:08:35,268 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:08:35,269 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:08:35,269 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:08:35,269 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:08:35,270 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:08:35,270 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:08:35,270 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:08:35,271 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:08:35,271 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:08:35,272 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:08:35,272 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:08:35,272 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:08:39,343 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:39,344 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:39,344 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:39,344 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:39,345 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:08:42,799 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 23:08:45,274 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:08:45,274 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:08:45,304 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:08:45,305 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:45,305 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:45,305 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:45,305 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:45,305 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:08:45,306 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:08:45,340 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:08:45,340 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:45,340 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:45,340 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:45,340 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:45,340 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:08:45,340 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:08:45,374 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:08:45,374 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:45,374 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:45,374 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:45,374 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:45,374 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 23:08:45,375 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:08:45,375 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:08:45,405 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:08:45,406 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 23:08:45,406 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:08:45,406 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:45,406 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:45,406 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:45,406 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:45,406 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:08:45,413 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 23:08:45,433 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 23:08:45,437 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 23:08:45,438 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 23:08:45,471 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:08:45,471 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:08:45,505 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:08:45,506 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:45,506 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:45,506 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:45,506 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:45,507 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:08:45,507 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:08:45,538 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:08:45,538 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:45,538 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:45,538 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:45,539 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:45,539 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:08:45,539 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:08:45,575 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:08:45,575 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:45,576 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:45,576 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:45,576 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:45,576 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 23:08:45,576 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:08:45,576 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:08:45,608 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:08:45,608 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 23:08:45,608 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:08:45,609 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:08:45,609 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:08:45,609 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:08:45,609 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:08:45,609 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:08:45,626 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 23:08:45,629 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 23:08:45,630 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 23:08:45,631 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 23:08:45,632 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 23:08:45,632 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 23:08:50,178 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 23:08:50,261 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:50] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 23:08:50,431 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:08:50,441 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:50] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:08:50,699 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:50] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 23:08:50,714 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:50] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 23:08:50,716 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:50] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:08:50,718 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:50] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:08:53,550 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:53] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 23:08:53,876 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:53] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:08:59,734 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:08:59] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:11,163 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:11] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:12,314 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:12] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:24,559 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:24] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:26,954 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:26] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:37,050 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:37] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:37,509 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:37] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:43,769 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:43] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:44,925 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:44] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:09:59,130 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:59] "POST /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:09:59,132 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:59] "PUT /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 23:09:59,386 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:59] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:09:59,467 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:59] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:09:59,472 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:59] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:09:59,711 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:09:59] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:10:06,357 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:06] "GET /api/agent/workflows/4 HTTP/1.1" 200 -
2025-08-11 23:10:06,679 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:06] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:10:17,428 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:17] "GET /agent HTTP/1.1" 200 -
2025-08-11 23:10:17,789 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:17] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:17,794 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:17] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:17,798 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:17] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:17,804 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:17] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:17,811 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:17] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:17,812 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:17] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:18,110 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:18] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:18,119 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:18] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:18,517 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:10:18,525 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:18] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 23:10:18,528 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:18] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:10:18,531 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:18] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:10:18,536 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:18] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:10:18,787 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:18] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 23:10:18,877 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:18] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 23:10:22,196 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 23:10:22,196 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:10:22,196 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:10:22,230 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:10:22,231 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 23:10:22,231 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:22] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:10:22,266 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:10:22,295 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:10:22,325 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:10:22,355 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:10:22,388 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:10:22,418 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:10:26,982 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:26] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:10:28,629 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:28] "GET /api/agent/runs/56 HTTP/1.1" 200 -
2025-08-11 23:10:37,464 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:37] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:10:39,554 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:10:39] "GET /api/agent/runs/56 HTTP/1.1" 200 -
2025-08-11 23:11:01,324 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:11:01] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:11:02,337 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:11:02] "GET /api/agent/runs/56 HTTP/1.1" 200 -
2025-08-11 23:12:12,583 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:12:12] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:12:12,842 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 23:12:12,842 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 23:12:12,843 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 23:12:12,846 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 23:12:12,846 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 23:12:12,847 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 23:12:12,847 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 23:12:13,679 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 23:12:13,686 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 23:12:13,687 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:12:13] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:13:19,385 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 23:13:19,401 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:13:19] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 23:13:19,402 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:13:19] "PUT /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:13:19,621 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:13:19] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:13:19,718 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:13:19] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:13:21,012 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:13:21] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:13:21,327 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:13:21] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:14:12,916 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 23:14:12,922 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:14:12] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 23:14:13,230 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:14:13] "PUT /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:14:13,568 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:14:13] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:14:13,570 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:14:13] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:14:14,521 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:14:14] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:14:14,832 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:14:14] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:16:16,356 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:16:16] "GET /admin/mcp-servers HTTP/1.1" 200 -
2025-08-11 23:16:16,563 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:16:16] "GET /static/js/admin/mcp-servers.js HTTP/1.1" 200 -
2025-08-11 23:16:16,709 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:16:16,724 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:16:16] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:16:16,891 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:16:16] "GET /api/admin/mcp-servers HTTP/1.1" 200 -
2025-08-11 23:16:16,900 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:16:16] "GET /api/admin/mcp-servers HTTP/1.1" 200 -
2025-08-11 23:17:45,911 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:17:45] "GET /api/agent/runs/55 HTTP/1.1" 200 -
2025-08-11 23:17:53,679 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:17:53] "GET /api/agent/runs/56 HTTP/1.1" 200 -
2025-08-11 23:19:50,976 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 23:19:50,976 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 23:19:50,977 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 23:19:50,977 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 23:19:50,977 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:19:50,978 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:19:50,978 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:19:50,978 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:19:50,978 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:19:50,979 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:19:50,979 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:19:50,979 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:19:50,979 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:19:50,979 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:19:50,979 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:19:50,980 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:19:50,980 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:19:50,980 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:19:50,981 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:19:50,981 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:19:50,981 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:19:50,981 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:19:50,981 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:19:50,981 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:19:50,982 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:19:50,982 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:19:50,982 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:19:50,982 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:19:54,928 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:19:54,928 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:19:54,928 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:19:54,929 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:19:54,930 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:19:58,400 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 23:20:00,736 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:00,737 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:00,767 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:00,767 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:20:00,767 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:20:00,767 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:20:00,767 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:20:00,768 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:00,768 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:00,799 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:00,799 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:20:00,800 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:20:00,800 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:20:00,800 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:20:00,800 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:00,800 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:00,830 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:00,830 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:20:00,830 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:20:00,830 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:20:00,830 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:20:00,831 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 23:20:00,831 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:00,831 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:00,859 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:00,859 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 23:20:00,859 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:20:00,859 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:20:00,859 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:20:00,859 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:20:00,859 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:20:00,860 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:20:00,866 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 23:20:00,888 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 23:20:00,890 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 23:20:00,891 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 23:20:00,921 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:00,922 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:00,951 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:00,951 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:20:00,952 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:20:00,952 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:20:00,952 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:20:00,952 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:00,952 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:00,981 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:00,982 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:20:00,982 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:20:00,982 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:20:00,982 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:20:00,982 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:00,982 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:01,012 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:01,012 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:20:01,013 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:20:01,013 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:20:01,013 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:20:01,013 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 23:20:01,013 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:01,013 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:01,044 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:01,044 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 23:20:01,044 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:20:01,044 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:20:01,044 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:20:01,044 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:20:01,045 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:20:01,045 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:20:01,057 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 23:20:01,059 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 23:20:01,061 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 23:20:01,061 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 23:20:01,063 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 23:20:01,063 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 23:20:11,545 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 23:20:11,587 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:11] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 23:20:11,797 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:11] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:11,929 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:20:11,937 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:11] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:20:12,224 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:12] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 23:20:12,227 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:12] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 23:20:12,235 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:12] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:20:12,236 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:12] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:20:12,247 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:12] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 23:20:12,663 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:12] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 23:20:13,557 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:13] "GET /admin/mcp-servers HTTP/1.1" 200 -
2025-08-11 23:20:13,956 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:20:13,964 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:13] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:20:13,966 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:13] "GET /api/admin/mcp-servers HTTP/1.1" 200 -
2025-08-11 23:20:14,213 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:14] "GET /api/admin/mcp-servers HTTP/1.1" 200 -
2025-08-11 23:20:15,812 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:15] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 23:20:16,169 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,171 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,180 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,182 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,188 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,189 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,478 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,491 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,879 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:20:16,883 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 23:20:16,885 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:20:16,894 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:16] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:20:17,160 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:17] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 23:20:17,310 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:17] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 23:20:18,459 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:18] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:20:18,794 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 23:20:18,795 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:20:18,795 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:20:18,840 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:20:18,840 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 23:20:18,840 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 23:20:18,840 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 23:20:18,840 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 23:20:18,845 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 23:20:18,846 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 23:20:18,846 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 23:20:18,846 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 23:20:19,641 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 23:20:19,649 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 23:20:19,651 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:19] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:20:43,662 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:43] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-11 23:20:44,251 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:44] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-11 23:20:44,328 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:20:44] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-11 23:21:38,228 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:21:38] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:21:38,567 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:21:38] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:21:42,299 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 23:21:42,309 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:21:42] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 23:21:42,620 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:21:42] "PUT /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:21:42,944 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:21:42] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:21:42,947 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:21:42] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:21:44,147 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:21:44] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:21:44,468 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:21:44] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:22:17,730 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:17] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:22:18,063 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:18] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:22:38,995 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:38] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:22:47,460 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:47] "GET /admin/agent-teams HTTP/1.1" 200 -
2025-08-11 23:22:47,726 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:22:47,730 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:47] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:22:47,875 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:47] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:22:47,896 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:47] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-11 23:22:47,898 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:47] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:22:47,910 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:47] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-11 23:22:49,266 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:22:49] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:25:39,380 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:25:39] "POST /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:25:39,654 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:25:39] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:25:39,708 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:25:39] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:25:41,426 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:25:41] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:25:41,743 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:25:41] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:25:59,857 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:25:59] "GET /agent HTTP/1.1" 200 -
2025-08-11 23:26:00,229 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:00] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-11 23:26:00,230 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:00] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-11 23:26:00,454 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:26:00,471 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:00] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:26:00,566 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:00] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:26:00,567 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:00] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:26:10,937 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:10] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:26:10,975 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:26:11,008 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:26:11,043 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:26:17,478 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:17] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:26:18,907 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:18] "GET /api/agent/runs/57 HTTP/1.1" 200 -
2025-08-11 23:26:33,941 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:33] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:26:35,307 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-11 23:26:35,651 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:35,652 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:35,653 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:35,654 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:35,656 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:35,659 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:35,980 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:35,981 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:35] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:36,366 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:26:36,377 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:36] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 23:26:36,380 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:36] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:26:36,384 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:36] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:26:36,629 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:36] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-11 23:26:36,806 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:36] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 23:26:43,916 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:26:43] "GET /api/agent/runs/57 HTTP/1.1" 200 -
2025-08-11 23:27:03,078 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:27:03] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:27:13,126 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:27:13] "GET /api/agent/teams/5 HTTP/1.1" 200 -
2025-08-11 23:27:32,678 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:27:32] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:27:33,901 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:27:33] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:27:46,936 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:27:46] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:27:47,495 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:27:47] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:28:00,457 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:00] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:28:08,318 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:08] "POST /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:28:08,648 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:08] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:28:08,651 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:08] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:28:16,442 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:16] "GET /agent HTTP/1.1" 200 -
2025-08-11 23:28:16,829 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:28:16,838 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:16] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:28:16,843 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:16] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:28:16,845 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:16] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:28:20,338 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:20] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:28:20,386 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:28:20,416 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:28:20,446 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:28:22,896 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:22] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:28:25,412 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:25] "GET /api/agent/runs/58 HTTP/1.1" 200 -
2025-08-11 23:28:32,889 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:32] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:28:34,257 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:28:34] "GET /api/agent/runs/58 HTTP/1.1" 200 -
2025-08-11 23:32:43,577 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:32:43] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:32:43,625 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:32:43,660 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:32:43,693 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:32:44,523 - ERROR - [base_events.py:1771] - Task exception was never retrieved
future: <Task finished name='Task-96' coro=<AsyncClient.aclose() done, defined at /home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py", line 2018, in aclose
    await self._transport.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py", line 385, in aclose
    await self._pool.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 313, in aclose
    await self._close_connections(closing_connections)
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 305, in _close_connections
    await connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py", line 171, in aclose
    await self._connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py", line 265, in aclose
    await self._network_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 55, in aclose
    await self._stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/streams/tls.py", line 216, in aclose
    await self.transport_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 1314, in aclose
    self._transport.close()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/selector_events.py", line 860, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 761, in call_soon
    self._check_closed()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 519, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-08-11 23:32:44,528 - ERROR - [base_events.py:1771] - Task exception was never retrieved
future: <Task finished name='Task-97' coro=<AsyncClient.aclose() done, defined at /home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py", line 2018, in aclose
    await self._transport.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py", line 385, in aclose
    await self._pool.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 313, in aclose
    await self._close_connections(closing_connections)
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 305, in _close_connections
    await connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py", line 171, in aclose
    await self._connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py", line 265, in aclose
    await self._network_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 55, in aclose
    await self._stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/streams/tls.py", line 216, in aclose
    await self.transport_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 1314, in aclose
    self._transport.close()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/selector_events.py", line 860, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 761, in call_soon
    self._check_closed()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 519, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-08-11 23:33:49,630 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:33:49] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:33:49,665 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:33:49,697 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:33:49,726 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:36:16,702 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:16] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:36:16,957 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:16] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:36:41,910 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 23:36:41,916 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:41] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 23:36:42,239 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:42] "PUT /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:36:42,560 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:42] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:36:42,566 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:42] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:36:47,481 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:47] "GET /agent HTTP/1.1" 200 -
2025-08-11 23:36:47,838 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:47] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-11 23:36:48,092 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:36:48,107 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:48] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:36:48,240 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:48] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:36:48,242 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:48] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:36:48,246 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:48] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-11 23:36:48,282 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:48] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-11 23:36:52,347 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:36:52] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:36:52,383 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:36:52,413 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:36:52,446 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:36:52,477 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:37:32,311 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:37:32] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:37:32,351 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:37:32,385 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:37:32,418 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:37:32,451 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:37:33,297 - ERROR - [base_events.py:1771] - Task exception was never retrieved
future: <Task finished name='Task-208' coro=<AsyncClient.aclose() done, defined at /home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py", line 2018, in aclose
    await self._transport.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py", line 385, in aclose
    await self._pool.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 313, in aclose
    await self._close_connections(closing_connections)
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 305, in _close_connections
    await connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py", line 171, in aclose
    await self._connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py", line 265, in aclose
    await self._network_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 55, in aclose
    await self._stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/streams/tls.py", line 216, in aclose
    await self.transport_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 1314, in aclose
    self._transport.close()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/selector_events.py", line 860, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 761, in call_soon
    self._check_closed()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 519, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-08-11 23:37:33,299 - ERROR - [base_events.py:1771] - Task exception was never retrieved
future: <Task finished name='Task-210' coro=<AsyncClient.aclose() done, defined at /home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_client.py", line 2018, in aclose
    await self._transport.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py", line 385, in aclose
    await self._pool.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 313, in aclose
    await self._close_connections(closing_connections)
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 305, in _close_connections
    await connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py", line 171, in aclose
    await self._connection.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py", line 265, in aclose
    await self._network_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 55, in aclose
    await self._stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/streams/tls.py", line 216, in aclose
    await self.transport_stream.aclose()
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 1314, in aclose
    self._transport.close()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/selector_events.py", line 860, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 761, in call_soon
    self._check_closed()
  File "/home/vijay/anaconda3/lib/python3.11/asyncio/base_events.py", line 519, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-08-11 23:37:46,805 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:37:46] "GET /agent HTTP/1.1" 200 -
2025-08-11 23:37:47,048 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:37:47,055 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:37:47] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:37:47,202 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:37:47] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:37:47,203 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:37:47] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:37:50,570 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 23:37:50,570 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 23:37:50,570 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 23:37:50,570 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 23:37:50,571 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:37:50,571 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:37:50,571 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:37:50,571 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:37:50,571 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:37:50,572 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:37:50,572 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:37:50,572 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:37:50,572 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:37:50,572 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:37:50,572 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:37:50,573 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:37:50,573 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:37:50,573 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:37:50,573 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:37:50,573 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:37:50,574 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:37:50,574 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:37:50,574 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:37:50,574 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:37:50,574 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:37:50,574 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:37:50,574 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:37:50,574 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:37:54,652 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:37:54,653 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:37:54,653 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:37:54,653 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:37:54,654 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:37:58,106 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 23:38:00,775 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:00,776 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:00,820 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:00,821 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:38:00,821 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:38:00,821 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:38:00,822 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:38:00,822 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:00,822 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:00,866 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:00,867 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:38:00,867 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:38:00,867 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:38:00,867 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:38:00,867 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:00,868 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:00,914 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:00,914 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:38:00,915 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:38:00,915 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:38:00,915 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:38:00,915 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 23:38:00,915 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:00,915 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:00,960 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:00,961 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 23:38:00,961 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:38:00,961 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:38:00,962 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:38:00,962 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:38:00,962 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:38:00,962 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:38:00,973 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 23:38:01,004 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 23:38:01,008 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 23:38:01,010 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 23:38:01,055 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:01,055 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:01,102 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:01,103 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:38:01,103 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:38:01,103 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:38:01,104 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:38:01,104 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:01,104 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:01,151 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:01,151 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:38:01,151 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:38:01,151 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:38:01,152 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:38:01,152 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:01,152 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:01,199 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:01,199 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:38:01,200 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:38:01,200 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:38:01,200 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:38:01,200 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 23:38:01,200 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:01,200 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:01,245 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:01,246 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 23:38:01,246 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:38:01,246 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:38:01,246 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:38:01,247 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:38:01,247 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:38:01,247 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:38:01,267 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 23:38:01,270 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 23:38:01,271 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 23:38:01,271 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 23:38:01,275 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 23:38:01,275 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 23:38:04,992 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 23:38:05,015 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:38:05] "GET /agent HTTP/1.1" 200 -
2025-08-11 23:38:05,237 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:38:05,245 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:38:05] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:38:05,388 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:38:05] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:38:05,390 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:38:05] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:38:22,751 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 23:38:22,751 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:38:22,751 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:38:22,791 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:38:22,791 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 23:38:22,792 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:38:22] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:38:22,825 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:38:22,859 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:38:22,894 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:38:22,925 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:38:41,966 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:38:41] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:38:42,222 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-11 23:38:42,222 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-11 23:38:42,222 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-11 23:38:42,225 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-11 23:38:42,225 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-11 23:38:42,226 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-11 23:38:42,226 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-11 23:38:43,062 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-11 23:38:43,068 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-11 23:38:43,070 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:38:43] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:42:48,346 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:42:48] "GET /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:42:48,600 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:42:48] "GET /api/agent/mcp/servers-with-tools HTTP/1.1" 200 -
2025-08-11 23:42:58,804 - ERROR - [app.py:875] - Exception on /api/agent/teams [POST]
Traceback (most recent call last):
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/anaconda3/lib/python3.11/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/utils/auth_utils.py", line 18, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/vijay/gitrepo/copilot/text2sql/src/routes/autogen_routes.py", line 26, in teams
    team.save()
  File "/home/vijay/gitrepo/copilot/text2sql/src/models/agent_team.py", line 122, in save
    cur.execute(
sqlite3.IntegrityError: UNIQUE constraint failed: agent_teams.name
2025-08-11 23:42:58,812 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:42:58] "[35m[1mPOST /api/agent/teams HTTP/1.1[0m" 500 -
2025-08-11 23:42:59,124 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:42:59] "PUT /api/agent/teams/6 HTTP/1.1" 200 -
2025-08-11 23:42:59,469 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:42:59] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:42:59,472 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:42:59] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:43:04,288 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:43:04] "GET /agent HTTP/1.1" 200 -
2025-08-11 23:43:04,706 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:43:04,713 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:43:04] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:43:04,714 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:43:04] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:43:04,716 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:43:04] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:43:08,078 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:43:08] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:43:08,172 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:43:08,218 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:43:08,249 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:43:08,281 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:43:43,105 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:43:43] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:43:45,666 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:43:45] "GET /api/agent/runs/64 HTTP/1.1" 200 -
2025-08-11 23:49:00,512 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-11 23:49:00,514 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Event loop is closed
2025-08-11 23:49:00,514 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-11 23:49:00,514 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-11 23:49:00,515 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:49:00,515 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:49:00,516 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:49:00,516 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:49:00,516 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:49:00,517 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:49:00,517 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:49:00,517 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:49:00,518 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:49:00,518 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:49:00,518 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:49:00,519 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:49:00,519 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:49:00,520 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:49:00,520 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:49:00,520 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:49:00,521 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:49:00,521 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:49:00,521 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:49:00,521 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:49:00,522 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:49:00,522 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:49:00,522 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:49:00,523 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:49:05,090 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:05,090 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:05,091 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:05,091 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:05,093 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:49:10,611 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-11 23:49:14,267 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:14,267 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:14,317 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:14,317 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:14,318 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:14,318 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:14,318 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:14,318 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:14,319 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:14,367 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:14,367 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:14,368 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:14,368 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:14,368 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:14,368 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:14,368 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:14,415 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:14,415 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:14,415 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:14,415 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:14,416 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:14,416 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 23:49:14,416 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:14,416 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:14,461 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:14,461 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 23:49:14,461 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:49:14,462 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:14,462 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:14,462 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:14,462 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:14,463 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:49:14,473 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-11 23:49:14,503 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-11 23:49:14,507 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-11 23:49:14,508 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-11 23:49:14,554 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:14,554 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:14,597 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:14,598 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:14,598 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:14,598 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:14,598 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:14,599 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:14,599 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:14,638 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:14,639 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:14,639 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:14,639 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:14,639 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:14,640 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:14,640 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:14,683 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:14,684 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:14,684 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:14,684 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:14,684 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:14,684 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-11 23:49:14,684 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:14,685 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:14,723 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:14,723 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-11 23:49:14,723 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:49:14,724 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-11 23:49:14,724 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-11 23:49:14,724 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-11 23:49:14,724 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-11 23:49:14,724 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-11 23:49:14,742 - INFO - [app.py:736] - Initializing application-wide components
2025-08-11 23:49:14,745 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-11 23:49:14,746 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-11 23:49:14,746 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-11 23:49:14,748 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-11 23:49:14,748 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-11 23:49:24,689 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-11 23:49:24,720 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:49:24] "GET /agent HTTP/1.1" 200 -
2025-08-11 23:49:24,938 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-11 23:49:24,947 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:49:24] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-11 23:49:25,141 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:49:25] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-11 23:49:25,142 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:49:25] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-11 23:49:28,476 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-11 23:49:28,476 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-11 23:49:28,476 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-11 23:49:28,514 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-11 23:49:28,514 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-11 23:49:28,515 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:49:28] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-11 23:49:28,551 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:49:28,584 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:49:28,618 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:49:28,651 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-11 23:49:36,220 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:49:36] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-11 23:49:38,221 - INFO - [_internal.py:97] - 127.0.0.1 - - [11/Aug/2025 23:49:38] "GET /api/agent/runs/65 HTTP/1.1" 200 -
2025-08-11 23:50:01,585 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:50:01,585 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:50:01,586 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:50:01,587 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:50:01,587 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:50:01,588 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:50:01,588 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:50:01,589 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:50:01,590 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:50:01,590 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:50:01,591 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:50:01,591 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-11 23:50:01,593 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-11 23:50:01,593 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-11 23:50:01,593 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:50:01,594 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-11 23:50:01,594 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:50:01,595 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-11 23:50:01,595 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:50:01,595 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-11 23:50:01,596 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-11 23:50:01,596 - INFO - [database.py:328] - Closing database connection
2025-08-11 23:50:01,596 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-11 23:50:01,597 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 05:52:30,175 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:52:30,175 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:52:30,175 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:52:30,176 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:52:30,177 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:52:35,664 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-12 05:52:38,980 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:52:38,980 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:52:39,015 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:52:39,015 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:52:39,016 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:52:39,016 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:52:39,016 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:52:39,016 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:52:39,016 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:52:39,054 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:52:39,054 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:52:39,054 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:52:39,055 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:52:39,055 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:52:39,055 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:52:39,055 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:52:39,098 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:52:39,098 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:52:39,098 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:52:39,098 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:52:39,099 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:52:39,099 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 05:52:39,099 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:52:39,099 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:52:39,147 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:52:39,147 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 05:52:39,147 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:52:39,148 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:52:39,148 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:52:39,148 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:52:39,148 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:52:39,148 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:52:39,158 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-12 05:52:39,185 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-12 05:52:39,188 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-12 05:52:39,188 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-12 05:52:39,230 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:52:39,230 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:26,312 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:26,312 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:26,313 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:26,313 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:26,314 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:53:30,141 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-12 05:53:33,133 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:53:33,133 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:33,171 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:53:33,171 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:33,171 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:33,171 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:33,171 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:33,172 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:53:33,172 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:33,208 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:53:33,209 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:33,209 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:33,209 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:33,209 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:33,209 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:53:33,209 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:33,244 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:53:33,245 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:33,245 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:33,245 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:33,245 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:33,245 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 05:53:33,245 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:53:33,246 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:33,280 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:53:33,280 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 05:53:33,280 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:53:33,280 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:33,280 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:33,280 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:33,281 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:33,281 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:53:33,288 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-12 05:53:33,307 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-12 05:53:33,310 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-12 05:53:33,311 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-12 05:53:33,349 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:53:33,350 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:33,391 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:53:33,391 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:33,392 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:33,392 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:33,392 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:33,392 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:53:33,392 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:33,427 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:53:33,427 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:33,428 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:33,428 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:33,428 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:33,428 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:53:33,428 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:33,464 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:53:33,464 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:33,464 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:33,464 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:33,465 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:33,465 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 05:53:33,465 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:53:33,465 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:53:33,499 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:53:33,500 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 05:53:33,500 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:53:33,500 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:53:33,500 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:53:33,500 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:53:33,500 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:53:33,501 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:53:33,515 - INFO - [app.py:736] - Initializing application-wide components
2025-08-12 05:53:33,518 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-12 05:53:33,519 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-12 05:53:33,519 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-12 05:53:33,521 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-12 05:53:33,521 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-12 05:53:37,858 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:37] "[32mGET /agent HTTP/1.1[0m" 302 -
2025-08-12 05:53:38,153 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:38] "GET /login HTTP/1.1" 200 -
2025-08-12 05:53:38,279 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:38] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:38,614 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:38] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:38,620 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:38] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:38,626 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:38] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:38,637 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:38] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:38,641 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:38] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:43,850 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-12 05:53:44,225 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:44] "[32mPOST /login HTTP/1.1[0m" 302 -
2025-08-12 05:53:44,569 - DEBUG - [app.py:172] - Main page requested
2025-08-12 05:53:44,632 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:44] "GET / HTTP/1.1" 200 -
2025-08-12 05:53:44,804 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:44] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,002 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,018 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,020 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,029 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,033 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,111 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,324 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,351 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,363 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,378 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,402 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,419 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,647 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,704 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,720 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,749 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,756 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,760 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:45,972 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:45] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:46,052 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:46] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:46,058 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:46] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:46,081 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:46] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:46,092 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:46] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:46,094 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:46] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:46,449 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-12 05:53:46,463 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:46] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:46,507 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:46] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-12 05:53:46,733 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:46] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-12 05:53:47,051 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:47] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:47,316 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:47] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-12 05:53:47,688 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:47] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-12 05:53:50,171 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:50] "GET /agent HTTP/1.1" 200 -
2025-08-12 05:53:50,553 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:50] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-12 05:53:50,570 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:50] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-12 05:53:50,794 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 05:53:50,806 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:50] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 05:53:50,921 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:50] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 05:53:50,936 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:50] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 05:53:56,223 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:53:56] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-12 05:54:06,442 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-12 05:54:06,443 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:54:06,444 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:54:06,501 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:54:06,502 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-12 05:54:06,502 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:06,502 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:54:06,502 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:06,510 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:54:06,510 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:54:06,511 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:54:06,511 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:54:07,468 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:54:07,477 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:54:07,478 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:54:07] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-12 05:54:07,479 - INFO - [agent_routes.py:112] - Processing query with 1 previous messages for context
2025-08-12 05:54:07,479 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-12 05:54:07,479 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:54:07,661 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:54:07,661 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:54:07,661 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:54:07,662 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:07,662 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:54:07,662 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:07,664 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:54:07,664 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:54:07,664 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:54:07,664 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:54:08,628 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:54:08,636 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:54:08,636 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-12 05:54:08,636 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: get me list of tools you have
2025-08-12 05:54:08,637 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-12 05:54:08,637 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. How can I help you today?"}, {'role': 'user', 'content': 'get me list of tools you have'}]
2025-08-12 05:54:08,637 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (1 previous messages)
2025-08-12 05:54:08,638 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-12 05:54:08,638 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:54:08,638 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:54:08,638 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:54:08,638 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:54:11,012 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 2.37s
2025-08-12 05:54:11,012 - INFO - [llm_engine.py:380] - [MCP-dataengineer] Raw model response: 'I have access to the following tools:

*   `get_mapping_details(mapping_reference_name: str)`: Reads mapping.xlsx, filters by mapping_reference_name, and returns formatted details.
*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.
*   `run_bash_shell(command: str)`: Execute a shell command and return combined stdout and stderr.
*   `get_table_data(table_name: str, limit: int | None = None)`: Fetches a specified number of rows ...' (truncated)
2025-08-12 05:54:11,013 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 2.37s
2025-08-12 05:54:11,013 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:54:11,013 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='I have access to the following tools:

*   `get_mapping_details(mapping_reference_name: str)`: Reads mapping.xlsx, filters by mapping_reference_name, and returns formatted details.
*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.
*   `run_bash_shell(command: str)`: Execute a shell command and return combined stdout and stderr.
*   `get_table_data(table_name: str, limit: int | None = None)`: Fetches a specified number of rows from a given table.
*   `get_table_row_count(table_name: str)`: Returns the total number of rows in the specified table.
*   `list_mappings()`: Reads mapping.xlsx and returns a list of unique 'Mapping Name' values.
*   `execute_sql_query(query: str)`: Executes a read-only SQL query against the database and returns results.
*   `read_file(file_path: str)`: Read contents of a file within the workspace.
*   `write_file(content: str, file_path: str)`: Write content to a file within the workspace.
*   `validate_mapping_logic(mapping_reference_name: str)`: Validates the logical consistency of a mapping document.
*   `execute_sql_script(script_path: str, unsafe: bool | None = None)`: Execute a SQL script file against the SQLite database.', has_tool_calls=False
2025-08-12 05:54:11,014 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': "I have access to the following tools:\n\n*   `get_mapping_details(mapping_reference_name: str)`: Reads mapping.xlsx, filters by mapping_reference_name, and returns formatted details.\n*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.\n*   `run_bash_shell(command: str)`: Execute a shell command and return combined stdout and stderr.\n*   `get_table_data(table_name: str, limit: int | None = None)`: Fetches a specified number of rows from a given table.\n*   `get_table_row_count(table_name: str)`: Returns the total number of rows in the specified table.\n*   `list_mappings()`: Reads mapping.xlsx and returns a list of unique 'Mapping Name' values.\n*   `execute_sql_query(query: str)`: Executes a read-only SQL query against the database and returns results.\n*   `read_file(file_path: str)`: Read contents of a file within the workspace.\n*   `write_file(content: str, file_path: str)`: Write content to a file within the workspace.\n*   `validate_mapping_logic(mapping_reference_name: str)`: Validates the logical consistency of a mapping document.\n*   `execute_sql_script(script_path: str, unsafe: bool | None = None)`: Execute a SQL script file against the SQLite database."}
2025-08-12 05:54:11,014 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-12 05:54:11,015 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-12 05:54:11,015 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:54:11,207 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:54:11,207 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:54:11,207 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:54:11,207 - INFO - [agent_routes.py:249] - Agent audit - Collected 7 response parts
2025-08-12 05:54:11,208 - DEBUG - [agent_routes.py:250] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | LLM_RESPONSE: I have access to the following tools:

*   `get_mapping_details(mapping_reference_name: str)`: Reads mapping.xlsx, filters by mapping_reference_name, and returns formatted details.
*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.
*   `run_bash_shell(command: str)`: Execute a...
2025-08-12 05:54:28,364 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:28,365 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:54:28,365 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:28,368 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:54:28,368 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:54:28,369 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:54:28,369 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:54:29,303 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:54:29,311 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:54:29,312 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:54:29] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-12 05:54:29,313 - INFO - [agent_routes.py:112] - Processing query with 3 previous messages for context
2025-08-12 05:54:29,313 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-12 05:54:29,313 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:54:29,497 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:54:29,497 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:54:29,497 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:54:29,497 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:29,498 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:54:29,498 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:29,499 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:54:29,499 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:54:29,500 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:54:29,500 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:54:30,404 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:54:30,413 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:54:30,413 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-12 05:54:30,413 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: get me list of files in current directory
2025-08-12 05:54:30,414 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-12 05:54:30,414 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. How can I help you today?"}, {'role': 'user', 'content': 'get me list of tools you have'}, {'role': 'assistant', 'content': "I have access to the following tools:\n\n*   `get_mapping_details(mapping_reference_name: str)`: Reads mapping.xlsx, filters by mapping_reference_name, and returns formatted details.\n*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.\n*   `run_bash_shell(command: str)`: Execute a shell command and return combined stdout and stderr.\n*   `get_table_data(table_name: str, limit: int | None = None)`: Fetches a specified number of rows from a given table.\n*   `get_table_row_count(table_name: str)`: Returns the total number of rows in the specified table.\n*   `list_mappings()`: Reads mapping.xlsx and returns a list of unique 'Mapping Name' values.\n*   `execute_sql_query(query: str)`: Executes a read-only SQL query against the database and returns results.\n*   `read_file(file_path: str)`: Read contents of a file within the workspace.\n*   `write_file(content: str, file_path: str)`: Write content to a file within the workspace.\n*   `validate_mapping_logic(mapping_reference_name: str)`: Validates the logical consistency of a mapping document.\n*   `execute_sql_script(script_path: str, unsafe: bool | None = None)`: Execute a SQL script file against the SQLite database."}, {'role': 'user', 'content': 'get me list of files in current directory'}]
2025-08-12 05:54:30,414 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (3 previous messages)
2025-08-12 05:54:30,414 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-12 05:54:30,415 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:54:30,415 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:54:30,415 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:54:30,415 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:54:32,451 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 2.04s
2025-08-12 05:54:32,452 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-12 05:54:32,452 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 2.04s
2025-08-12 05:54:32,452 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:54:32,453 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='None', has_tool_calls=True
2025-08-12 05:54:32,453 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 1/5)
2025-08-12 05:54:32,453 - INFO - [mcp_client_manager.py:519] - Calling tool 'run_bash_shell' with args: {'command': 'ls -F'}
2025-08-12 05:54:32,454 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling run_bash_shell via MCP session
2025-08-12 05:54:32,474 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: meta=None content=[TextContent(type='text', text='=0.3.0\nAIRGAP_DEPLOYMENT_INFO.md\nAIRGAP_README.md\nMCP_SKILL_LIBRARY_SUMMARY.md\nMESSAGE_FORMAT_GUIDE.md\nREADME.md\n__init__.py\napp.py\nchroma_data/\nchromadb_service/\nconfig/\ndata_mapping_metadata/\ndatabase.db\ndownload_vendor_assets.sh*\ninit_data_mapping_workflow.py\ninit_skill_library.py*\ninit_skill_library_db.py*\ninitialize_skills.py*\nlogs/\nrequirements.txt\nrestart.sh*\nsample_skills.json\nsetup_airgap.sh*\nsrc/\nstart_all_services.sh\nstart_mcp_data_mapping_server.sh*\nstart_mcp_skill_server.sh*\nstatic/\nstreamlit_app.py\ntasks.md\ntemplates/\ntemplates_backup_20250811_101418/\ntest.ipynb\ntest1.sh\ntest_llama_function_calling.py\ntest_message_formats.py\ntest_timestamp_fix.py\ntest_workflow_fix.py\ntext2sql.db\ntext2sql.db-shm\ntext2sql.db-wal\nupdate_templates.sh*\nupdate_vector_service.sh*\nuploads/\nvector_store.db\nverify_airgap.sh*\nweather.py', annotations=None, meta=None)] structuredContent={'result': '=0.3.0\nAIRGAP_DEPLOYMENT_INFO.md\nAIRGAP_README.md\nMCP_SKILL_LIBRARY_SUMMARY.md\nMESSAGE_FORMAT_GUIDE.md\nREADME.md\n__init__.py\napp.py\nchroma_data/\nchromadb_service/\nconfig/\ndata_mapping_metadata/\ndatabase.db\ndownload_vendor_assets.sh*\ninit_data_mapping_workflow.py\ninit_skill_library.py*\ninit_skill_library_db.py*\ninitialize_skills.py*\nlogs/\nrequirements.txt\nrestart.sh*\nsample_skills.json\nsetup_airgap.sh*\nsrc/\nstart_all_services.sh\nstart_mcp_data_mapping_server.sh*\nstart_mcp_skill_server.sh*\nstatic/\nstreamlit_app.py\ntasks.md\ntemplates/\ntemplates_backup_20250811_101418/\ntest.ipynb\ntest1.sh\ntest_llama_function_calling.py\ntest_message_formats.py\ntest_timestamp_fix.py\ntest_workflow_fix.py\ntext2sql.db\ntext2sql.db-shm\ntext2sql.db-wal\nupdate_templates.sh*\nupdate_vector_service.sh*\nuploads/\nvector_store.db\nverify_airgap.sh*\nweather.py'} isError=False completed successfully
2025-08-12 05:54:32,475 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-12 05:54:32,475 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:54:32,476 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:54:32,476 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:54:32,476 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:54:35,294 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 2.82s
2025-08-12 05:54:35,295 - INFO - [llm_engine.py:380] - [MCP-dataengineer] Raw model response: 'Here is a list of files and directories in the current directory:

Files:
*   `=0.3.0`
*   `AIRGAP_DEPLOYMENT_INFO.md`
*   `AIRGAP_README.md`
*   `MCP_SKILL_LIBRARY_SUMMARY.md`
*   `MESSAGE_FORMAT_GUIDE.md`
*   `README.md`
*   `__init__.py`
*   `app.py`
*   `database.db`
*   `download_vendor_assets.sh*`
*   `init_data_mapping_workflow.py`
*   `init_skill_library.py*`
*   `init_skill_library_db.py*`
*   `initialize_skills.py*`
*   `requirements.txt`
*   `restart.sh*`
*   `sample_skills.json`
*   ...' (truncated)
2025-08-12 05:54:35,296 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 2.82s
2025-08-12 05:54:35,297 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:54:35,297 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='Here is a list of files and directories in the current directory:

Files:
*   `=0.3.0`
*   `AIRGAP_DEPLOYMENT_INFO.md`
*   `AIRGAP_README.md`
*   `MCP_SKILL_LIBRARY_SUMMARY.md`
*   `MESSAGE_FORMAT_GUIDE.md`
*   `README.md`
*   `__init__.py`
*   `app.py`
*   `database.db`
*   `download_vendor_assets.sh*`
*   `init_data_mapping_workflow.py`
*   `init_skill_library.py*`
*   `init_skill_library_db.py*`
*   `initialize_skills.py*`
*   `requirements.txt`
*   `restart.sh*`
*   `sample_skills.json`
*   `setup_airgap.sh*`
*   `start_all_services.sh`
*   `start_mcp_data_mapping_server.sh*`
*   `start_mcp_skill_server.sh*`
*   `streamlit_app.py`
*   `tasks.md`
*   `test.ipynb`
*   `test1.sh`
*   `test_llama_function_calling.py`
*   `test_message_formats.py`
*   `test_timestamp_fix.py`
*   `test_workflow_fix.py`
*   `text2sql.db`
*   `text2sql.db-shm`
*   `text2sql.db-wal`
*   `update_templates.sh*`
*   `update_vector_service.sh*`
*   `verify_airgap.sh*`
*   `weather.py`

Directories:
*   `chroma_data/`
*   `chromadb_service/`
*   `config/`
*   `data_mapping_metadata/`
*   `logs/`
*   `src/`
*   `static/`
*   `templates/`
*   `templates_backup_20250811_101418/`
*   `uploads/`
*   `vector_store.db`', has_tool_calls=False
2025-08-12 05:54:35,298 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': 'Here is a list of files and directories in the current directory:\n\nFiles:\n*   `=0.3.0`\n*   `AIRGAP_DEPLOYMENT_INFO.md`\n*   `AIRGAP_README.md`\n*   `MCP_SKILL_LIBRARY_SUMMARY.md`\n*   `MESSAGE_FORMAT_GUIDE.md`\n*   `README.md`\n*   `__init__.py`\n*   `app.py`\n*   `database.db`\n*   `download_vendor_assets.sh*`\n*   `init_data_mapping_workflow.py`\n*   `init_skill_library.py*`\n*   `init_skill_library_db.py*`\n*   `initialize_skills.py*`\n*   `requirements.txt`\n*   `restart.sh*`\n*   `sample_skills.json`\n*   `setup_airgap.sh*`\n*   `start_all_services.sh`\n*   `start_mcp_data_mapping_server.sh*`\n*   `start_mcp_skill_server.sh*`\n*   `streamlit_app.py`\n*   `tasks.md`\n*   `test.ipynb`\n*   `test1.sh`\n*   `test_llama_function_calling.py`\n*   `test_message_formats.py`\n*   `test_timestamp_fix.py`\n*   `test_workflow_fix.py`\n*   `text2sql.db`\n*   `text2sql.db-shm`\n*   `text2sql.db-wal`\n*   `update_templates.sh*`\n*   `update_vector_service.sh*`\n*   `verify_airgap.sh*`\n*   `weather.py`\n\nDirectories:\n*   `chroma_data/`\n*   `chromadb_service/`\n*   `config/`\n*   `data_mapping_metadata/`\n*   `logs/`\n*   `src/`\n*   `static/`\n*   `templates/`\n*   `templates_backup_20250811_101418/`\n*   `uploads/`\n*   `vector_store.db`'}
2025-08-12 05:54:35,301 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-12 05:54:35,303 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-12 05:54:35,304 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:54:35,512 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:54:35,513 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:54:35,513 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:54:35,513 - INFO - [agent_routes.py:249] - Agent audit - Collected 8 response parts
2025-08-12 05:54:35,513 - DEBUG - [agent_routes.py:250] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | STATUS: Processing tool results... | LLM_RESPONSE: Here is a list of files and directories in the current directory:

Files:
*   `=0.3.0`
*   `AIRGAP_DEPLOYMENT_INFO.md`
*   `AIRGAP_README.md`
*   `MCP_SKILL_LIBRARY_SUMMARY.md`
*   `MESSAGE_FORMAT_GUIDE.md`
*   `README.md`
*   `__init__.py`
*   `app.py`
*   `database.db`
*   `download_vendor_assets.sh*`
*   ...
2025-08-12 05:54:51,038 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:51,039 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:54:51,039 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:51,043 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:54:51,044 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:54:51,044 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:54:51,044 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:54:52,015 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:54:52,023 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:54:52,025 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:54:52] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-12 05:54:52,026 - INFO - [agent_routes.py:112] - Processing query with 4 previous messages for context
2025-08-12 05:54:52,026 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-12 05:54:52,026 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:54:52,204 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:54:52,204 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:54:52,204 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:54:52,204 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:52,204 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:54:52,205 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:54:52,206 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:54:52,206 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:54:52,206 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:54:52,207 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:54:53,143 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:54:53,152 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:54:53,152 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-12 05:54:53,152 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: which is the largest
2025-08-12 05:54:53,152 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-12 05:54:53,153 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. How can I help you today?"}, {'role': 'user', 'content': 'get me list of tools you have'}, {'role': 'user', 'content': 'get me list of files in current directory'}, {'role': 'assistant', 'content': 'Here is a list of files and directories in the current directory:\n\nFiles:\n*   `=0.3.0`\n*   `AIRGAP_DEPLOYMENT_INFO.md`\n*   `AIRGAP_README.md`\n*   `MCP_SKILL_LIBRARY_SUMMARY.md`\n*   `MESSAGE_FORMAT_GUIDE.md`\n*   `README.md`\n*   `__init__.py`\n*   `app.py`\n*   `database.db`\n*   `download_vendor_assets.sh*`\n*   `init_data_mapping_workflow.py`\n*   `init_skill_library.py*`\n*   `init_skill_library_db.py*`\n*   `initialize_skills.py*`\n*   `requirements.txt`\n*   `restart.sh*`\n*   `sample_skills.json`\n*   `setup_airgap.sh*`\n*   `start_all_services.sh`\n*   `start_mcp_data_mapping_server.sh*`\n*   `start_mcp_skill_server.sh*`\n*   `streamlit_app.py`\n*   `tasks.md`\n*   `test.ipynb`\n*   `test1.sh`\n*   `test_llama_function_calling.py`\n*   `test_message_formats.py`\n*   `test_timestamp_fix.py`\n*   `test_workflow_fix.py`\n*   `text2sql.db`\n*   `text2sql.db-shm`\n*   `text2sql.db-wal`\n*   `update_templates.sh*`\n*   `update_vector_service.sh*`\n*   `verify_airgap.sh*`\n*   `weather.py`\n\nDirectories:\n*   `chroma_data/`\n*   `chromadb_service/`\n*   `config/`\n*   `data_mapping_metadata/`\n*   `logs/`\n*   `src/`\n*   `static/`\n*   `templates/`\n*   `templates_backup_20250811_101418/`\n*   `uploads/`\n*   `vector_store.db`'}, {'role': 'user', 'content': 'which is the largest'}]
2025-08-12 05:54:53,153 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (4 previous messages)
2025-08-12 05:54:53,153 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-12 05:54:53,154 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:54:53,154 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:54:53,155 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:54:53,155 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:54:55,353 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 2.20s
2025-08-12 05:54:55,355 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-12 05:54:55,356 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 2.20s
2025-08-12 05:54:55,356 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:54:55,357 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='None', has_tool_calls=True
2025-08-12 05:54:55,358 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 1/5)
2025-08-12 05:54:55,359 - INFO - [mcp_client_manager.py:519] - Calling tool 'run_bash_shell' with args: {'command': 'du -h "=0.3.0" AIRGAP_DEPLOYMENT_INFO.md AIRGAP_README.md MCP_SKILL_LIBRARY_SUMMARY.md MESSAGE_FORMAT_GUIDE.md README.md __init__.py app.py database.db download_vendor_assets.sh* init_data_mapping_workflow.py init_skill_library.py* init_skill_library_db.py* initialize_skills.py* requirements.txt restart.sh* sample_skills.json setup_airgap.sh* start_all_services.sh start_mcp_data_mapping_server.sh* start_mcp_skill_server.sh* streamlit_app.py tasks.md test.ipynb test1.sh test_llama_function_calling.py test_message_formats.py test_timestamp_fix.py test_workflow_fix.py text2sql.db text2sql.db-shm text2sql.db-wal update_templates.sh* update_vector_service.sh* verify_airgap.sh* weather.py'}
2025-08-12 05:54:55,360 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling run_bash_shell via MCP session
2025-08-12 05:54:55,407 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: meta=None content=[TextContent(type='text', text='4.0K\t=0.3.0\n4.0K\tAIRGAP_DEPLOYMENT_INFO.md\n4.0K\tAIRGAP_README.md\n8.0K\tMCP_SKILL_LIBRARY_SUMMARY.md\n8.0K\tMESSAGE_FORMAT_GUIDE.md\n36K\tREADME.md\n4.0K\t__init__.py\n32K\tapp.py\n0\tdatabase.db\n8.0K\tdownload_vendor_assets.sh\n0\tinit_data_mapping_workflow.py\n8.0K\tinit_skill_library.py\n8.0K\tinit_skill_library_db.py\n8.0K\tinitialize_skills.py\n4.0K\trequirements.txt\n4.0K\trestart.sh\n16K\tsample_skills.json\n8.0K\tsetup_airgap.sh\n4.0K\tstart_all_services.sh\n4.0K\tstart_mcp_data_mapping_server.sh\n4.0K\tstart_mcp_skill_server.sh\n20K\tstreamlit_app.py\n4.0K\ttasks.md\n140K\ttest.ipynb\n4.0K\ttest1.sh\n8.0K\ttest_llama_function_calling.py\n8.0K\ttest_message_formats.py\n0\ttest_timestamp_fix.py\n0\ttest_workflow_fix.py\n1.2M\ttext2sql.db\n32K\ttext2sql.db-shm\n3.7M\ttext2sql.db-wal\n12K\tupdate_templates.sh\n0\tupdate_vector_service.sh\n4.0K\tverify_airgap.sh\n8.0K\tweather.py', annotations=None, meta=None)] structuredContent={'result': '4.0K\t=0.3.0\n4.0K\tAIRGAP_DEPLOYMENT_INFO.md\n4.0K\tAIRGAP_README.md\n8.0K\tMCP_SKILL_LIBRARY_SUMMARY.md\n8.0K\tMESSAGE_FORMAT_GUIDE.md\n36K\tREADME.md\n4.0K\t__init__.py\n32K\tapp.py\n0\tdatabase.db\n8.0K\tdownload_vendor_assets.sh\n0\tinit_data_mapping_workflow.py\n8.0K\tinit_skill_library.py\n8.0K\tinit_skill_library_db.py\n8.0K\tinitialize_skills.py\n4.0K\trequirements.txt\n4.0K\trestart.sh\n16K\tsample_skills.json\n8.0K\tsetup_airgap.sh\n4.0K\tstart_all_services.sh\n4.0K\tstart_mcp_data_mapping_server.sh\n4.0K\tstart_mcp_skill_server.sh\n20K\tstreamlit_app.py\n4.0K\ttasks.md\n140K\ttest.ipynb\n4.0K\ttest1.sh\n8.0K\ttest_llama_function_calling.py\n8.0K\ttest_message_formats.py\n0\ttest_timestamp_fix.py\n0\ttest_workflow_fix.py\n1.2M\ttext2sql.db\n32K\ttext2sql.db-shm\n3.7M\ttext2sql.db-wal\n12K\tupdate_templates.sh\n0\tupdate_vector_service.sh\n4.0K\tverify_airgap.sh\n8.0K\tweather.py'} isError=False completed successfully
2025-08-12 05:54:55,408 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-12 05:54:55,409 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:54:55,409 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:54:55,410 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:54:55,410 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:54:58,952 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 3.54s
2025-08-12 05:54:58,952 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'The largest file in the current directory is `text2sql.db-wal` with a size of 3.7M.'
2025-08-12 05:54:58,953 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 3.54s
2025-08-12 05:54:58,954 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:54:58,955 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='The largest file in the current directory is `text2sql.db-wal` with a size of 3.7M.', has_tool_calls=False
2025-08-12 05:54:58,956 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': 'The largest file in the current directory is `text2sql.db-wal` with a size of 3.7M.'}
2025-08-12 05:54:58,957 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-12 05:54:58,960 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-12 05:54:58,961 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:54:59,159 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:54:59,159 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:54:59,159 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:54:59,160 - INFO - [agent_routes.py:249] - Agent audit - Collected 7 response parts
2025-08-12 05:54:59,160 - DEBUG - [agent_routes.py:250] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | STATUS: Processing tool results... | LLM_RESPONSE: The largest file in the current directory is `text2sql.db-wal` with a size of 3.7M. | STATUS: Processing complete. | STATUS: Agent processing completed....
2025-08-12 05:55:12,009 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:55:12] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 05:55:12,321 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:55:12] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 05:56:06,659 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:06] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-12 05:56:08,163 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:08] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 05:56:08,473 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:08] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 05:56:34,134 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:34] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-12 05:56:34,212 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-12 05:56:34,254 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-12 05:56:34,297 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-12 05:56:34,336 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-12 05:56:55,119 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-12 05:56:55,480 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,495 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,501 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,509 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,518 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,526 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,795 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,823 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,840 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,843 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,849 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:55,853 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:55] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,102 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,133 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,144 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,158 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,162 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,166 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,421 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,438 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,477 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,483 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,486 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:56,494 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:56] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:57,478 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:57] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:57,490 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:57] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:57,519 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:57] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:57,526 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:57] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:57,530 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:57] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:57,534 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:57] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:57,803 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:57] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:57,814 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:57] "GET /static/js/admin/agent-runs.js HTTP/1.1" 200 -
2025-08-12 05:56:57,960 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 05:56:58,004 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:58] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 05:56:58,184 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:58] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:58,198 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:58] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-12 05:56:58,319 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:58] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-12 05:56:58,639 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:58] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-12 05:56:59,700 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:56:59] "GET /api/agent/runs/66 HTTP/1.1" 200 -
2025-08-12 05:58:28,927 - DEBUG - [mcp_client_manager.py:606] - Cleanup for dataengineer skipped - already cleaned up
2025-08-12 05:58:28,928 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 05:58:28,928 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 05:58:28,928 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 05:58:28,929 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 05:58:28,929 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 05:58:28,929 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 05:58:28,929 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 05:58:28,929 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 05:58:28,930 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 05:58:28,930 - INFO - [database.py:328] - Closing database connection
2025-08-12 05:58:28,930 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 05:58:28,930 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 05:58:28,931 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 05:58:28,931 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 05:58:28,931 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 05:58:28,931 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 05:58:28,931 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 05:58:28,932 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 05:58:28,932 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 05:58:28,932 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 05:58:28,932 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 05:58:28,932 - INFO - [database.py:328] - Closing database connection
2025-08-12 05:58:28,932 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 05:58:28,932 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 05:58:33,042 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:33,042 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:33,043 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:33,043 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:33,044 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:58:37,577 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-12 05:58:40,550 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:40,551 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:40,585 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:40,585 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:40,585 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:40,586 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:40,586 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:40,586 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:40,586 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:40,620 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:40,620 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:40,621 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:40,621 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:40,621 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:40,621 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:40,621 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:40,655 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:40,655 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:40,655 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:40,656 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:40,656 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:40,656 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 05:58:40,656 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:40,656 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:40,691 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:40,691 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 05:58:40,691 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:58:40,691 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:40,692 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:40,692 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:40,692 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:40,692 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:58:40,700 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-12 05:58:40,721 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-12 05:58:40,725 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-12 05:58:40,726 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-12 05:58:40,765 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:40,765 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:40,799 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:40,799 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:40,800 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:40,800 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:40,800 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:40,800 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:40,801 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:40,834 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:40,835 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:40,835 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:40,835 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:40,835 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:40,835 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:40,835 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:40,870 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:40,871 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:40,871 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:40,871 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:40,871 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:40,871 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 05:58:40,871 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:40,871 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:40,906 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:40,906 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 05:58:40,906 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:58:40,906 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 05:58:40,906 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 05:58:40,907 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 05:58:40,907 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 05:58:40,907 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 05:58:40,923 - INFO - [app.py:736] - Initializing application-wide components
2025-08-12 05:58:40,925 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-12 05:58:40,926 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-12 05:58:40,926 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-12 05:58:40,927 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-12 05:58:40,927 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-12 05:58:45,514 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-12 05:58:45,549 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:45] "GET /agent HTTP/1.1" 200 -
2025-08-12 05:58:45,742 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:45] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-12 05:58:45,914 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:45] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-12 05:58:45,949 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:45] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-12 05:58:45,950 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:45] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 05:58:45,951 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:45] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 05:58:45,959 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:45] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-12 05:58:46,053 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-12 05:58:46,294 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-12 05:58:46,323 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,324 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,334 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-12 05:58:46,339 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,366 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,642 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-12 05:58:46,656 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,671 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,674 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,678 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,692 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-12 05:58:46,969 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-12 05:58:46,983 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:46] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-12 05:58:47,010 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-12 05:58:47,038 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-12 05:58:47,043 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-12 05:58:47,047 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-12 05:58:47,299 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-12 05:58:47,329 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-12 05:58:47,336 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-12 05:58:47,356 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-12 05:58:47,363 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-12 05:58:47,370 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-12 05:58:47,621 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/tool-confirmation.js HTTP/1.1" 200 -
2025-08-12 05:58:47,658 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:47] "GET /static/js/agent-chat.js HTTP/1.1" 200 -
2025-08-12 05:58:48,013 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 05:58:48,038 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:48] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-12 05:58:48,049 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:48] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 05:58:48,055 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:48] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 05:58:48,093 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:48] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 05:58:48,254 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:48] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-12 05:58:48,502 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:48] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-12 05:58:48,777 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:48] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-12 05:58:49,697 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:49] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-12 05:58:57,077 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-12 05:58:57,077 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 05:58:57,077 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 05:58:57,125 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 05:58:57,125 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-12 05:58:57,125 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:58:57,125 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:58:57,125 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:58:57,132 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:58:57,133 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:58:57,133 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:58:57,133 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:58:58,022 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:58:58,030 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:58:58,032 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:58:58] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-12 05:58:58,032 - INFO - [agent_routes.py:112] - Processing query with 1 previous messages for context
2025-08-12 05:58:58,032 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-12 05:58:58,032 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:58:58,207 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:58:58,207 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:58:58,207 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:58:58,207 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:58:58,207 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:58:58,207 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:58:58,209 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:58:58,209 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:58:58,209 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:58:58,210 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:58:59,071 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:58:59,078 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:58:59,079 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-12 05:58:59,079 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: get me list of tools you have
2025-08-12 05:58:59,079 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-12 05:58:59,079 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. How can I help you today?"}, {'role': 'user', 'content': 'get me list of tools you have'}]
2025-08-12 05:58:59,079 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (1 previous messages)
2025-08-12 05:58:59,080 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-12 05:58:59,080 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:58:59,080 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:58:59,080 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:58:59,081 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:59:02,265 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 3.18s
2025-08-12 05:59:02,266 - INFO - [llm_engine.py:380] - [MCP-dataengineer] Raw model response: 'I have the following tools at my disposal:

*   `get_mapping_details(mapping_reference_name: str)`: Reads `mapping.xlsx`, filters by `mapping_reference_name`, and returns formatted details.
*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.
*   `run_bash_shell(command: str)`: Executes a shell command and returns combined stdout and stderr.
*   `get_table_data(table_name: str, limit: int | None = None)`: Fetches a specified numb...' (truncated)
2025-08-12 05:59:02,267 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 3.19s
2025-08-12 05:59:02,267 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:59:02,268 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='I have the following tools at my disposal:

*   `get_mapping_details(mapping_reference_name: str)`: Reads `mapping.xlsx`, filters by `mapping_reference_name`, and returns formatted details.
*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.
*   `run_bash_shell(command: str)`: Executes a shell command and returns combined stdout and stderr.
*   `get_table_data(table_name: str, limit: int | None = None)`: Fetches a specified number of rows from a given table.
*   `get_table_row_count(table_name: str)`: Returns the total number of rows in the specified table.
*   `list_mappings()`: Reads `mapping.xlsx` and returns a list of unique 'Mapping Name' values.
*   `execute_sql_query(query: str)`: Executes a read-only SQL query against the database and returns results.
*   `read_file(file_path: str)`: Reads contents of a file within the workspace.
*   `write_file(content: str, file_path: str)`: Writes content to a file within the workspace.
*   `validate_mapping_logic(mapping_reference_name: str)`: Validates the logical consistency of a mapping document.
*   `execute_sql_script(script_path: str, unsafe: bool | None = None)`: Executes a SQL script file against the SQLite database.', has_tool_calls=False
2025-08-12 05:59:02,269 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': "I have the following tools at my disposal:\n\n*   `get_mapping_details(mapping_reference_name: str)`: Reads `mapping.xlsx`, filters by `mapping_reference_name`, and returns formatted details.\n*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.\n*   `run_bash_shell(command: str)`: Executes a shell command and returns combined stdout and stderr.\n*   `get_table_data(table_name: str, limit: int | None = None)`: Fetches a specified number of rows from a given table.\n*   `get_table_row_count(table_name: str)`: Returns the total number of rows in the specified table.\n*   `list_mappings()`: Reads `mapping.xlsx` and returns a list of unique 'Mapping Name' values.\n*   `execute_sql_query(query: str)`: Executes a read-only SQL query against the database and returns results.\n*   `read_file(file_path: str)`: Reads contents of a file within the workspace.\n*   `write_file(content: str, file_path: str)`: Writes content to a file within the workspace.\n*   `validate_mapping_logic(mapping_reference_name: str)`: Validates the logical consistency of a mapping document.\n*   `execute_sql_script(script_path: str, unsafe: bool | None = None)`: Executes a SQL script file against the SQLite database."}
2025-08-12 05:59:02,270 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-12 05:59:02,271 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-12 05:59:02,272 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:59:02,500 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:59:02,501 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:59:02,501 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:59:02,501 - INFO - [agent_routes.py:249] - Agent audit - Collected 7 response parts
2025-08-12 05:59:02,501 - DEBUG - [agent_routes.py:250] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | LLM_RESPONSE: I have the following tools at my disposal:

*   `get_mapping_details(mapping_reference_name: str)`: Reads `mapping.xlsx`, filters by `mapping_reference_name`, and returns formatted details.
*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.
*   `run_bash_shell(command: str)`: ...
2025-08-12 05:59:13,703 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:59:13,703 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:59:13,704 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:59:13,710 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:59:13,710 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:59:13,711 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:59:13,712 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:59:14,610 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:59:14,618 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:59:14,619 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:59:14] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-12 05:59:14,620 - INFO - [agent_routes.py:112] - Processing query with 3 previous messages for context
2025-08-12 05:59:14,620 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-12 05:59:14,620 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:59:14,798 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:59:14,799 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:59:14,799 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:59:14,799 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:59:14,799 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:59:14,799 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:59:14,801 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:59:14,801 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:59:14,801 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:59:14,802 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:59:15,673 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:59:15,680 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:59:15,680 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-12 05:59:15,680 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: give me list of files in current directory
2025-08-12 05:59:15,681 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-12 05:59:15,681 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. How can I help you today?"}, {'role': 'user', 'content': 'get me list of tools you have'}, {'role': 'assistant', 'content': "I have the following tools at my disposal:\n\n*   `get_mapping_details(mapping_reference_name: str)`: Reads `mapping.xlsx`, filters by `mapping_reference_name`, and returns formatted details.\n*   `validate_mapping(table_columns_json: dict)`: Validates whether specified tables and columns exist in the database.\n*   `run_bash_shell(command: str)`: Executes a shell command and returns combined stdout and stderr.\n*   `get_table_data(table_name: str, limit: int | None = None)`: Fetches a specified number of rows from a given table.\n*   `get_table_row_count(table_name: str)`: Returns the total number of rows in the specified table.\n*   `list_mappings()`: Reads `mapping.xlsx` and returns a list of unique 'Mapping Name' values.\n*   `execute_sql_query(query: str)`: Executes a read-only SQL query against the database and returns results.\n*   `read_file(file_path: str)`: Reads contents of a file within the workspace.\n*   `write_file(content: str, file_path: str)`: Writes content to a file within the workspace.\n*   `validate_mapping_logic(mapping_reference_name: str)`: Validates the logical consistency of a mapping document.\n*   `execute_sql_script(script_path: str, unsafe: bool | None = None)`: Executes a SQL script file against the SQLite database."}, {'role': 'user', 'content': 'give me list of files in current directory'}]
2025-08-12 05:59:15,681 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (3 previous messages)
2025-08-12 05:59:15,681 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-12 05:59:15,682 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:59:15,682 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:59:15,682 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:59:15,682 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:59:17,653 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 1.97s
2025-08-12 05:59:17,654 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-12 05:59:17,655 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 1.97s
2025-08-12 05:59:17,656 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:59:17,656 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='None', has_tool_calls=True
2025-08-12 05:59:17,657 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 1/5)
2025-08-12 05:59:17,658 - INFO - [mcp_client_manager.py:519] - Calling tool 'run_bash_shell' with args: {'command': 'ls -F'}
2025-08-12 05:59:17,658 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling run_bash_shell via MCP session
2025-08-12 05:59:17,684 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: meta=None content=[TextContent(type='text', text='=0.3.0\nAIRGAP_DEPLOYMENT_INFO.md\nAIRGAP_README.md\nMCP_SKILL_LIBRARY_SUMMARY.md\nMESSAGE_FORMAT_GUIDE.md\nREADME.md\n__init__.py\napp.py\nchroma_data/\nchromadb_service/\nconfig/\ndata_mapping_metadata/\ndatabase.db\ndownload_vendor_assets.sh*\ninit_data_mapping_workflow.py\ninit_skill_library.py*\ninit_skill_library_db.py*\ninitialize_skills.py*\nlogs/\nrequirements.txt\nrestart.sh*\nsample_skills.json\nsetup_airgap.sh*\nsrc/\nstart_all_services.sh\nstart_mcp_data_mapping_server.sh*\nstart_mcp_skill_server.sh*\nstatic/\nstreamlit_app.py\ntasks.md\ntemplates/\ntemplates_backup_20250811_101418/\ntest.ipynb\ntest1.sh\ntest_llama_function_calling.py\ntest_message_formats.py\ntest_timestamp_fix.py\ntest_workflow_fix.py\ntext2sql.db\ntext2sql.db-shm\ntext2sql.db-wal\nupdate_templates.sh*\nupdate_vector_service.sh*\nuploads/\nvector_store.db\nverify_airgap.sh*\nweather.py', annotations=None, meta=None)] structuredContent={'result': '=0.3.0\nAIRGAP_DEPLOYMENT_INFO.md\nAIRGAP_README.md\nMCP_SKILL_LIBRARY_SUMMARY.md\nMESSAGE_FORMAT_GUIDE.md\nREADME.md\n__init__.py\napp.py\nchroma_data/\nchromadb_service/\nconfig/\ndata_mapping_metadata/\ndatabase.db\ndownload_vendor_assets.sh*\ninit_data_mapping_workflow.py\ninit_skill_library.py*\ninit_skill_library_db.py*\ninitialize_skills.py*\nlogs/\nrequirements.txt\nrestart.sh*\nsample_skills.json\nsetup_airgap.sh*\nsrc/\nstart_all_services.sh\nstart_mcp_data_mapping_server.sh*\nstart_mcp_skill_server.sh*\nstatic/\nstreamlit_app.py\ntasks.md\ntemplates/\ntemplates_backup_20250811_101418/\ntest.ipynb\ntest1.sh\ntest_llama_function_calling.py\ntest_message_formats.py\ntest_timestamp_fix.py\ntest_workflow_fix.py\ntext2sql.db\ntext2sql.db-shm\ntext2sql.db-wal\nupdate_templates.sh*\nupdate_vector_service.sh*\nuploads/\nvector_store.db\nverify_airgap.sh*\nweather.py'} isError=False completed successfully
2025-08-12 05:59:17,684 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-12 05:59:17,685 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:59:17,685 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:59:17,685 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:59:17,685 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:59:19,764 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 2.08s
2025-08-12 05:59:19,764 - INFO - [llm_engine.py:380] - [MCP-dataengineer] Raw model response: 'The files in the current directory are:
=0.3.0
AIRGAP_DEPLOYMENT_INFO.md
AIRGAP_README.md
MCP_SKILL_LIBRARY_SUMMARY.md
MESSAGE_FORMAT_GUIDE.md
README.md
__init__.py
app.py
chroma_data/
chromadb_service/
config/
data_mapping_metadata/
database.db
download_vendor_assets.sh*
init_data_mapping_workflow.py
init_skill_library.py*
init_skill_library_db.py*
initialize_skills.py*
logs/
requirements.txt
restart.sh*
sample_skills.json
setup_airgap.sh*
src/
start_all_services.sh
start_mcp_data_mapping_serve...' (truncated)
2025-08-12 05:59:19,765 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 2.08s
2025-08-12 05:59:19,765 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:59:19,765 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='The files in the current directory are:
=0.3.0
AIRGAP_DEPLOYMENT_INFO.md
AIRGAP_README.md
MCP_SKILL_LIBRARY_SUMMARY.md
MESSAGE_FORMAT_GUIDE.md
README.md
__init__.py
app.py
chroma_data/
chromadb_service/
config/
data_mapping_metadata/
database.db
download_vendor_assets.sh*
init_data_mapping_workflow.py
init_skill_library.py*
init_skill_library_db.py*
initialize_skills.py*
logs/
requirements.txt
restart.sh*
sample_skills.json
setup_airgap.sh*
src/
start_all_services.sh
start_mcp_data_mapping_server.sh*
start_mcp_skill_server.sh*
static/
streamlit_app.py
tasks.md
templates/
templates_backup_20250811_101418/
test.ipynb
test1.sh
test_llama_function_calling.py
test_message_formats.py
test_timestamp_fix.py
test_workflow_fix.py
text2sql.db
text2sql.db-shm
text2sql.db-wal
update_templates.sh*
update_vector_service.sh*
uploads/
vector_store.db
verify_airgap.sh*
weather.py', has_tool_calls=False
2025-08-12 05:59:19,766 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': 'The files in the current directory are:\n=0.3.0\nAIRGAP_DEPLOYMENT_INFO.md\nAIRGAP_README.md\nMCP_SKILL_LIBRARY_SUMMARY.md\nMESSAGE_FORMAT_GUIDE.md\nREADME.md\n__init__.py\napp.py\nchroma_data/\nchromadb_service/\nconfig/\ndata_mapping_metadata/\ndatabase.db\ndownload_vendor_assets.sh*\ninit_data_mapping_workflow.py\ninit_skill_library.py*\ninit_skill_library_db.py*\ninitialize_skills.py*\nlogs/\nrequirements.txt\nrestart.sh*\nsample_skills.json\nsetup_airgap.sh*\nsrc/\nstart_all_services.sh\nstart_mcp_data_mapping_server.sh*\nstart_mcp_skill_server.sh*\nstatic/\nstreamlit_app.py\ntasks.md\ntemplates/\ntemplates_backup_20250811_101418/\ntest.ipynb\ntest1.sh\ntest_llama_function_calling.py\ntest_message_formats.py\ntest_timestamp_fix.py\ntest_workflow_fix.py\ntext2sql.db\ntext2sql.db-shm\ntext2sql.db-wal\nupdate_templates.sh*\nupdate_vector_service.sh*\nuploads/\nvector_store.db\nverify_airgap.sh*\nweather.py'}
2025-08-12 05:59:19,766 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-12 05:59:19,767 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-12 05:59:19,767 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:59:19,949 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:59:19,950 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:59:19,950 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:59:19,950 - INFO - [agent_routes.py:249] - Agent audit - Collected 8 response parts
2025-08-12 05:59:19,950 - DEBUG - [agent_routes.py:250] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | STATUS: Processing tool results... | LLM_RESPONSE: The files in the current directory are:
=0.3.0
AIRGAP_DEPLOYMENT_INFO.md
AIRGAP_README.md
MCP_SKILL_LIBRARY_SUMMARY.md
MESSAGE_FORMAT_GUIDE.md
README.md
__init__.py
app.py
chroma_data/
chromadb_service/
config/
data_mapping_metadata/
database.db
download_vendor_assets.sh*
init_data_mapping_workflow.py
init_s...
2025-08-12 05:59:24,671 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:59:24,672 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:59:24,672 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:59:24,675 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:59:24,676 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:59:24,676 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:59:24,677 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:59:25,591 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:59:25,601 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:59:25,602 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:59:25] "POST /api/agent/chat HTTP/1.1" 200 -
2025-08-12 05:59:25,602 - INFO - [agent_routes.py:112] - Processing query with 4 previous messages for context
2025-08-12 05:59:25,602 - INFO - [mcp_client_manager.py:707] - Cleaning up existing connection for fresh start on dataengineer
2025-08-12 05:59:25,603 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:59:25,764 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:59:25,764 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:59:25,764 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:59:25,765 - INFO - [mcp_client_manager.py:160] - Connecting to stdio MCP server: dataengineer with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:59:25,765 - DEBUG - [mcp_client_manager.py:175] - Creating StdioServerParameters with command=/home/vijay/anaconda3/bin/python, args=['./src/utils/dataengineer.py']
2025-08-12 05:59:25,765 - INFO - [mcp_client_manager.py:194] - Establishing stdio connection with command: /home/vijay/anaconda3/bin/python
2025-08-12 05:59:25,766 - INFO - [mcp_client_manager.py:196] - Stdio transport created successfully
2025-08-12 05:59:25,766 - INFO - [mcp_client_manager.py:200] - Creating ClientSession
2025-08-12 05:59:25,767 - INFO - [mcp_client_manager.py:204] - ClientSession created successfully
2025-08-12 05:59:25,767 - INFO - [mcp_client_manager.py:207] - Initializing MCP session
2025-08-12 05:59:26,650 - INFO - [mcp_client_manager.py:209] - MCP session initialized successfully
2025-08-12 05:59:26,660 - INFO - [mcp_client_manager.py:228] - Successfully connected to stdio MCP server dataengineer with 11 tools
2025-08-12 05:59:26,660 - INFO - [mcp_client_manager.py:732] - Fresh connection established successfully for dataengineer
2025-08-12 05:59:26,660 - INFO - [mcp_client_manager.py:400] - Processing query on server dataengineer with conversation history: which is largest
2025-08-12 05:59:26,660 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Starting query processing on dataengineer...'}
2025-08-12 05:59:26,660 - INFO - [mcp_client_manager.py:442] - **************: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactively to solve user requests\n2. SQL queries should be compatible with SQLite (avoid CTEs, use subqueries if needed)\n3. After receiving tool results, provide a clear summary\n4. Only retry failed steps if it makes logical sense\n5. Provide a clear final answer when complete"}, {'role': 'assistant', 'content': "Hello! I'm your agent assistant. How can I help you today?"}, {'role': 'user', 'content': 'get me list of tools you have'}, {'role': 'user', 'content': 'give me list of files in current directory'}, {'role': 'assistant', 'content': 'The files in the current directory are:\n=0.3.0\nAIRGAP_DEPLOYMENT_INFO.md\nAIRGAP_README.md\nMCP_SKILL_LIBRARY_SUMMARY.md\nMESSAGE_FORMAT_GUIDE.md\nREADME.md\n__init__.py\napp.py\nchroma_data/\nchromadb_service/\nconfig/\ndata_mapping_metadata/\ndatabase.db\ndownload_vendor_assets.sh*\ninit_data_mapping_workflow.py\ninit_skill_library.py*\ninit_skill_library_db.py*\ninitialize_skills.py*\nlogs/\nrequirements.txt\nrestart.sh*\nsample_skills.json\nsetup_airgap.sh*\nsrc/\nstart_all_services.sh\nstart_mcp_data_mapping_server.sh*\nstart_mcp_skill_server.sh*\nstatic/\nstreamlit_app.py\ntasks.md\ntemplates/\ntemplates_backup_20250811_101418/\ntest.ipynb\ntest1.sh\ntest_llama_function_calling.py\ntest_message_formats.py\ntest_timestamp_fix.py\ntest_workflow_fix.py\ntext2sql.db\ntext2sql.db-shm\ntext2sql.db-wal\nupdate_templates.sh*\nupdate_vector_service.sh*\nuploads/\nvector_store.db\nverify_airgap.sh*\nweather.py'}, {'role': 'user', 'content': 'which is largest'}]
2025-08-12 05:59:26,660 - INFO - [mcp_client_manager.py:443] - Processing query with conversation history (4 previous messages)
2025-08-12 05:59:26,661 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Generating initial plan...'}
2025-08-12 05:59:26,661 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:59:26,661 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:59:26,661 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:59:26,661 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:59:28,715 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 2.05s
2025-08-12 05:59:28,715 - INFO - [llm_engine.py:385] - [MCP-dataengineer] Model requested 1 tool calls
2025-08-12 05:59:28,716 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 2.05s
2025-08-12 05:59:28,716 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:59:28,716 - INFO - [mcp_client_manager.py:480] - Initial LLM response from dataengineer: content='None', has_tool_calls=True
2025-08-12 05:59:28,717 - INFO - [mcp_client_manager.py:493] - Tool calls on dataengineer: 1 (Loop 1/5)
2025-08-12 05:59:28,717 - INFO - [mcp_client_manager.py:519] - Calling tool 'run_bash_shell' with args: {'command': 'ls -lh'}
2025-08-12 05:59:28,718 - INFO - [mcp_client_manager.py:766] - TOOL CALL ATTEMPT 1: Calling run_bash_shell via MCP session
2025-08-12 05:59:28,738 - INFO - [mcp_client_manager.py:768] - TOOL CALL SUCCESS: meta=None content=[TextContent(type='text', text='total 7.8M\n-rw-r--r-- 1 vijay vijay 2.2K Aug 11 14:07 =0.3.0\n-rw-r--r-- 1 vijay vijay 1.5K Aug 11 12:54 AIRGAP_DEPLOYMENT_INFO.md\n-rw-r--r-- 1 vijay vijay 3.9K Aug 11 12:54 AIRGAP_README.md\n-rw-r--r-- 1 vijay vijay 4.4K Aug 11 12:16 MCP_SKILL_LIBRARY_SUMMARY.md\n-rw-r--r-- 1 vijay vijay 5.5K Aug 11 12:16 MESSAGE_FORMAT_GUIDE.md\n-rw-r--r-- 1 vijay vijay  33K Aug 11 12:54 README.md\n-rw-r--r-- 1 vijay vijay  134 Aug 11 12:16 __init__.py\n-rw-r--r-- 1 vijay vijay  31K Aug 11 13:44 app.py\ndrwxr-xr-x 9 vijay vijay 4.0K Aug 11 12:54 chroma_data\ndrwxr-xr-x 4 vijay vijay 4.0K Aug 11 12:54 chromadb_service\ndrwxr-xr-x 4 vijay vijay 4.0K Aug 11 12:54 config\ndrwxr-xr-x 2 vijay vijay 4.0K Aug 11 12:54 data_mapping_metadata\n-rw-r--r-- 1 vijay vijay    0 Aug 11 12:16 database.db\n-rwxr-xr-x 1 vijay vijay 7.9K Aug 11 12:54 download_vendor_assets.sh\n-rw-r--r-- 1 vijay vijay    0 Aug 12 05:35 init_data_mapping_workflow.py\n-rwxr-xr-x 1 vijay vijay 4.4K Aug 11 12:16 init_skill_library.py\n-rwxr-xr-x 1 vijay vijay 4.3K Aug 11 12:16 init_skill_library_db.py\n-rwxr-xr-x 1 vijay vijay 4.4K Aug 11 12:16 initialize_skills.py\ndrwxr-xr-x 2 vijay vijay 4.0K Aug 11 12:54 logs\n-rw-r--r-- 1 vijay vijay  337 Aug 11 15:04 requirements.txt\n-rwxr-xr-x 1 vijay vijay  362 Aug 11 12:16 restart.sh\n-rw-r--r-- 1 vijay vijay  16K Aug 11 12:16 sample_skills.json\n-rwxr-xr-x 1 vijay vijay 7.3K Aug 11 12:54 setup_airgap.sh\ndrwxr-xr-x 7 vijay vijay 4.0K Aug 11 12:16 src\n-rw-r--r-- 1 vijay vijay 2.9K Aug 11 12:16 start_all_services.sh\n-rwxr-xr-x 1 vijay vijay 1.1K Aug 11 12:54 start_mcp_data_mapping_server.sh\n-rwxr-xr-x 1 vijay vijay  921 Aug 11 12:16 start_mcp_skill_server.sh\ndrwxr-xr-x 5 vijay vijay 4.0K Aug 11 12:54 static\n-rw-r--r-- 1 vijay vijay  19K Aug 11 12:16 streamlit_app.py\n-rw-r--r-- 1 vijay vijay 3.6K Aug 11 12:54 tasks.md\ndrwxr-xr-x 6 vijay vijay 4.0K Aug 11 12:54 templates\ndrwxr-xr-x 6 vijay vijay 4.0K Aug 11 12:54 templates_backup_20250811_101418\n-rw-r--r-- 1 vijay vijay 137K Aug 11 12:16 test.ipynb\n-rw-r--r-- 1 vijay vijay  202 Aug 11 12:54 test1.sh\n-rw-r--r-- 1 vijay vijay 5.1K Aug 11 12:16 test_llama_function_calling.py\n-rw-r--r-- 1 vijay vijay 5.6K Aug 11 12:16 test_message_formats.py\n-rw-r--r-- 1 vijay vijay    0 Aug 12 05:35 test_timestamp_fix.py\n-rw-r--r-- 1 vijay vijay    0 Aug 12 05:35 test_workflow_fix.py\n-rw-r--r-- 1 vijay vijay 1.2M Aug 11 17:56 text2sql.db\n-rw-r--r-- 1 vijay vijay  32K Aug 12 05:59 text2sql.db-shm\n-rw-r--r-- 1 vijay vijay 3.8M Aug 12 05:59 text2sql.db-wal\n-rwxr-xr-x 1 vijay vijay 9.4K Aug 11 12:54 update_templates.sh\n-rwxr-xr-x 1 vijay vijay    0 Aug 11 12:16 update_vector_service.sh\ndrwxr-xr-x 2 vijay vijay 4.0K Aug 11 12:54 uploads\n-rw-r--r-- 1 vijay vijay 2.4M Aug 11 12:16 vector_store.db\n-rwxr-xr-x 1 vijay vijay  604 Aug 11 12:54 verify_airgap.sh\n-rw-r--r-- 1 vijay vijay 4.4K Aug 11 12:16 weather.py', annotations=None, meta=None)] structuredContent={'result': 'total 7.8M\n-rw-r--r-- 1 vijay vijay 2.2K Aug 11 14:07 =0.3.0\n-rw-r--r-- 1 vijay vijay 1.5K Aug 11 12:54 AIRGAP_DEPLOYMENT_INFO.md\n-rw-r--r-- 1 vijay vijay 3.9K Aug 11 12:54 AIRGAP_README.md\n-rw-r--r-- 1 vijay vijay 4.4K Aug 11 12:16 MCP_SKILL_LIBRARY_SUMMARY.md\n-rw-r--r-- 1 vijay vijay 5.5K Aug 11 12:16 MESSAGE_FORMAT_GUIDE.md\n-rw-r--r-- 1 vijay vijay  33K Aug 11 12:54 README.md\n-rw-r--r-- 1 vijay vijay  134 Aug 11 12:16 __init__.py\n-rw-r--r-- 1 vijay vijay  31K Aug 11 13:44 app.py\ndrwxr-xr-x 9 vijay vijay 4.0K Aug 11 12:54 chroma_data\ndrwxr-xr-x 4 vijay vijay 4.0K Aug 11 12:54 chromadb_service\ndrwxr-xr-x 4 vijay vijay 4.0K Aug 11 12:54 config\ndrwxr-xr-x 2 vijay vijay 4.0K Aug 11 12:54 data_mapping_metadata\n-rw-r--r-- 1 vijay vijay    0 Aug 11 12:16 database.db\n-rwxr-xr-x 1 vijay vijay 7.9K Aug 11 12:54 download_vendor_assets.sh\n-rw-r--r-- 1 vijay vijay    0 Aug 12 05:35 init_data_mapping_workflow.py\n-rwxr-xr-x 1 vijay vijay 4.4K Aug 11 12:16 init_skill_library.py\n-rwxr-xr-x 1 vijay vijay 4.3K Aug 11 12:16 init_skill_library_db.py\n-rwxr-xr-x 1 vijay vijay 4.4K Aug 11 12:16 initialize_skills.py\ndrwxr-xr-x 2 vijay vijay 4.0K Aug 11 12:54 logs\n-rw-r--r-- 1 vijay vijay  337 Aug 11 15:04 requirements.txt\n-rwxr-xr-x 1 vijay vijay  362 Aug 11 12:16 restart.sh\n-rw-r--r-- 1 vijay vijay  16K Aug 11 12:16 sample_skills.json\n-rwxr-xr-x 1 vijay vijay 7.3K Aug 11 12:54 setup_airgap.sh\ndrwxr-xr-x 7 vijay vijay 4.0K Aug 11 12:16 src\n-rw-r--r-- 1 vijay vijay 2.9K Aug 11 12:16 start_all_services.sh\n-rwxr-xr-x 1 vijay vijay 1.1K Aug 11 12:54 start_mcp_data_mapping_server.sh\n-rwxr-xr-x 1 vijay vijay  921 Aug 11 12:16 start_mcp_skill_server.sh\ndrwxr-xr-x 5 vijay vijay 4.0K Aug 11 12:54 static\n-rw-r--r-- 1 vijay vijay  19K Aug 11 12:16 streamlit_app.py\n-rw-r--r-- 1 vijay vijay 3.6K Aug 11 12:54 tasks.md\ndrwxr-xr-x 6 vijay vijay 4.0K Aug 11 12:54 templates\ndrwxr-xr-x 6 vijay vijay 4.0K Aug 11 12:54 templates_backup_20250811_101418\n-rw-r--r-- 1 vijay vijay 137K Aug 11 12:16 test.ipynb\n-rw-r--r-- 1 vijay vijay  202 Aug 11 12:54 test1.sh\n-rw-r--r-- 1 vijay vijay 5.1K Aug 11 12:16 test_llama_function_calling.py\n-rw-r--r-- 1 vijay vijay 5.6K Aug 11 12:16 test_message_formats.py\n-rw-r--r-- 1 vijay vijay    0 Aug 12 05:35 test_timestamp_fix.py\n-rw-r--r-- 1 vijay vijay    0 Aug 12 05:35 test_workflow_fix.py\n-rw-r--r-- 1 vijay vijay 1.2M Aug 11 17:56 text2sql.db\n-rw-r--r-- 1 vijay vijay  32K Aug 12 05:59 text2sql.db-shm\n-rw-r--r-- 1 vijay vijay 3.8M Aug 12 05:59 text2sql.db-wal\n-rwxr-xr-x 1 vijay vijay 9.4K Aug 11 12:54 update_templates.sh\n-rwxr-xr-x 1 vijay vijay    0 Aug 11 12:16 update_vector_service.sh\ndrwxr-xr-x 2 vijay vijay 4.0K Aug 11 12:54 uploads\n-rw-r--r-- 1 vijay vijay 2.4M Aug 11 12:16 vector_store.db\n-rwxr-xr-x 1 vijay vijay  604 Aug 11 12:54 verify_airgap.sh\n-rw-r--r-- 1 vijay vijay 4.4K Aug 11 12:16 weather.py'} isError=False completed successfully
2025-08-12 05:59:28,739 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing tool results...'}
2025-08-12 05:59:28,740 - INFO - [llm_engine.py:282] - [MCP-dataengineer] Tool-enabled completion generation started (format: openai)
2025-08-12 05:59:28,740 - INFO - [llm_engine.py:349] - [MCP-dataengineer] Prompt: [{'role': 'system', 'content': "You are an AI assistant using tools provided by the MCP server 'dataengineer'.\n\nCRITICAL FUNCTION CALLING RULES:\n- When you need to use ANY tool/function, respond with ONLY the JSON format specified in the prompt\n- Do NOT explain what you're doing before calling functions\n- Do NOT mix explanations with function calls\n- Use functions immediately when needed, then explain results after getting tool responses\n\nFollow these guidelines:\n1. Use tools proactivel... (truncated)
2025-08-12 05:59:28,740 - INFO - [llm_engine.py:365] - [MCP-dataengineer] Including 11 tools with choice: auto
2025-08-12 05:59:28,741 - INFO - [llm_engine.py:367] - [MCP-dataengineer] Sending request to gemini-2.5-flash with max_tokens=1500, temperature=0.7
2025-08-12 05:59:30,346 - INFO - [llm_engine.py:373] - [MCP-dataengineer] Model response received in 1.61s
2025-08-12 05:59:30,347 - INFO - [llm_engine.py:382] - [MCP-dataengineer] Raw model response: 'The largest file in the current directory is `text2sql.db-wal` with a size of 3.8M.'
2025-08-12 05:59:30,347 - INFO - [llm_engine.py:388] - [MCP-dataengineer] Tool-enabled completion generation completed in 1.61s
2025-08-12 05:59:30,347 - INFO - [llm_engine.py:389] - **************************
2025-08-12 05:59:30,348 - INFO - [mcp_client_manager.py:558] - LLM response after tool calls on dataengineer: content='The largest file in the current directory is `text2sql.db-wal` with a size of 3.8M.', has_tool_calls=False
2025-08-12 05:59:30,348 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'llm_response', 'content': 'The largest file in the current directory is `text2sql.db-wal` with a size of 3.8M.'}
2025-08-12 05:59:30,349 - DEBUG - [agent_routes.py:125] - Agent stream update: {'type': 'status', 'message': 'Processing complete.'}
2025-08-12 05:59:30,350 - DEBUG - [mcp_client_manager.py:856] - Cleaning up connection resources after request for dataengineer
2025-08-12 05:59:30,350 - INFO - [mcp_client_manager.py:609] - Cleaning up MCP client resources for server dataengineer...
2025-08-12 05:59:30,532 - WARNING - [mcp_client_manager.py:634] - Error during exit stack cleanup for dataengineer: Attempted to exit cancel scope in a different task than it was entered in
2025-08-12 05:59:30,532 - DEBUG - [mcp_client_manager.py:657] - Reset state for MCP client dataengineer
2025-08-12 05:59:30,532 - INFO - [mcp_client_manager.py:639] - MCP client resources cleaned up for server dataengineer.
2025-08-12 05:59:30,533 - INFO - [agent_routes.py:249] - Agent audit - Collected 7 response parts
2025-08-12 05:59:30,533 - DEBUG - [agent_routes.py:250] - Agent audit - Full response preview: STATUS: Connected to MCP server: dataengineer | STATUS: Starting query processing on dataengineer... | STATUS: Generating initial plan... | STATUS: Processing tool results... | LLM_RESPONSE: The largest file in the current directory is `text2sql.db-wal` with a size of 3.8M. | STATUS: Processing complete. | STATUS: Agent processing completed....
2025-08-12 05:59:36,387 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:59:36] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 05:59:36,389 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:59:36] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 05:59:47,505 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 05:59:47] "POST /api/agent/autogen/chat HTTP/1.1" 200 -
2025-08-12 05:59:47,555 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-12 05:59:47,589 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-12 05:59:47,623 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-12 05:59:47,657 - INFO - [autogen_orchestrator.py:267] - OpenAIChatCompletionClient initialized (model=gemini-2.5-flash, family=gemini, base_url=https://generativelanguage.googleapis.com/v1beta/openai/, api_key=AIza…)
2025-08-12 06:00:07,924 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:00:07] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-12 06:00:09,265 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:00:09] "GET /api/agent/runs/67 HTTP/1.1" 200 -
2025-08-12 06:01:02,925 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:01:02] "GET /api/agent/runs/66 HTTP/1.1" 200 -
2025-08-12 06:03:59,230 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:03:59] "GET /api/agent/servers HTTP/1.1" 200 -
2025-08-12 06:05:03,230 - DEBUG - [mcp_client_manager.py:606] - Cleanup for dataengineer skipped - already cleaned up
2025-08-12 06:05:03,231 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 06:05:03,232 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 06:05:03,233 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:05:03,234 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 06:05:03,235 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:05:03,236 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 06:05:03,237 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:05:03,237 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 06:05:03,238 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:05:03,239 - INFO - [database.py:328] - Closing database connection
2025-08-12 06:05:03,240 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 06:05:03,241 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 06:05:03,245 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 06:05:03,246 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 06:05:03,246 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:05:03,248 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 06:05:03,249 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:05:03,250 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 06:05:03,251 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:05:03,252 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 06:05:03,253 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:05:03,254 - INFO - [database.py:328] - Closing database connection
2025-08-12 06:05:03,255 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 06:05:03,256 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 06:05:07,447 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:07,447 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:07,447 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:07,447 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:07,449 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:05:11,273 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-12 06:05:14,787 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:05:14,788 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:05:14,823 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:05:14,824 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:14,824 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:14,824 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:14,824 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:14,824 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:05:14,825 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:05:14,861 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:05:14,861 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:14,861 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:14,862 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:14,862 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:14,862 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:05:14,862 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:05:14,897 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:05:14,897 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:14,897 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:14,898 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:14,898 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:14,898 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 06:05:14,898 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:05:14,898 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:05:14,933 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:05:14,933 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 06:05:14,933 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:05:14,933 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:14,933 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:14,934 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:14,934 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:14,934 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:05:14,944 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-12 06:05:14,970 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-12 06:05:14,973 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-12 06:05:14,974 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-12 06:05:15,010 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:05:15,010 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:05:15,050 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:05:15,050 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:15,050 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:15,051 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:15,051 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:15,051 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:05:15,051 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:05:15,085 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:05:15,085 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:15,085 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:15,085 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:15,086 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:15,086 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:05:15,086 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:05:15,124 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:05:15,125 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:15,125 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:15,125 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:15,125 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:15,126 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 06:05:15,126 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:05:15,126 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:05:15,161 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:05:15,161 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 06:05:15,161 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:05:15,162 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:05:15,162 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:05:15,162 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:05:15,162 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:05:15,162 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:05:15,177 - INFO - [app.py:736] - Initializing application-wide components
2025-08-12 06:05:15,213 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-12 06:05:15,215 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-12 06:05:15,215 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-12 06:05:15,219 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-12 06:05:15,219 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-12 06:05:21,005 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-12 06:05:21,162 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-12 06:05:21,258 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-12 06:05:21,589 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 06:05:21,595 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-12 06:05:21,613 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 06:05:21,633 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-12 06:05:21,643 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-12 06:05:21,672 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-12 06:05:21,951 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-12 06:05:21,990 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:21] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-12 06:05:22,020 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,036 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,049 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,061 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,273 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-12 06:05:22,324 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,381 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,382 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,386 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,394 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-12 06:05:22,593 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-12 06:05:22,648 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-12 06:05:22,700 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-12 06:05:22,710 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-12 06:05:22,716 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-12 06:05:22,720 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-12 06:05:22,917 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-12 06:05:22,977 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:22] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-12 06:05:23,027 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-12 06:05:23,039 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-12 06:05:23,054 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-12 06:05:23,059 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-12 06:05:23,236 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /static/js/admin/agent-runs.js HTTP/1.1" 200 -
2025-08-12 06:05:23,570 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:05:23,598 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-12 06:05:23,616 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-12 06:05:23,666 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:05:23,818 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:23] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-12 06:05:24,075 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:24] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-12 06:05:24,455 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:24] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-12 06:05:29,793 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:29] "GET /api/agent/runs/66 HTTP/1.1" 200 -
2025-08-12 06:05:48,897 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:48] "GET /api/agent/runs/58 HTTP/1.1" 200 -
2025-08-12 06:05:53,486 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:05:53] "GET /api/agent/runs/56 HTTP/1.1" 200 -
2025-08-12 06:09:19,266 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 06:09:19,266 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 06:09:19,267 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:09:19,267 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 06:09:19,267 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:09:19,267 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 06:09:19,267 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:09:19,267 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 06:09:19,268 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:09:19,268 - INFO - [database.py:328] - Closing database connection
2025-08-12 06:09:19,268 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 06:09:19,268 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 06:09:19,269 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 06:09:19,269 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 06:09:19,269 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:09:19,269 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 06:09:19,269 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:09:19,269 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 06:09:19,269 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:09:19,269 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 06:09:19,270 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:09:19,270 - INFO - [database.py:328] - Closing database connection
2025-08-12 06:09:19,270 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 06:09:19,270 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 06:09:25,463 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:25,463 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:25,463 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:25,464 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:25,465 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:09:30,053 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-12 06:09:33,604 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:09:33,604 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:09:33,648 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:09:33,648 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:33,649 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:33,649 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:33,649 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:33,649 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:09:33,649 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:09:33,694 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:09:33,694 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:33,695 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:33,695 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:33,695 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:33,695 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:09:33,696 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:09:33,741 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:09:33,741 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:33,742 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:33,742 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:33,742 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:33,742 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 06:09:33,743 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:09:33,743 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:09:33,788 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:09:33,788 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 06:09:33,788 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:09:33,788 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:33,788 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:33,789 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:33,789 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:33,789 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:09:33,799 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-12 06:09:33,830 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-12 06:09:33,834 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-12 06:09:33,835 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-12 06:09:33,884 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:09:33,885 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:09:33,934 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:09:33,934 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:33,935 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:33,935 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:33,935 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:33,935 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:09:33,935 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:09:33,983 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:09:33,983 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:33,983 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:33,983 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:33,984 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:33,984 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:09:33,984 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:09:34,034 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:09:34,034 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:34,034 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:34,035 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:34,035 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:34,035 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 06:09:34,035 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:09:34,036 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:09:34,087 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:09:34,087 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 06:09:34,088 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:09:34,088 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:09:34,088 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:09:34,088 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:09:34,089 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:09:34,089 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:09:34,110 - INFO - [app.py:736] - Initializing application-wide components
2025-08-12 06:09:34,114 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-12 06:09:34,115 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-12 06:09:34,115 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-12 06:09:34,118 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-12 06:09:34,118 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-12 06:09:41,753 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-12 06:09:41,842 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:41] "GET /admin/agent-runs HTTP/1.1" 200 -
2025-08-12 06:09:42,016 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-12 06:09:42,196 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-12 06:09:42,222 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 06:09:42,232 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 06:09:42,251 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-12 06:09:42,264 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-12 06:09:42,354 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-12 06:09:42,583 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-12 06:09:42,600 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-12 06:09:42,649 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-12 06:09:42,652 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-12 06:09:42,661 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-12 06:09:42,676 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 06:09:42,935 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-12 06:09:42,945 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-12 06:09:42,993 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 06:09:42,996 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:42] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-12 06:09:43,001 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-12 06:09:43,013 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-12 06:09:43,258 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-12 06:09:43,267 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-12 06:09:43,327 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-12 06:09:43,355 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-12 06:09:43,369 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-12 06:09:43,370 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-12 06:09:43,597 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-12 06:09:43,603 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-12 06:09:43,658 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-12 06:09:43,685 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-12 06:09:43,690 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-12 06:09:43,697 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-12 06:09:43,922 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:43] "GET /static/js/admin/agent-runs.js HTTP/1.1" 200 -
2025-08-12 06:09:44,254 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:09:44,269 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:44] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-12 06:09:44,273 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:44] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-12 06:09:44,300 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:44] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:09:44,498 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:44] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-12 06:09:44,700 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:44] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-12 06:09:44,854 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:09:44] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-12 06:10:00,241 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:00] "GET /api/agent/runs?limit=100 HTTP/1.1" 200 -
2025-08-12 06:10:08,162 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:08] "GET /api/agent/runs?limit=50 HTTP/1.1" 200 -
2025-08-12 06:10:19,311 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:19] "GET /api/agent/runs/56 HTTP/1.1" 200 -
2025-08-12 06:10:30,841 - DEBUG - [app.py:172] - Main page requested
2025-08-12 06:10:30,848 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:30] "GET / HTTP/1.1" 200 -
2025-08-12 06:10:31,258 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:31] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:31,270 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:31] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:31,303 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:31] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:31,309 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:31] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:31,313 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:31] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:31,319 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:31] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:31,595 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:31] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:31,606 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:31] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:32,347 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-12 06:10:32,361 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:32] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-12 06:10:32,403 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:32] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-12 06:10:32,668 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:32] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-12 06:10:32,994 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:32] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-12 06:10:33,259 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:33] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-12 06:10:33,640 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:33] "GET /query-editor HTTP/1.1" 200 -
2025-08-12 06:10:33,647 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:33] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-12 06:10:33,715 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:33] "GET /static/js/query-editor.js HTTP/1.1" 200 -
2025-08-12 06:10:34,067 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-12 06:10:34,115 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:34] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-12 06:10:34,164 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:34] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-12 06:10:34,178 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:34] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-12 06:10:34,842 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:34] "GET /knowledge HTTP/1.1" 200 -
2025-08-12 06:10:35,216 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:35] "GET /static/js/knowledge-base.js HTTP/1.1" 200 -
2025-08-12 06:10:35,455 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:10:35,475 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:35] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:10:35,548 - INFO - [knowledge_manager.py:33] - Initializing Knowledge Manager
2025-08-12 06:10:35,637 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-12 06:10:35,643 - INFO - [vector_store_client.py:44] - ChromaDB service connection established in 0.01s
2025-08-12 06:10:35,722 - INFO - [vector_store_client.py:121] - Collection 'knowledge_chunks' already exists
2025-08-12 06:10:35,722 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:10:35,722 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:10:35,743 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:35] "GET /agent HTTP/1.1" 200 -
2025-08-12 06:10:35,769 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:10:35,771 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:35] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-12 06:10:36,094 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:36] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-12 06:10:36,097 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:36] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-12 06:10:36,339 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:10:36,350 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:36] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:10:36,434 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:36] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 06:10:36,437 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:36] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 06:10:38,556 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:38] "GET /agent HTTP/1.1" 200 -
2025-08-12 06:10:38,957 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:10:38,987 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:38] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 06:10:38,996 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:38] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 06:10:39,009 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:39] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:10:39,462 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:39] "GET /data-mapping/ HTTP/1.1" 200 -
2025-08-12 06:10:39,848 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:39] "GET /static/js/data-mapping.js HTTP/1.1" 200 -
2025-08-12 06:10:40,091 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:10:40,106 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:40] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:10:40,198 - INFO - [data_mapping_routes.py:93] - Available MCP servers: ['Data Mapping Analyst', 'Engineer', 'Skills', 'Weather', 'dataengineer']
2025-08-12 06:10:40,202 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-12 06:10:40,203 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:10:40,203 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:10:40,259 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:10:40,259 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-12 06:10:40,260 - WARNING - [data_mapping_routes.py:106] - Could not connect to data mapping server: Data Mapping Analyst
2025-08-12 06:10:40,260 - INFO - [data_mapping_routes.py:111] - Data mapping server not found in registry, attempting manual registration
2025-08-12 06:10:40,262 - WARNING - [data_mapping_routes.py:119] - Could not connect to manual data mapping server: HTTPConnectionPool(host='localhost', port=8003): Max retries exceeded with url: /sse (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b2ef437d5d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-12 06:10:40,262 - WARNING - [data_mapping_routes.py:122] - Data mapping MCP server not found. Agent will work without MCP features.
2025-08-12 06:10:40,309 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:40] "GET /data-mapping/server-status HTTP/1.1" 200 -
2025-08-12 06:10:58,098 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:58] "GET /data-mapping/ HTTP/1.1" 200 -
2025-08-12 06:10:58,516 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:10:58,523 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:58] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:10:58,563 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:58] "GET /data-mapping/server-status HTTP/1.1" 200 -
2025-08-12 06:10:58,830 - INFO - [app.py:326] - Schema requested for workspace: 
2025-08-12 06:10:58,830 - DEBUG - [app.py:353] - Schema retrieval completed in 0.000s
2025-08-12 06:10:58,831 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:10:58] "GET /api/schema?workspace= HTTP/1.1" 200 -
2025-08-12 06:11:04,360 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:11:04] "GET /admin/ HTTP/1.1" 200 -
2025-08-12 06:11:04,599 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:11:04] "[36mGET /static/js/admin/dashboard.js HTTP/1.1[0m" 304 -
2025-08-12 06:11:04,727 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:11:04,772 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:11:04] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:11:05,073 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:11:05] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-12 06:11:05,092 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:11:05] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-12 06:11:11,638 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:11:11] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-12 06:11:12,358 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:11:12] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-12 06:11:12,514 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:11:12] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-12 06:13:19,246 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 06:13:19,248 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 06:13:19,249 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:13:19,250 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 06:13:19,250 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:13:19,251 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 06:13:19,251 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:13:19,252 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 06:13:19,252 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:13:19,252 - INFO - [database.py:328] - Closing database connection
2025-08-12 06:13:19,253 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 06:13:19,253 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 06:13:19,255 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 06:13:19,255 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 06:13:19,256 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:13:19,256 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 06:13:19,256 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:13:19,257 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 06:13:19,257 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:13:19,259 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 06:13:19,259 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:13:19,259 - INFO - [database.py:328] - Closing database connection
2025-08-12 06:13:19,260 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 06:13:19,260 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 06:13:23,164 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:23,165 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:23,165 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:23,165 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:23,166 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:13:27,056 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-12 06:13:30,562 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:13:30,562 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:13:30,596 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:13:30,596 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:30,596 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:30,596 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:30,597 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:30,597 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:13:30,597 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:13:30,631 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:13:30,631 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:30,631 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:30,632 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:30,632 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:30,632 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:13:30,632 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:13:30,670 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:13:30,670 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:30,670 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:30,670 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:30,671 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:30,671 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 06:13:30,671 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:13:30,671 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:13:30,705 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:13:30,705 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 06:13:30,705 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:13:30,705 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:30,705 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:30,706 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:30,706 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:30,706 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:13:30,714 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-12 06:13:30,734 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-12 06:13:30,737 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-12 06:13:30,739 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-12 06:13:30,774 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:13:30,774 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:13:30,809 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:13:30,809 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:30,810 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:30,810 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:30,810 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:30,810 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:13:30,810 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:13:30,844 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:13:30,844 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:30,844 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:30,844 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:30,844 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:30,845 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:13:30,845 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:13:30,875 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:13:30,876 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:30,876 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:30,876 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:30,876 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:30,876 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 06:13:30,876 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:13:30,876 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:13:30,913 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:13:30,913 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 06:13:30,914 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:13:30,914 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:13:30,914 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:13:30,914 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:13:30,915 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:13:30,915 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:13:30,930 - INFO - [app.py:736] - Initializing application-wide components
2025-08-12 06:13:30,933 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-12 06:13:30,934 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-12 06:13:30,934 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-12 06:13:30,936 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-12 06:13:30,936 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-12 06:13:34,149 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-12 06:13:34,225 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /admin/ HTTP/1.1" 200 -
2025-08-12 06:13:34,379 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-12 06:13:34,584 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-12 06:13:34,625 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 06:13:34,643 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 06:13:34,651 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-12 06:13:34,653 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-12 06:13:34,676 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-12 06:13:34,967 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-12 06:13:34,981 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:34] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-12 06:13:35,015 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,023 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,036 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,042 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,297 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-12 06:13:35,312 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,345 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,367 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,383 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,388 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-12 06:13:35,619 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-12 06:13:35,632 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-12 06:13:35,674 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-12 06:13:35,680 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-12 06:13:35,701 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-12 06:13:35,703 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-12 06:13:35,947 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-12 06:13:35,959 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:35] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-12 06:13:36,011 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-12 06:13:36,051 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-12 06:13:36,056 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-12 06:13:36,056 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-12 06:13:36,266 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-12 06:13:36,322 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-08-12 06:13:36,346 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:13:36,397 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:13:36,428 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-12 06:13:36,653 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-12 06:13:36,656 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-12 06:13:36,685 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "[33mGET /static/vendor/bootstrap/bootstrap.bundle.min.js.map HTTP/1.1[0m" 404 -
2025-08-12 06:13:36,691 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:36] "[33mGET /static/vendor/bootstrap/bootstrap.min.css.map HTTP/1.1[0m" 404 -
2025-08-12 06:13:37,136 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:37] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-12 06:13:37,142 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:37] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-12 06:13:37,384 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:13:37] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-12 06:15:54,784 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 06:15:54,784 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 06:15:54,785 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:15:54,785 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 06:15:54,785 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:15:54,785 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 06:15:54,786 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:15:54,786 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 06:15:54,786 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:15:54,787 - INFO - [database.py:328] - Closing database connection
2025-08-12 06:15:54,787 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 06:15:54,787 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 06:15:54,788 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 06:15:54,788 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 06:15:54,788 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:15:54,788 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 06:15:54,788 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:15:54,788 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 06:15:54,788 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:15:54,789 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 06:15:54,789 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 06:15:54,789 - INFO - [database.py:328] - Closing database connection
2025-08-12 06:15:54,789 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 06:15:54,789 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 06:15:58,762 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:15:58,762 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:15:58,762 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:15:58,763 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:15:58,764 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:16:02,461 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-12 06:16:05,212 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:05,212 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:05,247 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:05,247 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:16:05,247 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:16:05,247 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:16:05,247 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:16:05,248 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:05,248 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:05,283 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:05,283 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:16:05,283 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:16:05,284 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:16:05,284 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:16:05,284 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:05,284 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:05,318 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:05,318 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:16:05,318 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:16:05,319 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:16:05,319 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:16:05,319 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 06:16:05,319 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:05,319 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:05,353 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:05,353 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 06:16:05,353 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:16:05,353 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:16:05,354 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:16:05,354 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:16:05,354 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:16:05,354 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:16:05,363 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-12 06:16:05,383 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-12 06:16:05,386 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-12 06:16:05,387 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-12 06:16:05,424 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:05,424 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:05,459 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:05,459 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:16:05,460 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:16:05,460 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:16:05,460 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:16:05,460 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:05,460 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:05,498 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:05,498 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:16:05,499 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:16:05,499 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:16:05,499 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:16:05,499 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:05,499 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:05,533 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:05,533 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:16:05,534 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:16:05,534 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:16:05,534 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:16:05,534 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 06:16:05,534 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:05,534 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:05,568 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:05,568 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 06:16:05,568 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:16:05,569 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 06:16:05,569 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 06:16:05,569 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 06:16:05,569 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 06:16:05,569 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 06:16:05,584 - INFO - [app.py:736] - Initializing application-wide components
2025-08-12 06:16:05,587 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-12 06:16:05,588 - INFO - [app.py:744] - AutoGen tables initialized
2025-08-12 06:16:05,588 - INFO - [app.py:747] - Application-wide components initialization complete
2025-08-12 06:16:05,590 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-12 06:16:05,590 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-12 06:16:08,013 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-12 06:16:08,065 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /admin/ HTTP/1.1" 200 -
2025-08-12 06:16:08,260 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1" 200 -
2025-08-12 06:16:08,424 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/vendor/fontawesome/all.min.css HTTP/1.1" 200 -
2025-08-12 06:16:08,451 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 06:16:08,477 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1" 200 -
2025-08-12 06:16:08,484 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/css/themes.css HTTP/1.1" 200 -
2025-08-12 06:16:08,487 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/css/styles.css HTTP/1.1" 200 -
2025-08-12 06:16:08,577 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/css/datatable-fixes.css HTTP/1.1" 200 -
2025-08-12 06:16:08,825 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/css/knowledge-chat.css HTTP/1.1" 200 -
2025-08-12 06:16:08,827 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/js/theme-preload.js HTTP/1.1" 200 -
2025-08-12 06:16:08,846 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1" 200 -
2025-08-12 06:16:08,858 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1" 200 -
2025-08-12 06:16:08,866 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1" 200 -
2025-08-12 06:16:08,882 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:08] "GET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 06:16:09,160 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 -
2025-08-12 06:16:09,168 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1" 200 -
2025-08-12 06:16:09,230 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1" 200 -
2025-08-12 06:16:09,233 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1" 200 -
2025-08-12 06:16:09,234 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1" 200 -
2025-08-12 06:16:09,246 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1" 200 -
2025-08-12 06:16:09,509 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/theme.js HTTP/1.1" 200 -
2025-08-12 06:16:09,522 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/ui-utils.js HTTP/1.1" 200 -
2025-08-12 06:16:09,562 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/core.js HTTP/1.1" 200 -
2025-08-12 06:16:09,593 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/results-display.js HTTP/1.1" 200 -
2025-08-12 06:16:09,604 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/schema-manager.js HTTP/1.1" 200 -
2025-08-12 06:16:09,607 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/table-mentions.js HTTP/1.1" 200 -
2025-08-12 06:16:09,840 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/feedback.js HTTP/1.1" 200 -
2025-08-12 06:16:09,860 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/dashboard.js HTTP/1.1" 200 -
2025-08-12 06:16:09,903 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/query-handler.js HTTP/1.1" 200 -
2025-08-12 06:16:09,934 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/sql-editor.js HTTP/1.1" 200 -
2025-08-12 06:16:09,935 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/js/datatable-init.js HTTP/1.1" 200 -
2025-08-12 06:16:09,937 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:09] "GET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1" 200 -
2025-08-12 06:16:10,167 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:10] "GET /static/js/admin/dashboard.js HTTP/1.1" 200 -
2025-08-12 06:16:10,506 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:16:10,593 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:10] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1" 200 -
2025-08-12 06:16:10,610 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:10] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:10,673 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:10] "GET /admin/api/dashboard/stats HTTP/1.1" 200 -
2025-08-12 06:16:10,693 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:10] "GET /admin/api/audit-logs?limit=5 HTTP/1.1" 200 -
2025-08-12 06:16:10,781 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:10] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1" 200 -
2025-08-12 06:16:11,111 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:11] "GET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1" 200 -
2025-08-12 06:16:11,353 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:11] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-12 06:16:17,445 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:17] "GET /admin/audit-logs HTTP/1.1" 200 -
2025-08-12 06:16:17,795 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:17] "GET /static/js/admin/audit-logs.js HTTP/1.1" 200 -
2025-08-12 06:16:18,042 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:16:18,085 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:18] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:24,486 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:24] "GET /admin/api/audit-logs/1508 HTTP/1.1" 200 -
2025-08-12 06:16:28,040 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:28] "GET /admin/api/audit-logs/1509 HTTP/1.1" 200 -
2025-08-12 06:16:39,912 - DEBUG - [app.py:172] - Main page requested
2025-08-12 06:16:39,918 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:39] "GET / HTTP/1.1" 200 -
2025-08-12 06:16:40,358 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-12 06:16:40,406 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:40] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-12 06:16:40,498 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:40] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-12 06:16:40,520 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:40] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-12 06:16:43,116 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:43] "GET /query-editor HTTP/1.1" 200 -
2025-08-12 06:16:43,501 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:43] "[36mGET /static/js/query-editor.js HTTP/1.1[0m" 304 -
2025-08-12 06:16:43,756 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:43] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-12 06:16:44,123 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-12 06:16:44,130 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:44] "GET /knowledge HTTP/1.1" 200 -
2025-08-12 06:16:44,184 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:44] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-12 06:16:44,186 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:44] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-12 06:16:44,200 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:44] "[36mGET /static/js/knowledge-base.js HTTP/1.1[0m" 304 -
2025-08-12 06:16:44,557 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:16:44,577 - INFO - [knowledge_manager.py:33] - Initializing Knowledge Manager
2025-08-12 06:16:44,583 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:44] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:44,722 - INFO - [vector_store_client.py:36] - Connecting to ChromaDB service at http://localhost:8001
2025-08-12 06:16:44,727 - INFO - [vector_store_client.py:44] - ChromaDB service connection established in 0.00s
2025-08-12 06:16:44,734 - INFO - [vector_store_client.py:121] - Collection 'knowledge_chunks' already exists
2025-08-12 06:16:44,734 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:44,734 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:44,771 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:44,772 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:44] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-12 06:16:44,959 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:44] "GET /agent HTTP/1.1" 200 -
2025-08-12 06:16:45,336 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:45] "[36mGET /static/js/tool-confirmation.js HTTP/1.1[0m" 304 -
2025-08-12 06:16:45,354 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:45] "[36mGET /static/js/agent-chat.js HTTP/1.1[0m" 304 -
2025-08-12 06:16:45,563 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:16:45,570 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:45] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:45,701 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:45] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 06:16:45,717 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:45] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 06:16:45,906 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:45] "GET /knowledge HTTP/1.1" 200 -
2025-08-12 06:16:46,307 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:16:46,339 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:46] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:46,347 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:46] "GET /api/knowledge/tags HTTP/1.1" 200 -
2025-08-12 06:16:50,527 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:50] "GET /agent HTTP/1.1" 200 -
2025-08-12 06:16:50,938 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:16:50,975 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:50] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:50,983 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:50] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 06:16:50,987 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:50] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 06:16:51,247 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:51] "GET /data-mapping/ HTTP/1.1" 200 -
2025-08-12 06:16:51,352 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:51] "[36mGET /static/js/data-mapping.js HTTP/1.1[0m" 304 -
2025-08-12 06:16:51,714 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:16:51,730 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:51] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:51,740 - INFO - [data_mapping_routes.py:93] - Available MCP servers: ['Data Mapping Analyst', 'Engineer', 'Skills', 'Weather', 'dataengineer']
2025-08-12 06:16:51,753 - INFO - [common_llm.py:26] - Initializing shared LLM engine instance
2025-08-12 06:16:51,754 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 06:16:51,755 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 06:16:51,868 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 06:16:51,868 - INFO - [common_llm.py:28] - Shared LLM engine instance initialized successfully
2025-08-12 06:16:51,869 - WARNING - [data_mapping_routes.py:106] - Could not connect to data mapping server: Data Mapping Analyst
2025-08-12 06:16:51,869 - INFO - [data_mapping_routes.py:111] - Data mapping server not found in registry, attempting manual registration
2025-08-12 06:16:51,873 - WARNING - [data_mapping_routes.py:119] - Could not connect to manual data mapping server: HTTPConnectionPool(host='localhost', port=8003): Max retries exceeded with url: /sse (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f87434f8fd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2025-08-12 06:16:51,873 - WARNING - [data_mapping_routes.py:122] - Data mapping MCP server not found. Agent will work without MCP features.
2025-08-12 06:16:51,915 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:51] "GET /data-mapping/server-status HTTP/1.1" 200 -
2025-08-12 06:16:52,345 - INFO - [app.py:326] - Schema requested for workspace: 
2025-08-12 06:16:52,346 - DEBUG - [app.py:353] - Schema retrieval completed in 0.001s
2025-08-12 06:16:52,347 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:52] "GET /api/schema?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:53,906 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:53] "GET /agent HTTP/1.1" 200 -
2025-08-12 06:16:54,135 - DEBUG - [app.py:240] - Table suggestions requested for workspace: , query: ''
2025-08-12 06:16:54,142 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:54] "GET /api/tables/suggestions?workspace= HTTP/1.1" 200 -
2025-08-12 06:16:54,355 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:54] "GET /api/agent/workflows HTTP/1.1" 200 -
2025-08-12 06:16:54,360 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 06:16:54] "GET /api/agent/teams HTTP/1.1" 200 -
2025-08-12 08:24:50,351 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 08:24:50,351 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 08:24:50,351 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:24:50,351 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 08:24:50,351 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:24:50,352 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 08:24:50,352 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:24:50,352 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 08:24:50,352 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:24:50,352 - INFO - [database.py:328] - Closing database connection
2025-08-12 08:24:50,352 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 08:24:50,353 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 08:24:50,353 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 08:24:50,353 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 08:24:50,353 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:24:50,354 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 08:24:50,354 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:24:50,354 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 08:24:50,354 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:24:50,354 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 08:24:50,354 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:24:50,354 - INFO - [database.py:328] - Closing database connection
2025-08-12 08:24:50,354 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 08:24:50,354 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 08:41:38,792 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:38,792 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:38,792 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:38,792 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:38,793 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 08:41:44,255 - INFO - [mcp_client_manager.py:31] - Successfully imported MCP library components
2025-08-12 08:41:47,200 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 08:41:47,200 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 08:41:47,231 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 08:41:47,231 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:47,232 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:47,232 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:47,232 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:47,232 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 08:41:47,232 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 08:41:47,269 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 08:41:47,269 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:47,270 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:47,270 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:47,270 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:47,270 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 08:41:47,270 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 08:41:47,306 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 08:41:47,307 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:47,307 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:47,307 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:47,307 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:47,307 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 08:41:47,307 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 08:41:47,308 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 08:41:47,342 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 08:41:47,342 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 08:41:47,342 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 08:41:47,342 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:47,343 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:47,343 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:47,343 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:47,344 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 08:41:47,353 - INFO - [setup_knowledge_permissions.py:30] - Setting up knowledge base permissions
2025-08-12 08:41:47,377 - INFO - [setup_knowledge_permissions.py:61] - Assigning knowledge permissions to admin role
2025-08-12 08:41:47,379 - INFO - [setup_knowledge_permissions.py:70] - Assigning knowledge permissions to user role
2025-08-12 08:41:47,380 - INFO - [setup_knowledge_permissions.py:78] - Knowledge base permissions setup complete
2025-08-12 08:41:47,419 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 08:41:47,419 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 08:41:47,456 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 08:41:47,456 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:47,457 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:47,457 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:47,457 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:47,457 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 08:41:47,457 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 08:41:47,491 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 08:41:47,491 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:47,491 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:47,492 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:47,492 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:47,492 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 08:41:47,492 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 08:41:47,528 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 08:41:47,528 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:47,528 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:47,528 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:47,529 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:47,529 - INFO - [azure_client.py:11] - Initializing Azure AI Client using LLM Engine
2025-08-12 08:41:47,529 - INFO - [llm_engine.py:30] - Initializing LLM Engine with endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
2025-08-12 08:41:47,529 - INFO - [llm_engine.py:31] - Using model: gemini-2.5-flash
2025-08-12 08:41:47,563 - INFO - [llm_engine.py:39] - LLM Engine initialized successfully
2025-08-12 08:41:47,563 - INFO - [azure_client.py:17] - Azure AI Client initialized successfully
2025-08-12 08:41:47,563 - INFO - [database.py:108] - Database manager initialized with connection: sqlite:///text2sql.db
2025-08-12 08:41:47,563 - INFO - [schema_manager.py:48] - Loading schema from /home/vijay/gitrepo/copilot/text2sql/config/data/schema.json
2025-08-12 08:41:47,563 - INFO - [schema_manager.py:55] - Loaded 2 workspaces from schema file
2025-08-12 08:41:47,564 - INFO - [schema_manager.py:274] - Loading join conditions from /home/vijay/gitrepo/copilot/text2sql/config/data/condition.json
2025-08-12 08:41:47,564 - INFO - [schema_manager.py:281] - Loaded 3 join conditions from condition file
2025-08-12 08:41:47,564 - INFO - [feedback_manager.py:32] - Feedback manager initialized with connection: sqlite:///text2sql.db
2025-08-12 08:41:47,582 - INFO - [app.py:738] - Initializing application-wide components
2025-08-12 08:41:47,585 - INFO - [app.py:62] - Successfully started MCP server: dataengineer
2025-08-12 08:41:47,585 - INFO - [app.py:746] - AutoGen tables initialized
2025-08-12 08:41:47,585 - INFO - [app.py:749] - Application-wide components initialization complete
2025-08-12 08:41:47,587 - INFO - [_internal.py:97] - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://172.27.251.157:5000
2025-08-12 08:41:47,587 - INFO - [_internal.py:97] - [33mPress CTRL+C to quit[0m
2025-08-12 08:41:53,963 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:41:53] "[32mGET /admin/agent-runs HTTP/1.1[0m" 302 -
2025-08-12 08:41:54,187 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:41:54] "GET /login HTTP/1.1" 200 -
2025-08-12 08:41:54,252 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:41:54] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.min.css HTTP/1.1[0m" 304 -
2025-08-12 08:41:54,498 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:41:54] "[36mGET /static/vendor/fontawesome/all.min.css HTTP/1.1[0m" 304 -
2025-08-12 08:41:54,502 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:41:54] "[36mGET /static/css/themes.css HTTP/1.1[0m" 304 -
2025-08-12 08:41:54,510 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:41:54] "[36mGET /static/js/theme.js HTTP/1.1[0m" 304 -
2025-08-12 08:41:54,514 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:41:54] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-08-12 08:41:54,518 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:41:54] "[36mGET /static/js/theme-preload.js HTTP/1.1[0m" 304 -
2025-08-12 08:41:59,946 - INFO - [database.py:24] - Creating new database session factory with URI: sqlite:///text2sql.db
2025-08-12 08:42:00,182 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[32mPOST /login HTTP/1.1[0m" 302 -
2025-08-12 08:42:00,203 - DEBUG - [app.py:172] - Main page requested
2025-08-12 08:42:00,220 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "GET / HTTP/1.1" 200 -
2025-08-12 08:42:00,487 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,561 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.css HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,564 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/css/datatable-fixes.css HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,571 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/css/knowledge-chat.css HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,575 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/jquery/jquery-3.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,576 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/bootstrap/bootstrap-5.3.0.bundle.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,798 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/webfonts/fa-solid-900.woff2 HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,869 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/datatables/jquery.dataTables.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,873 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/datatables/dataTables.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,877 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/datatables/dataTables.responsive.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,883 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/datatables/responsive.bootstrap5.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:00,886 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:00] "[36mGET /static/vendor/chartjs/chart-3.9.1.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,111 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/vendor/markdown-it/markdown-it-13.0.1.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,175 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/ui-utils.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,176 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/vendor/highlight/highlight-11.7.0.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,179 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/core.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,183 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/schema-manager.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,185 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/table-mentions.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,422 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/results-display.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,484 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/feedback.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,487 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/query-handler.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,490 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/dashboard.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,502 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/loader.min.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,504 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/sql-editor.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:01,727 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:01] "[36mGET /static/js/datatable-init.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:02,067 - DEBUG - [app.py:240] - Table suggestions requested for workspace: dfd, query: ''
2025-08-12 08:42:02,078 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:02] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:02,088 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:02] "GET /api/tables/suggestions?workspace=dfd HTTP/1.1" 200 -
2025-08-12 08:42:02,311 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:02] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.css HTTP/1.1[0m" 304 -
2025-08-12 08:42:02,439 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:02] "[36mGET /static/vendor/monaco-editor/0.36.1/min/vs/editor/editor.main.nls.js HTTP/1.1[0m" 304 -
2025-08-12 08:42:02,557 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:02] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/basic-languages/sql/sql.js HTTP/1.1[0m" 404 -
2025-08-12 08:42:02,914 - INFO - [_internal.py:97] - 127.0.0.1 - - [12/Aug/2025 08:42:02] "[33mGET /static/vendor/monaco-editor/0.36.1/min/vs/base/worker/workerMain.js HTTP/1.1[0m" 404 -
2025-08-12 08:42:05,200 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 08:42:05,201 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 08:42:05,202 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:42:05,212 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 08:42:05,212 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:42:05,213 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 08:42:05,213 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:42:05,213 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 08:42:05,214 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:42:05,214 - INFO - [database.py:328] - Closing database connection
2025-08-12 08:42:05,214 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 08:42:05,215 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
2025-08-12 08:42:05,216 - INFO - [sql_generator.py:490] - Closing all agent connections
2025-08-12 08:42:05,216 - INFO - [intent_agent.py:135] - Closing intent agent's LLM engine connection
2025-08-12 08:42:05,216 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:42:05,217 - INFO - [table_agent.py:121] - Closing table agent's LLM engine connection
2025-08-12 08:42:05,217 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:42:05,217 - INFO - [column_agent.py:231] - Closing column agent's LLM engine connection
2025-08-12 08:42:05,218 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:42:05,218 - INFO - [azure_client.py:302] - Closing Azure AI client connection
2025-08-12 08:42:05,219 - INFO - [llm_engine.py:486] - Closing LLM Engine client connection
2025-08-12 08:42:05,219 - INFO - [database.py:328] - Closing database connection
2025-08-12 08:42:05,219 - INFO - [feedback_manager.py:785] - Closing database connections
2025-08-12 08:42:05,220 - INFO - [vector_store_client.py:439] - Closing ChromaDB service connection
